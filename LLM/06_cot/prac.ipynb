{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI 모의 면접봇"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 지원하고자 하는 회사의 정보를 수집 (채용공고-조건, 우대조건, 인재상, ...)\n",
    "2. 지원자의 정보 준비 (인적사항, 학력/경력, 포트폴리오, ...)\n",
    "3. 1과 2에서 수집한 정보를 바탕으로 모의 면접 진행\n",
    "    - 면접관의 스타일 선택 (성격, 성향, 실무진/임원진 등...)\n",
    "4. 모의 면접 결과 및 피드백 안내"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "company = \"\"\"\n",
    "팀 소개\n",
    "\n",
    "AI Lab은 CTO 산하에 편재되어 있으며, 스토리/음악 컨텐츠 추천/검색을 위한 고객 소비/행동 패턴을 분석하고, CRM 마케팅 자동화 모델링 등 통계 기반으로 데이터를 분석하고 모델링하는 업무를 수행하고 있습니다.\n",
    "\n",
    "특히 최근에는 Helix라는 인공지능(AI) 브랜드를 런칭했고, 첫 서비스로 카카오페이지에 적용되는 ‘헬릭스 푸시’를 선보였습니다. 헬릭스 푸시는 모바일 알림 형태로 웹툰과 웹소설 등 IP를 추천하고 캐시 등 혜택을 제공하는 서비스로 AI가 자체적으로 개별 유저 열람, 구매, 방문 데이터를 학습하고 이를 바탕으로 가장 최적화된 시점에 독자가 가장 선호할 것으로 여겨지는 작품을 이용권 혜택 등과 함께 전달합니다.\n",
    "\n",
    "이처럼 카카오엔터테인먼트는 AI 기술 연구 및 개발을 통해 다양한 플랫폼 안에서 비즈니스 효율과 가치를 극대화하고 사용자 경험을 향상시키고자 합니다.\n",
    "\n",
    "업무내용\n",
    "\n",
    "LLM(Large Language Model) 연구 / 개발\n",
    "Pre-training / fine-tuning / prompt engineering / RAG\n",
    "Domain-specific LLM 개발\n",
    "sLLM 개발\n",
    "\n",
    "지원자격\n",
    "\n",
    "컴퓨터 과학, 인공지능(AI) 분야 전공 석사 학위 혹은 이에 준하는 관련 경력(5년 이상)을 갖춘 분\n",
    "도메인 특화 LLM 모델에 대한 연구 및 개발 경험이 있는 분\n",
    "모델 경량화 기술에 대한 높은 이해와 활용 능력을 갖춘 분\n",
    "\n",
    "우대사항\n",
    "\n",
    "관련 분야 박사 학위를 소지한 분\n",
    "학회/컨퍼런스에 관련 논문 게재 또는 출판 경험이 있는 분\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio = \"\"\"\n",
    "소개\n",
    "이름: 허정윤\n",
    "직무: 백엔드 개발자\n",
    "학력: 컴퓨터공학과 학사 졸업\n",
    "교육: LLM AI CAMP 수료 중\n",
    "기술 스택: Java(Spring), Python, Vue.js 2, React, MariaDB, AWS, Docker, Linux\n",
    "백엔드 개발자로서 헬스케어 시스템 개발 및 운영을 경험하며, AI 및 클라우드 기술을 활용한 서비스 고도화에 관심이 많습니다.\n",
    "\n",
    "프로젝트 경험\n",
    "헬스케어 상담 시스템 유지보수 (2년)\n",
    "혈당 측정 장치 API 연동, DB 설계 및 최적화, Docker 기반 알림 서버 구축\n",
    "데이터 분석 및 시각화, Kubernetes 기반 서비스 운영\n",
    "기술 역량\n",
    "Java(Spring) 기반 API 개발 및 데이터베이스 설계\n",
    "AWS, Docker, Kubernetes를 활용한 배포 및 운영\n",
    "Vue.js 2, React를 활용한 프론트엔드 개발 경험\n",
    "관심 분야 및 목표\n",
    "스마트 팩토리, 커넥티드카, AI 서비스 개발 및 최적화, 클라우드 및 컨테이너 기반 인프라 구축.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([Document(metadata={}, page_content='팀 소개'),\n",
       "  Document(metadata={}, page_content='AI Lab은 CTO 산하에 편재되어 있으며, 스토리/음악 컨텐츠 추천/검색을 위한 고객 소비/행동 패턴을 분석하고, CRM 마케팅 자동화 모델링 등 통계 기반으로 데이터를'),\n",
       "  Document(metadata={}, page_content='모델링 등 통계 기반으로 데이터를 분석하고 모델링하는 업무를 수행하고 있습니다.'),\n",
       "  Document(metadata={}, page_content='특히 최근에는 Helix라는 인공지능(AI) 브랜드를 런칭했고, 첫 서비스로 카카오페이지에 적용되는 ‘헬릭스 푸시’를 선보였습니다. 헬릭스 푸시는 모바일 알림 형태로 웹툰과'),\n",
       "  Document(metadata={}, page_content='푸시는 모바일 알림 형태로 웹툰과 웹소설 등 IP를 추천하고 캐시 등 혜택을 제공하는 서비스로 AI가 자체적으로 개별 유저 열람, 구매, 방문 데이터를 학습하고 이를 바탕으로'),\n",
       "  Document(metadata={}, page_content='데이터를 학습하고 이를 바탕으로 가장 최적화된 시점에 독자가 가장 선호할 것으로 여겨지는 작품을 이용권 혜택 등과 함께 전달합니다.'),\n",
       "  Document(metadata={}, page_content='이처럼 카카오엔터테인먼트는 AI 기술 연구 및 개발을 통해 다양한 플랫폼 안에서 비즈니스 효율과 가치를 극대화하고 사용자 경험을 향상시키고자 합니다.\\n\\n업무내용'),\n",
       "  Document(metadata={}, page_content='LLM(Large Language Model) 연구 / 개발\\nPre-training / fine-tuning / prompt engineering / RAG'),\n",
       "  Document(metadata={}, page_content='Domain-specific LLM 개발\\nsLLM 개발'),\n",
       "  Document(metadata={}, page_content='지원자격'),\n",
       "  Document(metadata={}, page_content='컴퓨터 과학, 인공지능(AI) 분야 전공 석사 학위 혹은 이에 준하는 관련 경력(5년 이상)을 갖춘 분\\n도메인 특화 LLM 모델에 대한 연구 및 개발 경험이 있는 분'),\n",
       "  Document(metadata={}, page_content='모델 경량화 기술에 대한 높은 이해와 활용 능력을 갖춘 분'),\n",
       "  Document(metadata={}, page_content='우대사항\\n\\n관련 분야 박사 학위를 소지한 분\\n학회/컨퍼런스에 관련 논문 게재 또는 출판 경험이 있는 분'),\n",
       "  Document(metadata={}, page_content='소개\\n이름: 허정윤\\n직무: 백엔드 개발자\\n학력: 컴퓨터공학과 학사 졸업\\n교육: LLM AI CAMP 수료 중'),\n",
       "  Document(metadata={}, page_content='기술 스택: Java(Spring), Python, Vue.js 2, React, MariaDB, AWS, Docker, Linux'),\n",
       "  Document(metadata={}, page_content='백엔드 개발자로서 헬스케어 시스템 개발 및 운영을 경험하며, AI 및 클라우드 기술을 활용한 서비스 고도화에 관심이 많습니다.'),\n",
       "  Document(metadata={}, page_content='프로젝트 경험\\n헬스케어 상담 시스템 유지보수 (2년)\\n혈당 측정 장치 API 연동, DB 설계 및 최적화, Docker 기반 알림 서버 구축'),\n",
       "  Document(metadata={}, page_content='데이터 분석 및 시각화, Kubernetes 기반 서비스 운영\\n기술 역량\\nJava(Spring) 기반 API 개발 및 데이터베이스 설계'),\n",
       "  Document(metadata={}, page_content='AWS, Docker, Kubernetes를 활용한 배포 및 운영\\nVue.js 2, React를 활용한 프론트엔드 개발 경험\\n관심 분야 및 목표'),\n",
       "  Document(metadata={}, page_content='관심 분야 및 목표\\n스마트 팩토리, 커넥티드카, AI 서비스 개발 및 최적화, 클라우드 및 컨테이너 기반 인프라 구축.')],\n",
       " 20)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100, # 각 Chunk의 최대 문자 수 (기본값: 1000)\n",
    "    chunk_overlap=20, # 인접한 텍스트 조각 간 겹치는 문자 수 (기본값: 200)\n",
    "    # seperators: 텍스트 분할 구분자 우선순위 (기본값: ['\\n\\n', '\\n', ' ', ''])\n",
    ") \n",
    "\n",
    "# txt to document\n",
    "document = [Document(page_content=company), Document(page_content=portfolio)]\n",
    "\n",
    "document_chunked = splitter.split_documents(document)\n",
    "\n",
    "document_chunked, len(document_chunked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "documents = [\n",
    "    Document(page_content=company),\n",
    "    Document(page_content=portfolio)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([Document(metadata={}, page_content='팀 소개'),\n",
       "  Document(metadata={}, page_content='AI Lab은 CTO 산하에 편재되어 있으며, 스토리/음악 컨텐츠 추천/검색을 위한 고객 소비/행동 패턴을 분석하고, CRM 마케팅 자동화 모델링 등 통계 기반으로 데이터를'),\n",
       "  Document(metadata={}, page_content='모델링 등 통계 기반으로 데이터를 분석하고 모델링하는 업무를 수행하고 있습니다.'),\n",
       "  Document(metadata={}, page_content='특히 최근에는 Helix라는 인공지능(AI) 브랜드를 런칭했고, 첫 서비스로 카카오페이지에 적용되는 ‘헬릭스 푸시’를 선보였습니다. 헬릭스 푸시는 모바일 알림 형태로 웹툰과'),\n",
       "  Document(metadata={}, page_content='푸시는 모바일 알림 형태로 웹툰과 웹소설 등 IP를 추천하고 캐시 등 혜택을 제공하는 서비스로 AI가 자체적으로 개별 유저 열람, 구매, 방문 데이터를 학습하고 이를 바탕으로'),\n",
       "  Document(metadata={}, page_content='데이터를 학습하고 이를 바탕으로 가장 최적화된 시점에 독자가 가장 선호할 것으로 여겨지는 작품을 이용권 혜택 등과 함께 전달합니다.'),\n",
       "  Document(metadata={}, page_content='이처럼 카카오엔터테인먼트는 AI 기술 연구 및 개발을 통해 다양한 플랫폼 안에서 비즈니스 효율과 가치를 극대화하고 사용자 경험을 향상시키고자 합니다.\\n\\n업무내용'),\n",
       "  Document(metadata={}, page_content='LLM(Large Language Model) 연구 / 개발\\nPre-training / fine-tuning / prompt engineering / RAG'),\n",
       "  Document(metadata={}, page_content='Domain-specific LLM 개발\\nsLLM 개발'),\n",
       "  Document(metadata={}, page_content='지원자격'),\n",
       "  Document(metadata={}, page_content='컴퓨터 과학, 인공지능(AI) 분야 전공 석사 학위 혹은 이에 준하는 관련 경력(5년 이상)을 갖춘 분\\n도메인 특화 LLM 모델에 대한 연구 및 개발 경험이 있는 분'),\n",
       "  Document(metadata={}, page_content='모델 경량화 기술에 대한 높은 이해와 활용 능력을 갖춘 분'),\n",
       "  Document(metadata={}, page_content='우대사항\\n\\n관련 분야 박사 학위를 소지한 분\\n학회/컨퍼런스에 관련 논문 게재 또는 출판 경험이 있는 분'),\n",
       "  Document(metadata={}, page_content='소개\\n이름: 허정윤\\n직무: 백엔드 개발자\\n학력: 컴퓨터공학과 학사 졸업\\n교육: LLM AI CAMP 수료 중'),\n",
       "  Document(metadata={}, page_content='기술 스택: Java(Spring), Python, Vue.js 2, React, MariaDB, AWS, Docker, Linux'),\n",
       "  Document(metadata={}, page_content='백엔드 개발자로서 헬스케어 시스템 개발 및 운영을 경험하며, AI 및 클라우드 기술을 활용한 서비스 고도화에 관심이 많습니다.'),\n",
       "  Document(metadata={}, page_content='프로젝트 경험\\n헬스케어 상담 시스템 유지보수 (2년)\\n혈당 측정 장치 API 연동, DB 설계 및 최적화, Docker 기반 알림 서버 구축'),\n",
       "  Document(metadata={}, page_content='데이터 분석 및 시각화, Kubernetes 기반 서비스 운영\\n기술 역량\\nJava(Spring) 기반 API 개발 및 데이터베이스 설계'),\n",
       "  Document(metadata={}, page_content='AWS, Docker, Kubernetes를 활용한 배포 및 운영\\nVue.js 2, React를 활용한 프론트엔드 개발 경험\\n관심 분야 및 목표'),\n",
       "  Document(metadata={}, page_content='관심 분야 및 목표\\n스마트 팩토리, 커넥티드카, AI 서비스 개발 및 최적화, 클라우드 및 컨테이너 기반 인프라 구축.')],\n",
       " 20)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100, # 각 Chunk의 최대 문자 수 (기본값: 1000)\n",
    "    chunk_overlap=20, # 인접한 텍스트 조각 간 겹치는 문자 수 (기본값: 200)\n",
    "    # seperators: 텍스트 분할 구분자 우선순위 (기본값: ['\\n\\n', '\\n', ' ', ''])\n",
    ") \n",
    "\n",
    "document_chunked = splitter.split_documents(documents)\n",
    "\n",
    "document_chunked, len(document_chunked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(model='text-embedding-3-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma.vectorstores import Chroma\n",
    "\n",
    "vector_store = Chroma.from_documents(document_chunked, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    temperature=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "좋습니다. 첫 번째 질문입니다.\n",
      "\n",
      "\"AI와 LLM(대규모 언어 모델)의 차이점은 무엇인가요? 그리고 LLM이 어떻게 자연어 처리(NLP) 분야에서 활용되는지 설명해 주세요.\"\n",
      "몰라요\n",
      "괜찮습니다. AI와 LLM에 대한 이해는 시간이 걸릴 수 있습니다. 다음 질문으로 넘어가겠습니다.\n",
      "\n",
      "\"자연어 처리(NLP)에서 LLM의 활용 사례 중 하나를 설명하고, 그 사례가 어떻게 실제 문제를 해결하는 데 기여하는지 이야기해 주세요.\"\n",
      "몰라요\n",
      "알겠습니다. 정보가 부족할 수 있습니다. 마지막 질문을 드리겠습니다.\n",
      "\n",
      "\"AI 윤리에 대해 어떻게 생각하시나요? AI 시스템이 사회에 미치는 영향에 대해 어떤 점을 고려해야 한다고 생각하시나요?\"\n",
      "몰라요\n",
      "이해했습니다. AI와 LLM, 그리고 AI 윤리에 대한 지식은 점차 쌓아갈 수 있는 부분입니다. 앞으로 관련 자료를 찾아보시거나 학습해보시면 도움이 될 것입니다. 감사합니다. 면접이 끝났습니다.\n",
      "종료\n",
      "**평가**\n",
      "\n",
      "지원자는 AI 및 LLM(대규모 언어 모델)에 대한 기본적인 이해가 부족한 것으로 보입니다. 면접 중에 세 가지 질문 모두에 대해 '모른다'는 답변을 하였으며, 이는 해당 분야에 대한 기술적 역량이 미흡하다는 것을 나타냅니다. \n",
      "\n",
      "지원자가 모델링 및 데이터 분석에 대한 경험이 있다고 하더라도, AI 및 자연어 처리(NLP) 관련 지식이 부족한 점은 큰 단점으로 작용합니다. 특히, 관련 분야에서 박사 학위를 소지한 지원자를 우대하는 조건에 비추어 볼 때, 기술적 전문성이 요구되는 이 역할에는 적합하지 않을 것으로 판단됩니다.\n",
      "\n",
      "**점수: 2/10**  \n",
      "(기술적 지식 부족으로 인해 낮은 점수)\n",
      "\n",
      "**합격 여부: 불합격**  \n",
      "지원자는 AI 및 LLM에 대한 기초 지식이 부족하여, 해당 직무에 필요한 기술 역량을 갖추지 못한 것으로 평가됩니다. 향후 관련 분야에 대한 학습과 경험이 필요할 것으로 보입니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "sys_inst = \"\"\"\n",
    "당신은 면접관입니다. \n",
    "지원자에게 질문을 하고 답변을 듣고 피드백을 진행하면 됩니다.\n",
    "AI, LLM 관련한 질문을 해주세요.\n",
    "질문에 대한 피드백은 줄 필요 없어\n",
    "\"\"\"\n",
    "msgs = [SystemMessage(sys_inst)]\n",
    "res = model.invoke(msgs)\n",
    "msgs.append(res)\n",
    "print()\n",
    "print(res.content)\n",
    "\n",
    "while True:\n",
    "    reply = input()\n",
    "    print(reply)\n",
    "    msgs.append(HumanMessage(reply))\n",
    "    if \"종료\" in reply:\n",
    "        break\n",
    "    res = model.invoke(msgs)\n",
    "    msgs.append(res)\n",
    "    print(res.content)\n",
    "    \n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    다음 '질문'에 대해 '문서'의 내용만을 참고하여 '평가'을 생성해 주세요.\n",
    "    질문 : {question}\n",
    "    문서 : {context}\n",
    "    대화 내용 : \n",
    "    \"\"\" + \"\\n\".join([msg.content for msg in msgs]),\n",
    "    input_variables=[\"question\", \"context\"],\n",
    ")\n",
    "\n",
    "retriever = vector_store.as_retriever()\n",
    "chain = RetrievalQA.from_chain_type(\n",
    "    llm=model,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vector_store.as_retriever(),\n",
    "    chain_type_kwargs={\"prompt\": prompt},\n",
    ")\n",
    "\n",
    "res = chain.invoke(\"대화 내용을 토대로 면접관의 입장으로써 지원자의 기술 역량에 대해 점수와 합격 여부를 포함한 피드백 및 평가를 진행해주세요\")\n",
    "\n",
    "print(res['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vectordb_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
