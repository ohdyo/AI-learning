{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI 모의 면접봇\n",
    "\n",
    "1. 지원하고자 하는 회사의 정보 수집(채용공고-조건,우대조건,인재상,...)\n",
    "2. 지원자의 정보 준비 (인적사항, 학력/경력, 포트폴리오,...)\n",
    "3. 1과 2에서 수집한 정보를 바탕으로 모의 면접 진행\n",
    "    - 면접관의 스타일 선택 (성격, 성향, 실무진/임원진 등...)\n",
    "4. 모의 면접 결과 및 피드백 안내\n",
    "\n",
    "- 결과 시연 + langsmith history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import ChatMessage,HumanMessage,AIMessage\n",
    "from langchain_core.documents import Document\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 회사꺼 백터변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. 이스트소프트 조건: LLM/NLP 관련 분야 석사 학위 이상 또는 그에 준하는 3년 이상의 경력 알고리즘과 머신러닝, LLM 분야에 대한 깊은 이해 Pytorch를 활용한 코드 작성 및 실험 능숙 우대조건: LLM 학습 및 최적화 경험 분산 학습 시스템 구축 경험 GPU 자원 최적화 경험 모델 경량화 및 추론 성능 최적화 경험 AWS, Azure 등 클라우드 플랫폼 사용 경험 필요 기술 스택: Git AI/인공지능 Linux Machine Learning Deep Learning AWS TensorFlow Python Azure PyTorch 출처:  JOBKOREA.CO.KR',\n",
       " '2. 업스테이지 조건: LLM 알고리즘/데이터 연구·개발 경험 LLM Post-training 경험 다양한 협업 환경에서의 원활한 의사소통 능력 우대조건: 대규모 모델 학습을 위한 프레임워크 사용 경험 (예: DeepSpeed) LLM 기반 제품 개발 경험 AI 및 NLP 관련 국제 학회 논문 게재 경험 필요 기술 스택: AI/인공지능 NLP TensorFlow PyTorch 출처:  JOBKOREA.CO.KR',\n",
       " '3. 삼정KPMG 조건: ML/AI/NL/LLM 분야 경력자 관련 프로젝트 경험 및 성과 보유자 우대조건: 금융 및 컨설팅 업계 경험자 데이터 분석 및 처리 능력 우수자 필요 기술 스택: Machine Learning AI Natural Language Processing LLM 출처:  JOBKOREA.CO.KR',\n",
       " '4. 아이브릭스 조건: LLM 서비스 구축 및 운영 경험 AI 모델 개발 및 최적화 능력 우대조건: 대규모 데이터 처리 경험 클라우드 환경에서의 서비스 개발 경험 필요 기술 스택: AI/인공지능 Machine Learning Python TensorFlow 출처:  잡코리아',\n",
       " '5. 비전스페이스 조건: 생성형 AI, LLM, RAG R&D 개발 경험 로봇산업 관련 프로젝트 참여 경험 우대조건: 데이터 사이언스 및 분석 능력 우수자 유연근무제 활용 가능자 필요 기술 스택: 데이터 분석 AI/인공지능 Machine Learning Python 출처:  JOBKOREA.CO.KR',\n",
       " '6. 진인프라 조건: LLM 개발 경력자 중견 IT 기업에서의 프로젝트 경험 우대조건: AI 및 머신러닝 분야 전문성 보유자 팀 협업 및 커뮤니케이션 능력 우수자 필요 기술 스택: LLM 개발 AI/인공지능 Machine Learning Python']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./data/company_info.txt' , 'r', encoding='utf-8') as f:\n",
    "    company_info = f.read()\n",
    "    \n",
    "# 개행이 두 번 들어간 부분을 기준으로 텍스트 분할\n",
    "company_info_list = company_info.split('\\n\\n')\n",
    "\n",
    "# 개행 띄어쓰기로 변환\n",
    "company_info_list = [info.replace('\\n', ' ') for info in company_info_list]\n",
    "\n",
    "company_info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='1. 이스트소프트 조건: LLM/NLP 관련 분야 석사 학위 이상 또는 그에 준하는 3년 이상의 경력 알고리즘과 머신러닝, LLM 분야에 대한 깊은 이해 Pytorch를 활용한 코드 작성 및 실험 능숙 우대조건: LLM 학습 및 최적화 경험 분산 학습 시스템 구축 경험 GPU 자원 최적화 경험 모델 경량화 및 추론 성능 최적화 경험 AWS, Azure 등 클라우드 플랫폼 사용 경험 필요 기술 스택: Git AI/인공지능 Linux Machine Learning Deep Learning AWS TensorFlow Python Azure PyTorch 출처:  JOBKOREA.CO.KR'),\n",
       " Document(metadata={}, page_content='2. 업스테이지 조건: LLM 알고리즘/데이터 연구·개발 경험 LLM Post-training 경험 다양한 협업 환경에서의 원활한 의사소통 능력 우대조건: 대규모 모델 학습을 위한 프레임워크 사용 경험 (예: DeepSpeed) LLM 기반 제품 개발 경험 AI 및 NLP 관련 국제 학회 논문 게재 경험 필요 기술 스택: AI/인공지능 NLP TensorFlow PyTorch 출처:  JOBKOREA.CO.KR'),\n",
       " Document(metadata={}, page_content='3. 삼정KPMG 조건: ML/AI/NL/LLM 분야 경력자 관련 프로젝트 경험 및 성과 보유자 우대조건: 금융 및 컨설팅 업계 경험자 데이터 분석 및 처리 능력 우수자 필요 기술 스택: Machine Learning AI Natural Language Processing LLM 출처:  JOBKOREA.CO.KR'),\n",
       " Document(metadata={}, page_content='4. 아이브릭스 조건: LLM 서비스 구축 및 운영 경험 AI 모델 개발 및 최적화 능력 우대조건: 대규모 데이터 처리 경험 클라우드 환경에서의 서비스 개발 경험 필요 기술 스택: AI/인공지능 Machine Learning Python TensorFlow 출처:  잡코리아'),\n",
       " Document(metadata={}, page_content='5. 비전스페이스 조건: 생성형 AI, LLM, RAG R&D 개발 경험 로봇산업 관련 프로젝트 참여 경험 우대조건: 데이터 사이언스 및 분석 능력 우수자 유연근무제 활용 가능자 필요 기술 스택: 데이터 분석 AI/인공지능 Machine Learning Python 출처:  JOBKOREA.CO.KR'),\n",
       " Document(metadata={}, page_content='6. 진인프라 조건: LLM 개발 경력자 중견 IT 기업에서의 프로젝트 경험 우대조건: AI 및 머신러닝 분야 전문성 보유자 팀 협업 및 커뮤니케이션 능력 우수자 필요 기술 스택: LLM 개발 AI/인공지능 Machine Learning Python')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = [Document(page_content=info) for info in company_info_list]\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩 모델 생성\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(model='text-embedding-3-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9dee60f5-6a64-47e0-b082-249cafcc47e3',\n",
       " 'f8c9192c-c7d7-4e77-b276-0fe00a99ee19',\n",
       " '3a396134-6aa6-4549-80a4-6f2ec8644de5',\n",
       " 'ff9bd2b4-4b2a-4571-9edf-8d5fe64c2a53',\n",
       " 'ddd57042-b3bd-40d5-b2ac-d8d1f055ade4',\n",
       " 'fa4db59d-5db7-4452-ac4d-27961e7f5fdb']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_chroma.vectorstores import Chroma\n",
    "vector_store_company = Chroma(\n",
    "    embedding_function=embedding_model,\n",
    "    persist_directory='./data/company_info_vector_store'\n",
    ")\n",
    "vector_store_company.add_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 내 정보 벡터 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'이력서 1. 인적사항 - 이름: 이재혁 - 성별: 남자 - 생년월일: 2000년생 - 병역사항: 현역 만기 전역 2. 학력 - 학사 학위 취득  3. 경력 및 교육 - 풀스택 개발자 수료 과정 이수 - LLM서비스 개발자 수료중  4. 포트폴리오 1) 프로젝트 경험 - 대실 예약 시스템 개발 (Spring Boot, React, MySQL)   - Spring Boot 기반의 백엔드 API 개발   - React를 활용한 프론트엔드 구현   - MySQL을 이용한 데이터베이스 설계 및 최적화   - Docker를 활용한 배포 환경 구성 - CI/CD 자동화 구축 (Jenkins, Docker, GitHub Actions)   - Jenkins와 GitHub Actions를 활용한 배포 자동화   - Docker 컨테이너 기반으로 프론트엔드 및 백엔드 개별 배포   - 코드 변경 시 자동 빌드 및 테스트 실행 - 머신러닝 및 딥러닝 모델 개발 및 배포 (Python, TensorFlow, PyTorch, Streamlit, XGBoost, RandomForest, Transformer, LangChain)   - 기대수명 예측 및 음악 사이트 이탈률 분석 프로젝트 진행   - Streamlit을 활용한 인터랙티브 웹 애플리케이션 구현   - XGBoost 및 랜덤 포레스트를 활용한 회귀 및 분류 모델 개발   - TensorFlow 및 PyTorch를 활용한 딥러닝 모델 구축 및 최적화   - CNN, RNN을 활용한 이미지 및 시계열 데이터 분석 경험   - Transformer 기반 자연어 처리 모델 개발 및 최적화   - LangChain을 활용한 LLM 기반 응용 서비스 개발 및 데이터 파이프라인 구성 2) 보유 기술 - 프론트엔드: React, JavaScript, TypeScript - 백엔드: Spring Boot, Java - 데이터베이스: MySQL, PostgreSQL - 배포 및 운영: Docker, Jenkins, GitHub Actions - 머신러닝 & 딥러닝: Python, XGBoost, RandomForest, TensorFlow, PyTorch, CNN, RNN, Transformer, LangChain, Streamlit - 기타: Git, Linux, RESTful API 설계 '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./data/job_application.txt' , 'r', encoding='utf-8') as f:\n",
    "    my_info = f.read()\n",
    "\n",
    "my_info = my_info.replace('\\n\\n', ' ')\n",
    "my_info = my_info.replace('\\n', ' ')\n",
    "my_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='이력서 1. 인적사항 - 이름: 이재혁 - 성별: 남자 - 생년월일: 2000년생 - 병역사항: 현역 만기 전역 2. 학력 - 학사 학위 취득  3. 경력 및 교육 - 풀스택 개발자 수료 과정 이수 - LLM서비스 개발자 수료중  4. 포트폴리오 1) 프로젝트 경험 - 대실 예약 시스템 개발 (Spring Boot, React, MySQL)   - Spring Boot 기반의 백엔드 API 개발   - React를 활용한 프론트엔드 구현   - MySQL을 이용한 데이터베이스 설계 및 최적화   - Docker를 활용한 배포 환경 구성 - CI/CD 자동화 구축 (Jenkins, Docker, GitHub Actions)   - Jenkins와 GitHub Actions를 활용한 배포 자동화   - Docker 컨테이너 기반으로 프론트엔드 및 백엔드 개별 배포   - 코드 변경 시 자동 빌드 및 테스트 실행 - 머신러닝 및 딥러닝 모델 개발 및 배포 (Python, TensorFlow, PyTorch, Streamlit, XGBoost, RandomForest, Transformer, LangChain)   - 기대수명 예측 및 음악 사이트 이탈률 분석 프로젝트 진행   - Streamlit을 활용한 인터랙티브 웹 애플리케이션 구현   - XGBoost 및 랜덤 포레스트를 활용한 회귀 및 분류 모델 개발   - TensorFlow 및 PyTorch를 활용한 딥러닝 모델 구축 및 최적화   - CNN, RNN을 활용한 이미지 및 시계열 데이터 분석 경험   - Transformer 기반 자연어 처리 모델 개발 및 최적화   - LangChain을 활용한 LLM 기반 응용 서비스 개발 및 데이터 파이프라인 구성 2) 보유 기술 - 프론트엔드: React, JavaScript, TypeScript - 백엔드: Spring Boot, Java - 데이터베이스: MySQL, PostgreSQL - 배포 및 운영: Docker, Jenkins, GitHub Actions - 머신러닝 & 딥러닝: Python, XGBoost, RandomForest, TensorFlow, PyTorch, CNN, RNN, Transformer, LangChain, Streamlit - 기타: Git, Linux, RESTful API 설계 ')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = [Document(page_content=my_info)]\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='1. 이스트소프트 조건: LLM/NLP 관련 분야 석사 학위 이상 또는 그에 준하는 3년 이상의 경력 알고리즘과 머신러닝, LLM 분야에 대한 깊은 이해 Pytorch를 활용한 코드 작성 및 실험 능숙 우대조건: LLM 학습 및 최적화 경험 분산 학습 시스템 구축 경험 GPU 자원 최적화 경험 모델 경량화 및 추론 성능 최적화 경험 AWS, Azure 등 클라우드 플랫폼 사용 경험 필요 기술 스택: Git AI/인공지능 Linux Machine Learning Deep Learning AWS TensorFlow Python Azure PyTorch 출처:  JOBKOREA.CO.KR'),\n",
       " Document(metadata={}, page_content='2. 업스테이지 조건: LLM 알고리즘/데이터 연구·개발 경험 LLM Post-training 경험 다양한 협업 환경에서의 원활한 의사소통 능력 우대조건: 대규모 모델 학습을 위한 프레임워크 사용 경험 (예: DeepSpeed) LLM 기반 제품 개발 경험 AI 및 NLP 관련 국제 학회 논문 게재 경험 필요 기술 스택: AI/인공지능 NLP TensorFlow PyTorch 출처:  JOBKOREA.CO.KR'),\n",
       " Document(metadata={}, page_content='3. 삼정KPMG 조건: ML/AI/NL/LLM 분야 경력자 관련 프로젝트 경험 및 성과 보유자 우대조건: 금융 및 컨설팅 업계 경험자 데이터 분석 및 처리 능력 우수자 필요 기술 스택: Machine Learning AI Natural Language Processing LLM 출처:  JOBKOREA.CO.KR'),\n",
       " Document(metadata={}, page_content='4. 아이브릭스 조건: LLM 서비스 구축 및 운영 경험 AI 모델 개발 및 최적화 능력 우대조건: 대규모 데이터 처리 경험 클라우드 환경에서의 서비스 개발 경험 필요 기술 스택: AI/인공지능 Machine Learning Python TensorFlow 출처:  잡코리아'),\n",
       " Document(metadata={}, page_content='5. 비전스페이스 조건: 생성형 AI, LLM, RAG R&D 개발 경험 로봇산업 관련 프로젝트 참여 경험 우대조건: 데이터 사이언스 및 분석 능력 우수자 유연근무제 활용 가능자 필요 기술 스택: 데이터 분석 AI/인공지능 Machine Learning Python 출처:  JOBKOREA.CO.KR'),\n",
       " Document(metadata={}, page_content='6. 진인프라 조건: LLM 개발 경력자 중견 IT 기업에서의 프로젝트 경험 우대조건: AI 및 머신러닝 분야 전문성 보유자 팀 협업 및 커뮤니케이션 능력 우수자 필요 기술 스택: LLM 개발 AI/인공지능 Machine Learning Python'),\n",
       " Document(metadata={}, page_content='이력서 1. 인적사항 - 이름: 이재혁 - 성별: 남자 - 생년월일: 2000년생 - 병역사항: 현역 만기 전역 2. 학력 - 학사 학위 취득  3. 경력 및 교육 - 풀스택'),\n",
       " Document(metadata={}, page_content='3. 경력 및 교육 - 풀스택 개발자 수료 과정 이수 - LLM서비스 개발자 수료중  4. 포트폴리오 1) 프로젝트 경험 - 대실 예약 시스템 개발 (Spring Boot,'),\n",
       " Document(metadata={}, page_content='개발 (Spring Boot, React, MySQL)   - Spring Boot 기반의 백엔드 API 개발   - React를 활용한 프론트엔드 구현   - MySQL을'),\n",
       " Document(metadata={}, page_content='프론트엔드 구현   - MySQL을 이용한 데이터베이스 설계 및 최적화   - Docker를 활용한 배포 환경 구성 - CI/CD 자동화 구축 (Jenkins, Docker,'),\n",
       " Document(metadata={}, page_content='(Jenkins, Docker, GitHub Actions)   - Jenkins와 GitHub Actions를 활용한 배포 자동화   - Docker 컨테이너 기반으로'),\n",
       " Document(metadata={}, page_content='- Docker 컨테이너 기반으로 프론트엔드 및 백엔드 개별 배포   - 코드 변경 시 자동 빌드 및 테스트 실행 - 머신러닝 및 딥러닝 모델 개발 및 배포 (Python,'),\n",
       " Document(metadata={}, page_content='모델 개발 및 배포 (Python, TensorFlow, PyTorch, Streamlit, XGBoost, RandomForest, Transformer, LangChain)'),\n",
       " Document(metadata={}, page_content='LangChain)   - 기대수명 예측 및 음악 사이트 이탈률 분석 프로젝트 진행   - Streamlit을 활용한 인터랙티브 웹 애플리케이션 구현   - XGBoost 및'),\n",
       " Document(metadata={}, page_content='구현   - XGBoost 및 랜덤 포레스트를 활용한 회귀 및 분류 모델 개발   - TensorFlow 및 PyTorch를 활용한 딥러닝 모델 구축 및 최적화   - CNN,'),\n",
       " Document(metadata={}, page_content='구축 및 최적화   - CNN, RNN을 활용한 이미지 및 시계열 데이터 분석 경험   - Transformer 기반 자연어 처리 모델 개발 및 최적화   - LangChain을'),\n",
       " Document(metadata={}, page_content='최적화   - LangChain을 활용한 LLM 기반 응용 서비스 개발 및 데이터 파이프라인 구성 2) 보유 기술 - 프론트엔드: React, JavaScript,'),\n",
       " Document(metadata={}, page_content='React, JavaScript, TypeScript - 백엔드: Spring Boot, Java - 데이터베이스: MySQL, PostgreSQL - 배포 및 운영:'),\n",
       " Document(metadata={}, page_content='- 배포 및 운영: Docker, Jenkins, GitHub Actions - 머신러닝 & 딥러닝: Python, XGBoost, RandomForest, TensorFlow,'),\n",
       " Document(metadata={}, page_content='TensorFlow, PyTorch, CNN, RNN, Transformer, LangChain, Streamlit - 기타: Git, Linux, RESTful API 설계')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100, # 각 chunk의 최대 문자 수\n",
    "    chunk_overlap=20 # 인접한 텍스트 조각 간 겹치는 문자 수 (기본값: 200)\n",
    "                        # 텍스트 분할 구분자 우선순위 (기본값: ['\\n\\n', '\\n', ' ', ''])\n",
    ")\n",
    "docs = splitter.split_documents(docs)\n",
    "documents.extend(docs)\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6c4650fc-119d-4b30-bb28-bd3bdfdb4b9a',\n",
       " 'b50c2521-e423-4c8b-b010-c4fbe0d773f5',\n",
       " '50e9f4d5-0ce9-4600-bd0b-ca93b6726a1e',\n",
       " '1a2c80ec-0331-4d93-a5d7-61ef0c0ce6a0',\n",
       " '6f037cdf-490c-469b-bfa2-394489f24620',\n",
       " '8a3987e7-f5ba-452e-9253-8d78eb7838f4',\n",
       " '9ec71d29-2a60-4254-9735-e04bcbe11753',\n",
       " 'b00004dc-21cf-4843-af7d-de05d8747858',\n",
       " '1b45d51b-ab78-42cb-a3f3-2160dd1587fe',\n",
       " '19c0e7e2-77d2-4a23-902b-0642aeb0126d',\n",
       " '071b6a9d-718f-4819-b175-ac61e0034f6d',\n",
       " '6406a011-08e4-4b6f-a4d9-ff60025ed371',\n",
       " '194a15e9-0d97-49d2-8c96-d5b2f03f2177',\n",
       " '4bc9c1d8-fc63-4932-a8e6-af21eeb9b6f4',\n",
       " '5f8a7d46-1f0a-4b71-b7a0-b2ebe675463e',\n",
       " '203298cd-6ffd-418c-ab8d-29107c6909cf',\n",
       " 'cd552eed-9624-424c-8c17-261f51a8f31e',\n",
       " '63680175-0348-487c-8793-f744d2b1fb5b',\n",
       " '183a2426-4187-42b4-8304-aab4b6602ebf',\n",
       " '0e860ded-2f3b-48be-bba7-06c8ec7dca3f']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store_company.add_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "# llm 설정 (모델 생성)\n",
    "model = ChatOpenAI(\n",
    "    model = 'gpt-4o-mini',\n",
    "    temperature=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate([\n",
    "    ('system',\"\"\"\n",
    "    너는 면접관이야 \n",
    "    \n",
    "    다음 '지원자의 정보'를 바탕으로 '회사 정보'를 참고하여 지원자에게 알맞는 질문을 해서 모의 면접을 진행해줘.\n",
    "    회사내 필요한 기술스택 혹은 정보에서 담겨진 궁금증 다 물어봐줘\n",
    "    면접관의 성격은 친절하거나 까칠하거나 너가 편한대로 해도 무방해\n",
    "    면접관의 직업은 현직자이거나 임원 혹은 프로젝트매니저 아무거나 상관없어\n",
    "    \n",
    "    ---\n",
    "    지원자의 정보 : {context}\n",
    "    문서 : {context}\n",
    "    ---\n",
    "    <면접 흐름>\n",
    "    면접관이 먼저 질문 후 지원자가 답변을 하게 됩니다.\n",
    "    면접관 : [정보와 문서를 토대로 나온 질문]\n",
    "    지원자 : {query}\n",
    "    이 흐름을 3번 반복해.\n",
    "    \n",
    "    <3번 질문 후 면접 결과 및 피드백>\n",
    "    면접 결과와 피드백을 해줘.\n",
    "    \n",
    "    <답변에 대한 조건>\n",
    "    - 회사의 요구사항에 대해 질문 할 것\n",
    "    - 지원자의 정보에 대한 질문을 할 것\n",
    "    \"\"\", ),\n",
    "    MessagesPlaceholder(variable_name='history'),\n",
    "    ('human','{query}')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store_company.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "좋습니다. 면접을 시작하겠습니다. AI 및 LLM(대형 언어 모델) 관련 질문에 대해 답변해 주시기 바랍니다.\n",
      "\n",
      "1. LLM이란 무엇이며, 그 기본 원리는 무엇인가요?\n",
      "\n",
      "2. LLM의 학습 과정에서 사용되는 데이터의 종류와 그 중요성에 대해 설명해 주세요.\n",
      "\n",
      "3. LLM의 주요 활용 사례는 무엇인지, 그리고 그로 인해 발생할 수 있는 윤리적 문제는 무엇인지 논의해 주세요.\n",
      "\n",
      "4. LLM의 성능을 평가하는 방법에는 어떤 것들이 있으며, 어떤 지표가 가장 중요한지 설명해 주세요.\n",
      "\n",
      "5. 최근 LLM의 발전 방향이나 트렌드 중 하나를 설명하고, 그 이유에 대해 논의해 주세요.\n",
      "\n",
      "6. LLM을 사용할 때 발생할 수 있는 편향(bias) 문제에 대해 어떻게 접근해야 한다고 생각하시나요?\n",
      "\n",
      "7. LLM의 발전이 향후 산업에 미치는 영향에 대해 어떻게 예측하시나요?\n",
      "\n",
      "이 질문들에 대한 답변을 부탁드립니다.\n",
      "안녕하세요\n",
      "안녕하세요! 면접에 참여해 주셔서 감사합니다. 질문에 대한 답변을 시작해 주시면 좋겠습니다. 첫 번째 질문입니다:\n",
      "\n",
      "1. LLM이란 무엇이며, 그 기본 원리는 무엇인가요?\n",
      "몰라요\n",
      "괜찮습니다. LLM(대형 언어 모델)에 대한 이해가 부족하더라도 다른 질문에 대해 답변해 보실 수 있습니다. 다음 질문으로 넘어가겠습니다.\n",
      "\n",
      "2. LLM의 학습 과정에서 사용되는 데이터의 종류와 그 중요성에 대해 설명해 주세요.\n",
      "몰라요\n",
      "이해합니다. 특정 주제에 대한 지식이 부족할 수 있습니다. 다음 질문으로 넘어가겠습니다.\n",
      "\n",
      "3. LLM의 주요 활용 사례는 무엇인지, 그리고 그로 인해 발생할 수 있는 윤리적 문제는 무엇인지 논의해 주세요.\n",
      "몰라요\n",
      "알겠습니다. 여러 질문에 대한 답변이 어렵다면, 다른 접근을 시도해 보겠습니다.\n",
      "\n",
      "면접의 목적은 지원자의 경험과 지식을 평가하는 것이지만, 때로는 특정 주제에 대한 지식이 부족할 수 있습니다. \n",
      "\n",
      "이제 면접을 마무리하겠습니다. \n",
      "\n",
      "**면접 결과 및 피드백:**\n",
      "\n",
      "- 지원자는 AI 및 LLM 관련 질문에 대한 답변을 하지 못했습니다. 이는 해당 분야에 대한 지식이 부족하다는 것을 나타냅니다.\n",
      "- LLM과 관련된 기본 개념, 활용 사례, 윤리적 문제 등에 대한 이해가 필요합니다.\n",
      "- 향후 AI 및 LLM 관련 자료를 학습하고, 관련 프로젝트나 경험을 쌓는 것이 좋겠습니다.\n",
      "\n",
      "지금까지 면접에 참여해 주셔서 감사합니다. 추가로 궁금한 점이나 질문이 있다면 언제든지 말씀해 주세요.\n",
      "종료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 2, updating n_results = 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**면접 결과 및 피드백:**\n",
      "\n",
      "- **기술 역량 평가 점수**: 2/10\n",
      "- **합격 여부**: 불합격\n",
      "\n",
      "**피드백:**\n",
      "\n",
      "지원자는 AI 및 LLM(대형 언어 모델)에 대한 질문에 대해 전혀 답변하지 못했습니다. 이는 해당 분야에 대한 기본적인 이해가 부족하다는 것을 나타냅니다. 면접에서 다룬 질문들은 LLM의 기본 개념, 학습 과정, 활용 사례, 윤리적 문제 등으로, 이들에 대한 지식은 AI 및 머신러닝 분야에서 필수적인 요소입니다.\n",
      "\n",
      "이력서에 나와 있는 다양한 기술과 프로젝트 경험은 긍정적이지만, 면접에서의 답변 부족은 지원자의 기술 역량에 대한 신뢰를 크게 저하시켰습니다. LLM 및 AI 관련 지식이 부족한 상태에서는 해당 분야에서의 역할을 수행하기 어려울 것으로 판단됩니다.\n",
      "\n",
      "향후 AI 및 LLM 관련 자료를 학습하고, 관련 프로젝트나 경험을 쌓는 것이 필요합니다. 이러한 준비가 이루어진 후 다시 지원하는 것을 권장합니다. \n",
      "\n",
      "감사합니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "sys_inst = \"\"\"\n",
    "당신은 면접관입니다. \n",
    "지원자에게 질문을 여러번 진행하고 질문을 다 했으면 면접 결과와 피드백을 해주세요.\n",
    "AI, LLM 관련한 질문을 해주세요.\n",
    "\"\"\"\n",
    "msgs = [SystemMessage(sys_inst)]\n",
    "res = model.invoke(msgs)\n",
    "msgs.append(res)\n",
    "print()\n",
    "print(res.content)\n",
    "\n",
    "while True:\n",
    "    reply = input()\n",
    "    print(reply)\n",
    "    msgs.append(HumanMessage(reply))\n",
    "    if \"종료\" in reply:\n",
    "        break\n",
    "    res = model.invoke(msgs)\n",
    "    msgs.append(res)\n",
    "    print(res.content)\n",
    "    \n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    다음 '질문'에 대해 '문서'의 내용만을 참고하여 '평가'을 생성해 주세요.\n",
    "    질문 : {question}\n",
    "    문서 : {context}\n",
    "    대화 내용 : \n",
    "    \"\"\" + \"\\n\".join([msg.content for msg in msgs]),\n",
    "    input_variables=[\"question\", \"context\"],\n",
    ")\n",
    "\n",
    "retriever = vector_store.as_retriever()\n",
    "chain = RetrievalQA.from_chain_type(\n",
    "    llm=model,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vector_store.as_retriever(),\n",
    "    chain_type_kwargs={\"prompt\": prompt},\n",
    ")\n",
    "\n",
    "res = chain.invoke(\"대화 내용을 토대로 면접관의 입장으로써 지원자의 기술 역량에 대해 점수와 합격 여부를 포함한 피드백 및 평가를 진행해주세요\")\n",
    "\n",
    "print(res['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Missing some input keys: {'history', 'query'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m history \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 2\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mqa_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m안녕하세요\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhistory\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ljh10\\anaconda3\\envs\\vectordb_env\\lib\\site-packages\\langchain\\chains\\base.py:170\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    169\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    171\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[1;32mc:\\Users\\ljh10\\anaconda3\\envs\\vectordb_env\\lib\\site-packages\\langchain\\chains\\base.py:160\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[0;32m    159\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 160\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    165\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    166\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[0;32m    167\u001b[0m     )\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\ljh10\\anaconda3\\envs\\vectordb_env\\lib\\site-packages\\langchain\\chains\\retrieval_qa\\base.py:154\u001b[0m, in \u001b[0;36mBaseRetrievalQA._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    153\u001b[0m     docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_docs(question)  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 154\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcombine_documents_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_documents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_run_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_source_documents:\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key: answer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource_documents\u001b[39m\u001b[38;5;124m\"\u001b[39m: docs}\n",
      "File \u001b[1;32mc:\\Users\\ljh10\\anaconda3\\envs\\vectordb_env\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:181\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    180\u001b[0m     emit_warning()\n\u001b[1;32m--> 181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ljh10\\anaconda3\\envs\\vectordb_env\\lib\\site-packages\\langchain\\chains\\base.py:611\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[0;32m    606\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[0;32m    607\u001b[0m         _output_key\n\u001b[0;32m    608\u001b[0m     ]\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m--> 611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[0;32m    612\u001b[0m         _output_key\n\u001b[0;32m    613\u001b[0m     ]\n\u001b[0;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m    616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    617\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supported with either positional arguments or keyword arguments,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    618\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but none were provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    619\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\ljh10\\anaconda3\\envs\\vectordb_env\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:181\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    180\u001b[0m     emit_warning()\n\u001b[1;32m--> 181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ljh10\\anaconda3\\envs\\vectordb_env\\lib\\site-packages\\langchain\\chains\\base.py:389\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \n\u001b[0;32m    359\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    382\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[0;32m    387\u001b[0m }\n\u001b[1;32m--> 389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ljh10\\anaconda3\\envs\\vectordb_env\\lib\\site-packages\\langchain\\chains\\base.py:170\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    169\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    171\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[1;32mc:\\Users\\ljh10\\anaconda3\\envs\\vectordb_env\\lib\\site-packages\\langchain\\chains\\base.py:158\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    153\u001b[0m     inputs,\n\u001b[0;32m    154\u001b[0m     run_id,\n\u001b[0;32m    155\u001b[0m     name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[0;32m    156\u001b[0m )\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 158\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    159\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    165\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    166\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[0;32m    167\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\ljh10\\anaconda3\\envs\\vectordb_env\\lib\\site-packages\\langchain\\chains\\base.py:290\u001b[0m, in \u001b[0;36mChain._validate_inputs\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    288\u001b[0m missing_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_keys)\u001b[38;5;241m.\u001b[39mdifference(inputs)\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_keys:\n\u001b[1;32m--> 290\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing some input keys: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Missing some input keys: {'history', 'query'}"
     ]
    }
   ],
   "source": [
    "history = []\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vectordb_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
