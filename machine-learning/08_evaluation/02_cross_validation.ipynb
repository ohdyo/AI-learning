{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 교차검증 (Cross Validation)\n",
    "- 모델을 더욱 신뢰성 있게 평가하는 방법\n",
    "- 데이터셋을 여러 개로 나누고, 각 부분이 한번씩 검증 데이터로 사용되도록 하는 방법\n",
    "- 훈련-검증을 반복하면서 학습을 진행\n",
    "- 과대적합 방지 효과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_input, iris_target = load_iris(return_X_y=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function unique at 0x0000020736E33420>\n",
      "<function unique at 0x0000020736E33420>\n",
      "<function unique at 0x0000020736E33420>\n",
      "<function unique at 0x0000020736E33420>\n",
      "<function unique at 0x0000020736E33420>\n",
      "훈련별 정확도:  [1.0, 1.0, 0.9333333333333333, 0.9666666666666667, 0.9666666666666667]\n",
      "분류모델 정확도:  0.9733333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 교차검증 KFold 객체 생성\n",
    "lr_clf = LogisticRegression()\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42) #n_splits : 폴드 개수, shuffles : 폴드로 나누기 전에 섞을건지 여부 (디폴트 : False)\n",
    "\n",
    "# k번 반복하면서 평가한 정확도를 저장할 배열\n",
    "cv_accuracy = []\n",
    "\n",
    "for train_index,val_index in kfold.split(iris_input):\n",
    "    X_train, y_train = iris_input[train_index], iris_target[train_index]\n",
    "    X_val , y_val = iris_input[val_index], iris_target[val_index]\n",
    "\n",
    "    print(np.unique)\n",
    "    \n",
    "    lr_clf.fit(X_train, y_train)    # 모델 학습\n",
    "    y_pred = lr_clf.predict(X_val)  # 검증 데이터로 예측\n",
    "    acc_score = accuracy_score(y_val, y_pred)   # 정확도 계산\n",
    "    cv_accuracy.append(acc_score)   # cv_accuracy 배열에 정확도 추가\n",
    "    \n",
    "print('훈련별 정확도: ', cv_accuracy)\n",
    "print('분류모델 정확도: ', np.mean(cv_accuracy))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([40, 40, 40]))\n",
      "(array([0, 1, 2]), array([10, 10, 10]))\n",
      "=================\n",
      "(array([0, 1, 2]), array([40, 40, 40]))\n",
      "(array([0, 1, 2]), array([10, 10, 10]))\n",
      "=================\n",
      "(array([0, 1, 2]), array([40, 40, 40]))\n",
      "(array([0, 1, 2]), array([10, 10, 10]))\n",
      "=================\n",
      "(array([0, 1, 2]), array([40, 40, 40]))\n",
      "(array([0, 1, 2]), array([10, 10, 10]))\n",
      "=================\n",
      "(array([0, 1, 2]), array([40, 40, 40]))\n",
      "(array([0, 1, 2]), array([10, 10, 10]))\n",
      "=================\n",
      "훈련별 정확도:  [0.9666666666666667, 1.0, 0.9333333333333333, 0.9666666666666667, 1.0]\n",
      "분류모델 정확도:  0.9733333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ljh10\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Stratified-K-Fold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 교차검증 StratifiedKFold 객체 생성\n",
    "lr_clf = LogisticRegression()\n",
    "stratifiedKFold_kfold = StratifiedKFold(n_splits=5) #n_splits : 폴드 개수\n",
    "\n",
    "# k번 반복하면서 평가한 정확도를 저장할 배열\n",
    "cv_accuracy = []\n",
    "\n",
    "for train_index,val_index in stratifiedKFold_kfold.split(iris_input,iris_target):\n",
    "    X_train, y_train = iris_input[train_index], iris_target[train_index]\n",
    "    X_val , y_val = iris_input[val_index], iris_target[val_index]\n",
    "\n",
    "    print(np.unique(y_train, return_counts=True))\n",
    "    print(np.unique(y_val,return_counts=True))\n",
    "    print('=================')\n",
    "    \n",
    "    lr_clf.fit(X_train, y_train)    # 모델 학습\n",
    "    y_pred = lr_clf.predict(X_val)  # 검증 데이터로 예측\n",
    "    acc_score = accuracy_score(y_val, y_pred)   # 정확도 계산\n",
    "    cv_accuracy.append(acc_score)   # cv_accuracy 배열에 정확도 추가\n",
    "    \n",
    "print('훈련별 정확도: ', cv_accuracy)\n",
    "print('분류모델 정확도: ', np.mean(cv_accuracy))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cross_val_score\n",
    "- 교차 검증을 통해 모델 성능을 평가하는 함수\n",
    "- 내부적으로 지정한 횟수만큼 학습/검증을 나누어 반복 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'scoring' parameter of cross_val_score must be a str among {'adjusted_rand_score', 'neg_mean_gamma_deviance', 'jaccard_samples', 'fowlkes_mallows_score', 'precision_samples', 'neg_mean_absolute_percentage_error', 'precision_weighted', 'neg_mean_squared_error', 'explained_variance', 'recall_weighted', 'balanced_accuracy', 'jaccard_weighted', 'precision_micro', 'top_k_accuracy', 'v_measure_score', 'f1_weighted', 'roc_auc_ovo_weighted', 'roc_auc_ovr_weighted', 'accuracy', 'average_precision', 'precision_macro', 'neg_mean_poisson_deviance', 'roc_auc_ovo', 'homogeneity_score', 'neg_mean_absolute_error', 'f1_macro', 'mutual_info_score', 'recall_micro', 'f1', 'r2', 'jaccard', 'f1_samples', 'roc_auc_ovr', 'f1_micro', 'jaccard_macro', 'normalized_mutual_info_score', 'recall', 'neg_log_loss', 'neg_max_error', 'roc_auc', 'neg_root_mean_squared_log_error', 'adjusted_mutual_info_score', 'recall_samples', 'recall_macro', 'matthews_corrcoef', 'positive_likelihood_ratio', 'precision', 'neg_median_absolute_error', 'd2_absolute_error_score', 'neg_mean_squared_log_error', 'neg_root_mean_squared_error', 'neg_negative_likelihood_ratio', 'rand_score', 'completeness_score', 'jaccard_micro', 'neg_brier_score'}, a callable or None. Got 'accurcy' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 9\u001b[0m\n\u001b[0;32m      3\u001b[0m lr_clf \u001b[38;5;241m=\u001b[39m LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# 첫 번째 인자 : 모델\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# 두 번째 인자 : 입력 데이터\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# 세 번째 인자 : 라벨 데이터\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# scoreing: 평가 지표 (accuracy, precisdion, recall, f1)\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr_clf\u001b[49m\u001b[43m,\u001b[49m\u001b[43miris_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43miris_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccurcy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m훈련별 정확도: \u001b[39m\u001b[38;5;124m'\u001b[39m, scores)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m모델 정확도: \u001b[39m\u001b[38;5;124m'\u001b[39m, np\u001b[38;5;241m.\u001b[39mmean(scores))\n",
      "File \u001b[1;32mc:\\Users\\ljh10\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:206\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m to_ignore \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcls\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    204\u001b[0m params \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m params\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m to_ignore}\n\u001b[1;32m--> 206\u001b[0m \u001b[43mvalidate_parameter_constraints\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparameter_constraints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaller_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__qualname__\u001b[39;49m\n\u001b[0;32m    208\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n",
      "File \u001b[1;32mc:\\Users\\ljh10\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:98\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[1;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     constraints_str \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(c)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mconstraints[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     95\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     96\u001b[0m     )\n\u001b[1;32m---> 98\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m InvalidParameterError(\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaller_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_val\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    101\u001b[0m )\n",
      "\u001b[1;31mInvalidParameterError\u001b[0m: The 'scoring' parameter of cross_val_score must be a str among {'adjusted_rand_score', 'neg_mean_gamma_deviance', 'jaccard_samples', 'fowlkes_mallows_score', 'precision_samples', 'neg_mean_absolute_percentage_error', 'precision_weighted', 'neg_mean_squared_error', 'explained_variance', 'recall_weighted', 'balanced_accuracy', 'jaccard_weighted', 'precision_micro', 'top_k_accuracy', 'v_measure_score', 'f1_weighted', 'roc_auc_ovo_weighted', 'roc_auc_ovr_weighted', 'accuracy', 'average_precision', 'precision_macro', 'neg_mean_poisson_deviance', 'roc_auc_ovo', 'homogeneity_score', 'neg_mean_absolute_error', 'f1_macro', 'mutual_info_score', 'recall_micro', 'f1', 'r2', 'jaccard', 'f1_samples', 'roc_auc_ovr', 'f1_micro', 'jaccard_macro', 'normalized_mutual_info_score', 'recall', 'neg_log_loss', 'neg_max_error', 'roc_auc', 'neg_root_mean_squared_log_error', 'adjusted_mutual_info_score', 'recall_samples', 'recall_macro', 'matthews_corrcoef', 'positive_likelihood_ratio', 'precision', 'neg_median_absolute_error', 'd2_absolute_error_score', 'neg_mean_squared_log_error', 'neg_root_mean_squared_error', 'neg_negative_likelihood_ratio', 'rand_score', 'completeness_score', 'jaccard_micro', 'neg_brier_score'}, a callable or None. Got 'accurcy' instead."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "lr_clf = LogisticRegression(max_iter=100)\n",
    "\n",
    "# 첫 번째 인자 : 모델\n",
    "# 두 번째 인자 : 입력 데이터\n",
    "# 세 번째 인자 : 라벨 데이터\n",
    "# scoreing: 평가 지표 (accuracy, precisdion, recall, f1)\n",
    "scores = cross_val_score(lr_clf,iris_input,iris_target,scoring='accurcy',cv=5)\n",
    "\n",
    "print('훈련별 정확도: ', scores)\n",
    "print('모델 정확도: ', np.mean(scores))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pystudy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
