{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameter Tuning\n",
    "- hyper parameter : 모델 설정과 관려해 직접 지정할 수 있는 매개변수\n",
    "- model parameter : 회귀계수(가중치), 절편 등 모델의 학습 대상이 되는 변수\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적의 파라미터 :  {'n_neighbors': 7}\n",
      "최적화된 모델 객체 :  KNeighborsClassifier(n_neighbors=7)\n",
      "최적화된 점수:  0.9800000000000001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 데이터 로드\n",
    "iris_input, iris_target = load_iris(return_X_y=True)\n",
    "\n",
    "# 모델 생성\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# 테스트할 파라미터 값\n",
    "params = {\n",
    "    'n_neighbors' : range(1,13,2)\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(knn, params, scoring='accuracy', cv=5)\n",
    "grid.fit(iris_input, iris_target)\n",
    "\n",
    "print('최적의 파라미터 : ', grid.best_params_)\n",
    "print('최적화된 모델 객체 : ', grid.best_estimator_)\n",
    "print('최적화된 점수: ', grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=7)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>KNeighborsClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\">?<span>Documentation for KNeighborsClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>KNeighborsClassifier(n_neighbors=7)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_knn = grid.best_estimator_\n",
    "best_knn.score(iris_input,iris_target)\n",
    "best_knn.fit(iris_input,iris_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomSearchCV\n",
    "- 하이퍼 파라미터의 값 목록이나 값의 범위를 제공하는데, 이 범위 중에 랜덤하게 값을 뽑아내 최적의 하이퍼 파라미터 조합을 찾는다.\n",
    "    - 탐색범위가 넓을 때 짧은 시간 내에 좋은 결과를 얻을 수 있다.\n",
    "    - 랜덤하게 값을 추출해 계산하므로, 전역 최적값을 놓칠 수 있다.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적의 파라미터 :  {'n_neighbors': 5}\n",
      "최적화된 모델 객체 :  KNeighborsClassifier()\n",
      "최적화된 점수:  0.9733333333333334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00103683, 0.00221806, 0.00065722, 0.00082235, 0.00030198,\n",
       "        0.0004209 , 0.00021024, 0.00020127, 0.00032201, 0.        ]),\n",
       " 'std_fit_time': array([0.00110114, 0.00277113, 0.00016381, 0.00082774, 0.00060396,\n",
       "        0.00084181, 0.00042048, 0.00040255, 0.00064402, 0.        ]),\n",
       " 'mean_score_time': array([0.0053565 , 0.00224547, 0.00341806, 0.01251373, 0.00343208,\n",
       "        0.00341878, 0.01077733, 0.01056056, 0.001896  , 0.00322952]),\n",
       " 'std_score_time': array([0.00383794, 0.00308659, 0.00026281, 0.00089588, 0.00354499,\n",
       "        0.00265435, 0.00240061, 0.00312583, 0.00155373, 0.00397133]),\n",
       " 'param_n_neighbors': masked_array(data=[57, 23, 21, 83, 5, 55, 77, 63, 45, 9],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value=999999),\n",
       " 'params': [{'n_neighbors': 57},\n",
       "  {'n_neighbors': 23},\n",
       "  {'n_neighbors': 21},\n",
       "  {'n_neighbors': 83},\n",
       "  {'n_neighbors': 5},\n",
       "  {'n_neighbors': 55},\n",
       "  {'n_neighbors': 77},\n",
       "  {'n_neighbors': 63},\n",
       "  {'n_neighbors': 45},\n",
       "  {'n_neighbors': 9}],\n",
       " 'split0_test_score': array([0.9       , 0.93333333, 0.93333333, 0.66666667, 0.96666667,\n",
       "        0.9       , 0.86666667, 0.9       , 0.9       , 0.96666667]),\n",
       " 'split1_test_score': array([0.93333333, 1.        , 1.        , 0.66666667, 1.        ,\n",
       "        0.93333333, 0.9       , 0.9       , 0.93333333, 1.        ]),\n",
       " 'split2_test_score': array([0.83333333, 0.93333333, 0.93333333, 0.66666667, 0.93333333,\n",
       "        0.83333333, 0.8       , 0.83333333, 0.9       , 0.96666667]),\n",
       " 'split3_test_score': array([0.93333333, 0.93333333, 0.96666667, 0.66666667, 0.96666667,\n",
       "        0.93333333, 0.93333333, 0.93333333, 0.96666667, 0.93333333]),\n",
       " 'split4_test_score': array([0.86666667, 1.        , 1.        , 0.63333333, 1.        ,\n",
       "        0.93333333, 0.86666667, 0.86666667, 1.        , 1.        ]),\n",
       " 'mean_test_score': array([0.89333333, 0.96      , 0.96666667, 0.66      , 0.97333333,\n",
       "        0.90666667, 0.87333333, 0.88666667, 0.94      , 0.97333333]),\n",
       " 'std_test_score': array([0.03887301, 0.03265986, 0.02981424, 0.01333333, 0.02494438,\n",
       "        0.03887301, 0.04422166, 0.03399346, 0.03887301, 0.02494438]),\n",
       " 'rank_test_score': array([ 7,  4,  3, 10,  1,  6,  9,  8,  5,  1], dtype=int32)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# 모델 생성\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "params = {\n",
    "    'n_neighbors' : range(1,100,2)\n",
    "}\n",
    "\n",
    "# n_iter : 탐색할 최적의 하이퍼 파라미터 조합 수\n",
    "            # 값이 크면 시간이 오래 걸림 / 값이 작으면 조흔 조합을 찾을 가능성 저하\n",
    "rd_search = RandomizedSearchCV(knn, params, cv=5, n_iter=10, random_state=0)\n",
    "rd_search.fit(iris_input, iris_target)\n",
    "\n",
    "print('최적의 파라미터 : ', rd_search.best_params_)\n",
    "print('최적화된 모델 객체 : ', rd_search.best_estimator_)\n",
    "print('최적화된 점수: ', rd_search.best_score_)\n",
    "rd_search.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyperOpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table border=\"1\">\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>함수명</th>\n",
    "            <th>설명</th>\n",
    "            <th>사용 방법</th>\n",
    "            <th>예시 코드</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>suggest_uniform</td>\n",
    "            <td>연속적인 실수 값 샘플링</td>\n",
    "            <td>trial.suggest_uniform(name, low, high)</td>\n",
    "            <td><code>trial.suggest_uniform('learning_rate', 0.01, 0.1)</code></td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>suggest_discrete_uniform</td>\n",
    "            <td>연속적이지만 일정 간격(step)을 갖는 값 샘플링</td>\n",
    "            <td>trial.suggest_discrete_uniform(name, low, high, step)</td>\n",
    "            <td><code>trial.suggest_discrete_uniform('num_layers', 1, 5, 1)</code></td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>suggest_loguniform</td>\n",
    "            <td>로그 스케일로 분포된 실수 값 샘플링</td>\n",
    "            <td>trial.suggest_loguniform(name, low, high)</td>\n",
    "            <td><code>trial.suggest_loguniform('reg_param', 1e-3, 1)</code></td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>suggest_int</td>\n",
    "            <td>정수 값 샘플링</td>\n",
    "            <td>trial.suggest_int(name, low, high, step)</td>\n",
    "            <td><code>trial.suggest_int('num_trees', 1, 100)</code></td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>suggest_categorical</td>\n",
    "            <td>주어진 리스트 중 임의의 값 샘플링</td>\n",
    "            <td>trial.suggest_categorical(name, choices)</td>\n",
    "            <td><code>trial.suggest_categorical('optimizer', ['adam', 'sgd', 'rmsprop'])</code></td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>suggest_float</td>\n",
    "            <td>연속적인 실수 값 샘플링 (<code>step</code> 사용 가능)</td>\n",
    "            <td>trial.suggest_float(name, low, high, step=None, log=False)</td>\n",
    "            <td><code>trial.suggest_float('alpha', 0.1, 1.0, step=0.1)</code></td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperopt\n",
    "from hyperopt import hp\n",
    "\n",
    "search_space = {\n",
    "    'x' : hp.quniform('x', -10,10,1),\n",
    "    'y' : hp.quniform('y', -15,15,1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 목적 함수\n",
    "def objective(search_space):\n",
    "    x = search_space['x']\n",
    "    y = search_space['y']\n",
    "    return {\n",
    "        'loss' : x**2 + 20 * y,\n",
    "        'status' : hyperopt.STATUS_OK\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:29<00:00, 16.94trial/s, best loss: -300.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'x': 0.0, 'y': -15.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, Trials\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "best_val = fmin(\n",
    "    fn=objective,   # 목적 함수\n",
    "    space=search_space, # 검색공간\n",
    "    algo=tpe.suggest,   # 베이지안 최적화 적용\n",
    "    max_evals=500,      # 반복 횟수\n",
    "    trials=trials       # 탐색과정 저장\n",
    ")\n",
    "\n",
    "best_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': [7.0,\n",
       "  6.0,\n",
       "  -8.0,\n",
       "  -4.0,\n",
       "  10.0,\n",
       "  8.0,\n",
       "  6.0,\n",
       "  -5.0,\n",
       "  5.0,\n",
       "  8.0,\n",
       "  -4.0,\n",
       "  -4.0,\n",
       "  -1.0,\n",
       "  6.0,\n",
       "  3.0,\n",
       "  1.0,\n",
       "  -7.0,\n",
       "  -6.0,\n",
       "  -1.0,\n",
       "  9.0,\n",
       "  1.0,\n",
       "  -2.0,\n",
       "  -10.0,\n",
       "  -2.0,\n",
       "  -10.0,\n",
       "  -3.0,\n",
       "  3.0,\n",
       "  3.0,\n",
       "  3.0,\n",
       "  1.0,\n",
       "  4.0,\n",
       "  -0.0,\n",
       "  -8.0,\n",
       "  2.0,\n",
       "  -2.0,\n",
       "  -1.0,\n",
       "  -6.0,\n",
       "  -8.0,\n",
       "  -2.0,\n",
       "  -5.0,\n",
       "  -3.0,\n",
       "  0.0,\n",
       "  5.0,\n",
       "  -1.0,\n",
       "  -4.0,\n",
       "  7.0,\n",
       "  -3.0,\n",
       "  -9.0,\n",
       "  2.0,\n",
       "  -7.0,\n",
       "  -6.0,\n",
       "  -5.0,\n",
       "  5.0,\n",
       "  -1.0,\n",
       "  2.0,\n",
       "  1.0,\n",
       "  -4.0,\n",
       "  0.0,\n",
       "  4.0,\n",
       "  8.0,\n",
       "  -3.0,\n",
       "  -5.0,\n",
       "  -7.0,\n",
       "  -2.0,\n",
       "  9.0,\n",
       "  6.0,\n",
       "  4.0,\n",
       "  3.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  7.0,\n",
       "  -1.0,\n",
       "  -1.0,\n",
       "  -1.0,\n",
       "  2.0,\n",
       "  -3.0,\n",
       "  -4.0,\n",
       "  1.0,\n",
       "  -2.0,\n",
       "  -1.0,\n",
       "  0.0,\n",
       "  -1.0,\n",
       "  -6.0,\n",
       "  -2.0,\n",
       "  2.0,\n",
       "  -5.0,\n",
       "  -9.0,\n",
       "  -4.0,\n",
       "  -3.0,\n",
       "  3.0,\n",
       "  5.0,\n",
       "  1.0,\n",
       "  -0.0,\n",
       "  4.0,\n",
       "  -1.0,\n",
       "  -7.0,\n",
       "  -2.0,\n",
       "  -6.0,\n",
       "  1.0,\n",
       "  -9.0,\n",
       "  -3.0,\n",
       "  -4.0,\n",
       "  2.0,\n",
       "  -5.0,\n",
       "  -0.0,\n",
       "  -3.0,\n",
       "  6.0,\n",
       "  -2.0,\n",
       "  -8.0,\n",
       "  3.0,\n",
       "  4.0,\n",
       "  9.0,\n",
       "  2.0,\n",
       "  1.0,\n",
       "  -1.0,\n",
       "  -0.0,\n",
       "  -2.0,\n",
       "  -4.0,\n",
       "  5.0,\n",
       "  -4.0,\n",
       "  -5.0,\n",
       "  -6.0,\n",
       "  -1.0,\n",
       "  3.0,\n",
       "  1.0,\n",
       "  -7.0,\n",
       "  7.0,\n",
       "  -3.0,\n",
       "  0.0,\n",
       "  -2.0,\n",
       "  -1.0,\n",
       "  2.0,\n",
       "  -1.0,\n",
       "  1.0,\n",
       "  5.0,\n",
       "  -8.0,\n",
       "  10.0,\n",
       "  4.0,\n",
       "  -3.0,\n",
       "  3.0,\n",
       "  -5.0,\n",
       "  2.0,\n",
       "  -2.0,\n",
       "  0.0,\n",
       "  -10.0,\n",
       "  -1.0,\n",
       "  -1.0,\n",
       "  -2.0,\n",
       "  -3.0,\n",
       "  1.0,\n",
       "  -4.0,\n",
       "  -0.0,\n",
       "  -4.0,\n",
       "  -0.0,\n",
       "  -1.0,\n",
       "  -1.0,\n",
       "  -3.0,\n",
       "  2.0,\n",
       "  -2.0,\n",
       "  -5.0,\n",
       "  1.0,\n",
       "  -6.0,\n",
       "  3.0,\n",
       "  -4.0,\n",
       "  0.0,\n",
       "  6.0,\n",
       "  -3.0,\n",
       "  -2.0,\n",
       "  -1.0,\n",
       "  2.0,\n",
       "  -1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  4.0,\n",
       "  -5.0,\n",
       "  3.0,\n",
       "  -2.0,\n",
       "  -3.0,\n",
       "  1.0,\n",
       "  -7.0,\n",
       "  -2.0,\n",
       "  -4.0,\n",
       "  -1.0,\n",
       "  2.0,\n",
       "  8.0,\n",
       "  -0.0,\n",
       "  -6.0,\n",
       "  4.0,\n",
       "  1.0,\n",
       "  -3.0,\n",
       "  -1.0,\n",
       "  -2.0,\n",
       "  0.0,\n",
       "  -5.0,\n",
       "  1.0,\n",
       "  -4.0,\n",
       "  2.0,\n",
       "  -3.0,\n",
       "  -1.0,\n",
       "  -7.0,\n",
       "  5.0,\n",
       "  -2.0,\n",
       "  3.0,\n",
       "  0.0,\n",
       "  -4.0,\n",
       "  -1.0,\n",
       "  -3.0,\n",
       "  -5.0,\n",
       "  -6.0,\n",
       "  1.0,\n",
       "  4.0,\n",
       "  2.0,\n",
       "  -1.0,\n",
       "  -2.0,\n",
       "  0.0,\n",
       "  -8.0,\n",
       "  -3.0,\n",
       "  3.0,\n",
       "  -0.0,\n",
       "  -2.0,\n",
       "  1.0,\n",
       "  2.0,\n",
       "  -4.0,\n",
       "  -10.0,\n",
       "  -9.0,\n",
       "  6.0,\n",
       "  -1.0,\n",
       "  -5.0,\n",
       "  -3.0,\n",
       "  -2.0,\n",
       "  -6.0,\n",
       "  1.0,\n",
       "  3.0,\n",
       "  2.0,\n",
       "  0.0,\n",
       "  7.0,\n",
       "  -1.0,\n",
       "  5.0,\n",
       "  -3.0,\n",
       "  -4.0,\n",
       "  10.0,\n",
       "  0.0,\n",
       "  -0.0,\n",
       "  5.0,\n",
       "  3.0,\n",
       "  4.0,\n",
       "  1.0,\n",
       "  -2.0,\n",
       "  0.0,\n",
       "  2.0,\n",
       "  -1.0,\n",
       "  1.0,\n",
       "  2.0,\n",
       "  -5.0,\n",
       "  -2.0,\n",
       "  -1.0,\n",
       "  3.0,\n",
       "  0.0,\n",
       "  -1.0,\n",
       "  1.0,\n",
       "  -2.0,\n",
       "  -3.0,\n",
       "  -1.0,\n",
       "  -0.0,\n",
       "  -0.0,\n",
       "  2.0,\n",
       "  1.0,\n",
       "  -1.0,\n",
       "  -2.0,\n",
       "  0.0,\n",
       "  -3.0,\n",
       "  2.0,\n",
       "  -0.0,\n",
       "  1.0,\n",
       "  -1.0,\n",
       "  -4.0,\n",
       "  4.0,\n",
       "  -2.0,\n",
       "  1.0,\n",
       "  4.0,\n",
       "  -1.0,\n",
       "  -3.0,\n",
       "  3.0,\n",
       "  -0.0,\n",
       "  -2.0,\n",
       "  -4.0,\n",
       "  2.0,\n",
       "  -1.0,\n",
       "  1.0,\n",
       "  -0.0,\n",
       "  -2.0,\n",
       "  -3.0,\n",
       "  9.0,\n",
       "  2.0,\n",
       "  1.0,\n",
       "  -4.0,\n",
       "  -0.0,\n",
       "  3.0,\n",
       "  -1.0,\n",
       "  -5.0,\n",
       "  -1.0,\n",
       "  1.0,\n",
       "  -2.0,\n",
       "  -3.0,\n",
       "  -0.0,\n",
       "  4.0,\n",
       "  2.0,\n",
       "  3.0,\n",
       "  0.0,\n",
       "  6.0,\n",
       "  1.0,\n",
       "  -0.0,\n",
       "  1.0,\n",
       "  2.0,\n",
       "  -2.0,\n",
       "  -0.0,\n",
       "  8.0,\n",
       "  -1.0,\n",
       "  3.0,\n",
       "  5.0,\n",
       "  2.0,\n",
       "  4.0,\n",
       "  -2.0,\n",
       "  3.0,\n",
       "  -3.0,\n",
       "  1.0,\n",
       "  -0.0,\n",
       "  -5.0,\n",
       "  1.0,\n",
       "  3.0,\n",
       "  -1.0,\n",
       "  -4.0,\n",
       "  5.0,\n",
       "  -1.0,\n",
       "  -2.0,\n",
       "  -6.0,\n",
       "  -3.0,\n",
       "  2.0,\n",
       "  0.0,\n",
       "  2.0,\n",
       "  -2.0,\n",
       "  1.0,\n",
       "  -0.0,\n",
       "  -3.0,\n",
       "  -1.0,\n",
       "  -4.0,\n",
       "  0.0,\n",
       "  -1.0,\n",
       "  4.0,\n",
       "  -7.0,\n",
       "  -2.0,\n",
       "  -4.0,\n",
       "  1.0,\n",
       "  4.0,\n",
       "  6.0,\n",
       "  2.0,\n",
       "  -3.0,\n",
       "  3.0,\n",
       "  0.0,\n",
       "  -2.0,\n",
       "  1.0,\n",
       "  7.0,\n",
       "  6.0,\n",
       "  -1.0,\n",
       "  2.0,\n",
       "  -1.0,\n",
       "  0.0,\n",
       "  3.0,\n",
       "  5.0,\n",
       "  -5.0,\n",
       "  -2.0,\n",
       "  -4.0,\n",
       "  -3.0,\n",
       "  1.0,\n",
       "  2.0,\n",
       "  4.0,\n",
       "  -6.0,\n",
       "  5.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  -1.0,\n",
       "  3.0,\n",
       "  -2.0,\n",
       "  1.0,\n",
       "  -8.0,\n",
       "  0.0,\n",
       "  -3.0,\n",
       "  2.0,\n",
       "  1.0,\n",
       "  3.0,\n",
       "  -2.0,\n",
       "  3.0,\n",
       "  2.0,\n",
       "  -4.0,\n",
       "  1.0,\n",
       "  -1.0,\n",
       "  4.0,\n",
       "  -1.0,\n",
       "  -3.0,\n",
       "  8.0,\n",
       "  2.0,\n",
       "  1.0,\n",
       "  -0.0,\n",
       "  -0.0,\n",
       "  0.0,\n",
       "  -1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  2.0,\n",
       "  0.0,\n",
       "  -1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  2.0,\n",
       "  -2.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  -1.0,\n",
       "  0.0,\n",
       "  -2.0,\n",
       "  -1.0,\n",
       "  -2.0,\n",
       "  3.0,\n",
       "  2.0,\n",
       "  1.0,\n",
       "  -0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  2.0,\n",
       "  -1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  2.0,\n",
       "  3.0,\n",
       "  0.0,\n",
       "  -1.0,\n",
       "  -2.0,\n",
       "  1.0,\n",
       "  -1.0,\n",
       "  2.0,\n",
       "  4.0,\n",
       "  -3.0,\n",
       "  3.0,\n",
       "  -2.0,\n",
       "  1.0,\n",
       "  -0.0,\n",
       "  -1.0,\n",
       "  -0.0,\n",
       "  2.0,\n",
       "  -2.0,\n",
       "  1.0,\n",
       "  -0.0,\n",
       "  -3.0,\n",
       "  4.0,\n",
       "  -1.0,\n",
       "  -2.0,\n",
       "  3.0,\n",
       "  2.0,\n",
       "  -1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  -3.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  2.0,\n",
       "  -1.0,\n",
       "  -2.0,\n",
       "  1.0,\n",
       "  3.0,\n",
       "  -0.0,\n",
       "  2.0,\n",
       "  0.0,\n",
       "  -1.0,\n",
       "  -3.0,\n",
       "  -2.0,\n",
       "  1.0,\n",
       "  3.0,\n",
       "  -0.0,\n",
       "  5.0,\n",
       "  -4.0,\n",
       "  2.0,\n",
       "  -1.0,\n",
       "  4.0,\n",
       "  1.0,\n",
       "  -2.0,\n",
       "  -1.0,\n",
       "  2.0,\n",
       "  -0.0,\n",
       "  -3.0,\n",
       "  0.0,\n",
       "  -1.0,\n",
       "  -2.0,\n",
       "  3.0,\n",
       "  1.0,\n",
       "  -4.0,\n",
       "  -1.0,\n",
       "  2.0,\n",
       "  1.0,\n",
       "  -2.0],\n",
       " 'y': [-3.0,\n",
       "  -14.0,\n",
       "  10.0,\n",
       "  -9.0,\n",
       "  -4.0,\n",
       "  -11.0,\n",
       "  -2.0,\n",
       "  13.0,\n",
       "  -8.0,\n",
       "  -14.0,\n",
       "  1.0,\n",
       "  -14.0,\n",
       "  -4.0,\n",
       "  -3.0,\n",
       "  -1.0,\n",
       "  -1.0,\n",
       "  -2.0,\n",
       "  11.0,\n",
       "  11.0,\n",
       "  -14.0,\n",
       "  4.0,\n",
       "  -15.0,\n",
       "  -11.0,\n",
       "  -7.0,\n",
       "  6.0,\n",
       "  -11.0,\n",
       "  -15.0,\n",
       "  -12.0,\n",
       "  -6.0,\n",
       "  3.0,\n",
       "  -9.0,\n",
       "  7.0,\n",
       "  -15.0,\n",
       "  -6.0,\n",
       "  -12.0,\n",
       "  -15.0,\n",
       "  -9.0,\n",
       "  -12.0,\n",
       "  -5.0,\n",
       "  -10.0,\n",
       "  15.0,\n",
       "  -13.0,\n",
       "  1.0,\n",
       "  -8.0,\n",
       "  -15.0,\n",
       "  8.0,\n",
       "  -4.0,\n",
       "  -13.0,\n",
       "  15.0,\n",
       "  1.0,\n",
       "  -10.0,\n",
       "  -7.0,\n",
       "  -3.0,\n",
       "  3.0,\n",
       "  13.0,\n",
       "  -13.0,\n",
       "  -8.0,\n",
       "  -1.0,\n",
       "  -14.0,\n",
       "  5.0,\n",
       "  -10.0,\n",
       "  9.0,\n",
       "  -5.0,\n",
       "  -7.0,\n",
       "  -11.0,\n",
       "  -15.0,\n",
       "  -14.0,\n",
       "  -12.0,\n",
       "  -9.0,\n",
       "  -13.0,\n",
       "  -11.0,\n",
       "  -15.0,\n",
       "  -15.0,\n",
       "  -14.0,\n",
       "  -2.0,\n",
       "  -8.0,\n",
       "  -15.0,\n",
       "  -12.0,\n",
       "  -10.0,\n",
       "  -6.0,\n",
       "  -13.0,\n",
       "  -11.0,\n",
       "  -9.0,\n",
       "  -14.0,\n",
       "  -5.0,\n",
       "  13.0,\n",
       "  0.0,\n",
       "  -4.0,\n",
       "  -15.0,\n",
       "  2.0,\n",
       "  -10.0,\n",
       "  -7.0,\n",
       "  -12.0,\n",
       "  -13.0,\n",
       "  6.0,\n",
       "  -8.0,\n",
       "  -6.0,\n",
       "  -12.0,\n",
       "  -14.0,\n",
       "  -9.0,\n",
       "  10.0,\n",
       "  -3.0,\n",
       "  -2.0,\n",
       "  -11.0,\n",
       "  -1.0,\n",
       "  -7.0,\n",
       "  -15.0,\n",
       "  14.0,\n",
       "  -13.0,\n",
       "  4.0,\n",
       "  -10.0,\n",
       "  -0.0,\n",
       "  -12.0,\n",
       "  -5.0,\n",
       "  -14.0,\n",
       "  -11.0,\n",
       "  -15.0,\n",
       "  -13.0,\n",
       "  -10.0,\n",
       "  -3.0,\n",
       "  8.0,\n",
       "  -8.0,\n",
       "  -15.0,\n",
       "  -9.0,\n",
       "  12.0,\n",
       "  -6.0,\n",
       "  -14.0,\n",
       "  -11.0,\n",
       "  2.0,\n",
       "  -13.0,\n",
       "  -15.0,\n",
       "  -4.0,\n",
       "  -7.0,\n",
       "  -8.0,\n",
       "  6.0,\n",
       "  -12.0,\n",
       "  -14.0,\n",
       "  -15.0,\n",
       "  -10.0,\n",
       "  4.0,\n",
       "  -11.0,\n",
       "  -9.0,\n",
       "  10.0,\n",
       "  -12.0,\n",
       "  -5.0,\n",
       "  -13.0,\n",
       "  -15.0,\n",
       "  -14.0,\n",
       "  -15.0,\n",
       "  -13.0,\n",
       "  -12.0,\n",
       "  -14.0,\n",
       "  -11.0,\n",
       "  -10.0,\n",
       "  -15.0,\n",
       "  -14.0,\n",
       "  -13.0,\n",
       "  -9.0,\n",
       "  -12.0,\n",
       "  -15.0,\n",
       "  -11.0,\n",
       "  -7.0,\n",
       "  -6.0,\n",
       "  -14.0,\n",
       "  -9.0,\n",
       "  -13.0,\n",
       "  -2.0,\n",
       "  -8.0,\n",
       "  -12.0,\n",
       "  -10.0,\n",
       "  -15.0,\n",
       "  2.0,\n",
       "  -14.0,\n",
       "  7.0,\n",
       "  -11.0,\n",
       "  -4.0,\n",
       "  -15.0,\n",
       "  -1.0,\n",
       "  -8.0,\n",
       "  -13.0,\n",
       "  -12.0,\n",
       "  11.0,\n",
       "  14.0,\n",
       "  -10.0,\n",
       "  -14.0,\n",
       "  3.0,\n",
       "  -7.0,\n",
       "  -13.0,\n",
       "  -9.0,\n",
       "  -11.0,\n",
       "  -15.0,\n",
       "  5.0,\n",
       "  -5.0,\n",
       "  -12.0,\n",
       "  -14.0,\n",
       "  1.0,\n",
       "  -11.0,\n",
       "  -10.0,\n",
       "  -13.0,\n",
       "  -15.0,\n",
       "  -3.0,\n",
       "  -6.0,\n",
       "  -15.0,\n",
       "  -13.0,\n",
       "  -8.0,\n",
       "  -12.0,\n",
       "  -9.0,\n",
       "  9.0,\n",
       "  -15.0,\n",
       "  -14.0,\n",
       "  -4.0,\n",
       "  -10.0,\n",
       "  -11.0,\n",
       "  0.0,\n",
       "  -7.0,\n",
       "  -14.0,\n",
       "  -12.0,\n",
       "  -13.0,\n",
       "  -14.0,\n",
       "  12.0,\n",
       "  -9.0,\n",
       "  -1.0,\n",
       "  -10.0,\n",
       "  -12.0,\n",
       "  -15.0,\n",
       "  -13.0,\n",
       "  -8.0,\n",
       "  7.0,\n",
       "  -12.0,\n",
       "  -6.0,\n",
       "  -11.0,\n",
       "  -2.0,\n",
       "  5.0,\n",
       "  -14.0,\n",
       "  -10.0,\n",
       "  -14.0,\n",
       "  -13.0,\n",
       "  -11.0,\n",
       "  -5.0,\n",
       "  -7.0,\n",
       "  -3.0,\n",
       "  -15.0,\n",
       "  3.0,\n",
       "  -8.0,\n",
       "  -9.0,\n",
       "  -15.0,\n",
       "  -12.0,\n",
       "  8.0,\n",
       "  -14.0,\n",
       "  -13.0,\n",
       "  -4.0,\n",
       "  -6.0,\n",
       "  -9.0,\n",
       "  -11.0,\n",
       "  -15.0,\n",
       "  -15.0,\n",
       "  -12.0,\n",
       "  -14.0,\n",
       "  -15.0,\n",
       "  -13.0,\n",
       "  -14.0,\n",
       "  -13.0,\n",
       "  -15.0,\n",
       "  -15.0,\n",
       "  -10.0,\n",
       "  -13.0,\n",
       "  -11.0,\n",
       "  -15.0,\n",
       "  -15.0,\n",
       "  -12.0,\n",
       "  -14.0,\n",
       "  -12.0,\n",
       "  -10.0,\n",
       "  -11.0,\n",
       "  -14.0,\n",
       "  -13.0,\n",
       "  -12.0,\n",
       "  -14.0,\n",
       "  -15.0,\n",
       "  -11.0,\n",
       "  -14.0,\n",
       "  1.0,\n",
       "  -13.0,\n",
       "  -9.0,\n",
       "  -8.0,\n",
       "  -15.0,\n",
       "  -13.0,\n",
       "  -10.0,\n",
       "  9.0,\n",
       "  -12.0,\n",
       "  -15.0,\n",
       "  -14.0,\n",
       "  -13.0,\n",
       "  -11.0,\n",
       "  -10.0,\n",
       "  -7.0,\n",
       "  -12.0,\n",
       "  -14.0,\n",
       "  14.0,\n",
       "  4.0,\n",
       "  -9.0,\n",
       "  -11.0,\n",
       "  -15.0,\n",
       "  -13.0,\n",
       "  -15.0,\n",
       "  -14.0,\n",
       "  -8.0,\n",
       "  -10.0,\n",
       "  -12.0,\n",
       "  -13.0,\n",
       "  -14.0,\n",
       "  -5.0,\n",
       "  -11.0,\n",
       "  -15.0,\n",
       "  11.0,\n",
       "  -12.0,\n",
       "  -15.0,\n",
       "  -6.0,\n",
       "  2.0,\n",
       "  -14.0,\n",
       "  6.0,\n",
       "  -10.0,\n",
       "  -9.0,\n",
       "  15.0,\n",
       "  12.0,\n",
       "  -1.0,\n",
       "  -13.0,\n",
       "  -11.0,\n",
       "  -15.0,\n",
       "  -12.0,\n",
       "  -8.0,\n",
       "  -14.0,\n",
       "  -15.0,\n",
       "  -13.0,\n",
       "  -12.0,\n",
       "  -10.0,\n",
       "  8.0,\n",
       "  -13.0,\n",
       "  -11.0,\n",
       "  -12.0,\n",
       "  -14.0,\n",
       "  1.0,\n",
       "  -8.0,\n",
       "  5.0,\n",
       "  -9.0,\n",
       "  -15.0,\n",
       "  -7.0,\n",
       "  -13.0,\n",
       "  -10.0,\n",
       "  0.0,\n",
       "  -2.0,\n",
       "  -14.0,\n",
       "  -11.0,\n",
       "  10.0,\n",
       "  -15.0,\n",
       "  -12.0,\n",
       "  -13.0,\n",
       "  -14.0,\n",
       "  -12.0,\n",
       "  -9.0,\n",
       "  -15.0,\n",
       "  3.0,\n",
       "  -7.0,\n",
       "  -6.0,\n",
       "  -11.0,\n",
       "  -13.0,\n",
       "  -14.0,\n",
       "  -3.0,\n",
       "  -15.0,\n",
       "  -4.0,\n",
       "  -10.0,\n",
       "  -14.0,\n",
       "  -12.0,\n",
       "  -9.0,\n",
       "  -15.0,\n",
       "  -13.0,\n",
       "  7.0,\n",
       "  -5.0,\n",
       "  -10.0,\n",
       "  -15.0,\n",
       "  -11.0,\n",
       "  -14.0,\n",
       "  -13.0,\n",
       "  -11.0,\n",
       "  -7.0,\n",
       "  -8.0,\n",
       "  -12.0,\n",
       "  4.0,\n",
       "  -15.0,\n",
       "  -14.0,\n",
       "  -13.0,\n",
       "  -12.0,\n",
       "  -9.0,\n",
       "  -14.0,\n",
       "  13.0,\n",
       "  -10.0,\n",
       "  -11.0,\n",
       "  -15.0,\n",
       "  9.0,\n",
       "  -15.0,\n",
       "  -13.0,\n",
       "  -15.0,\n",
       "  -15.0,\n",
       "  -14.0,\n",
       "  -14.0,\n",
       "  -14.0,\n",
       "  -13.0,\n",
       "  -15.0,\n",
       "  -12.0,\n",
       "  -15.0,\n",
       "  -13.0,\n",
       "  -14.0,\n",
       "  -13.0,\n",
       "  -15.0,\n",
       "  -12.0,\n",
       "  -11.0,\n",
       "  -15.0,\n",
       "  -14.0,\n",
       "  -12.0,\n",
       "  -13.0,\n",
       "  -14.0,\n",
       "  -12.0,\n",
       "  -15.0,\n",
       "  -13.0,\n",
       "  -11.0,\n",
       "  -15.0,\n",
       "  -14.0,\n",
       "  -13.0,\n",
       "  -14.0,\n",
       "  -10.0,\n",
       "  -15.0,\n",
       "  -12.0,\n",
       "  -11.0,\n",
       "  -15.0,\n",
       "  -13.0,\n",
       "  -12.0,\n",
       "  -11.0,\n",
       "  -9.0,\n",
       "  -14.0,\n",
       "  -13.0,\n",
       "  -15.0,\n",
       "  -12.0,\n",
       "  -10.0,\n",
       "  -14.0,\n",
       "  -15.0,\n",
       "  -10.0,\n",
       "  -11.0,\n",
       "  -8.0,\n",
       "  -13.0,\n",
       "  -0.0,\n",
       "  -14.0,\n",
       "  -14.0,\n",
       "  -13.0,\n",
       "  -15.0,\n",
       "  -12.0,\n",
       "  -15.0,\n",
       "  2.0,\n",
       "  -9.0,\n",
       "  -12.0,\n",
       "  -11.0,\n",
       "  -15.0,\n",
       "  -14.0,\n",
       "  -13.0,\n",
       "  6.0,\n",
       "  11.0,\n",
       "  -10.0,\n",
       "  -14.0,\n",
       "  -8.0,\n",
       "  -2.0,\n",
       "  -13.0,\n",
       "  -15.0,\n",
       "  -12.0,\n",
       "  -15.0,\n",
       "  -14.0,\n",
       "  -9.0,\n",
       "  -11.0,\n",
       "  -13.0,\n",
       "  -10.0,\n",
       "  -15.0,\n",
       "  -1.0,\n",
       "  -11.0,\n",
       "  -12.0,\n",
       "  -14.0,\n",
       "  14.0,\n",
       "  -7.0,\n",
       "  5.0,\n",
       "  -13.0,\n",
       "  -13.0,\n",
       "  -9.0,\n",
       "  -14.0,\n",
       "  -12.0,\n",
       "  -6.0,\n",
       "  -15.0,\n",
       "  -10.0,\n",
       "  -15.0,\n",
       "  -11.0,\n",
       "  -3.0,\n",
       "  -14.0,\n",
       "  -12.0,\n",
       "  -8.0]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 탐색과정 -> 목적함수 반환값 (loss 실행 상태 저장) 저장\n",
    "trials.results\n",
    "\n",
    "# 탐색과정 -> 하이퍼 파라미터값을 딕셔너리(리스트) 형태로 저장\n",
    "trials.vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- hyperopt를 활용한 XGBoost 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:21<00:00,  2.30trial/s, best loss: -0.971830985915493] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.5018098698961706,\n",
       " 'learning_rate': 0.10310677358446975,\n",
       " 'max_depth': 6.0,\n",
       " 'n_estimators': 500.0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, random_state=42)\n",
    "\n",
    "# 1. 검색 공간\n",
    "search_space = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 100, 500, 100),\n",
    "    'max_depth': hp.quniform('max_depth', 3, 10, 1),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1)\n",
    "}\n",
    "\n",
    "\n",
    "# 2. 목적 함수\n",
    "def xgb_objective(ss):\n",
    "    xgb_clf = XGBClassifier(\n",
    "        n_estimators=int(ss['n_estimators']),\n",
    "        max_depth=int(ss['max_depth']),\n",
    "        learning_rate=ss['learning_rate'],\n",
    "        colsample_bytree=ss['colsample_bytree']\n",
    "    )\n",
    "    mean_acc = cross_val_score(xgb_clf, X_train, y_train, scoring='accuracy', cv=3).mean()      # accuracy로 평균을 구해 양수면 성능이 높은거임\n",
    "    return {\n",
    "        'loss': -1 * mean_acc,\n",
    "        'status': hyperopt.STATUS_OK\n",
    "    }\n",
    "\n",
    "# 3. Trials() + fmin() 써서 최적화 파라미터 찾음\n",
    "trials = Trials()\n",
    "best = fmin(\n",
    "    fn=xgb_objective,\n",
    "    space=search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=50,\n",
    "    trials=trials\n",
    ")\n",
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 생선 다중 분류 with cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-11 16:15:51,000] A new study created in memory with name: no-name-15e6e72a-13cd-46ba-92b3-0266adfe0dd9\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\484541454.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  x = trial.suggest_uniform('x',-10,10)\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\484541454.py:5: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  y = trial.suggest_uniform('y',-15,15)\n",
      "[I 2025-02-11 16:15:51,017] Trial 0 finished with value: 77.26626068286728 and parameters: {'x': -5.771365437963238, 'y': -4.426058333476954}. Best is trial 0 with value: 77.26626068286728.\n",
      "[I 2025-02-11 16:15:51,018] Trial 1 finished with value: 394.97872770692067 and parameters: {'x': 5.77991988969146, 'y': 14.678688297592867}. Best is trial 0 with value: 77.26626068286728.\n",
      "[I 2025-02-11 16:15:51,019] Trial 2 finished with value: 141.38086734431718 and parameters: {'x': 9.990893442172155, 'y': 4.618122281636449}. Best is trial 0 with value: 77.26626068286728.\n",
      "[I 2025-02-11 16:15:51,020] Trial 3 finished with value: 1.4672361753557046 and parameters: {'x': 3.0110052328930355, 'y': -6.211245251881168}. Best is trial 3 with value: 1.4672361753557046.\n",
      "[I 2025-02-11 16:15:51,021] Trial 4 finished with value: 41.83665935722324 and parameters: {'x': 9.380153826400818, 'y': -6.063154038080203}. Best is trial 3 with value: 1.4672361753557046.\n",
      "[I 2025-02-11 16:15:51,021] Trial 5 finished with value: 129.7604177008255 and parameters: {'x': -8.320699993697847, 'y': -3.7342317141296846}. Best is trial 3 with value: 1.4672361753557046.\n",
      "[I 2025-02-11 16:15:51,023] Trial 6 finished with value: 98.90155372609271 and parameters: {'x': -2.3231700737964918, 'y': 3.400322261171304}. Best is trial 3 with value: 1.4672361753557046.\n",
      "[I 2025-02-11 16:15:51,024] Trial 7 finished with value: 55.68398333502307 and parameters: {'x': 7.47622077035135, 'y': 0.970546955689926}. Best is trial 3 with value: 1.4672361753557046.\n",
      "[I 2025-02-11 16:15:51,024] Trial 8 finished with value: 163.60836995984366 and parameters: {'x': -7.134504112978433, 'y': 2.803857785984242}. Best is trial 3 with value: 1.4672361753557046.\n",
      "[I 2025-02-11 16:15:51,024] Trial 9 finished with value: 373.78971420199844 and parameters: {'x': -5.5953055404974705, 'y': 12.317922417758197}. Best is trial 3 with value: 1.4672361753557046.\n",
      "[I 2025-02-11 16:15:51,034] Trial 10 finished with value: 100.18486720957561 and parameters: {'x': 2.0902957798057384, 'y': -14.967813473442225}. Best is trial 3 with value: 1.4672361753557046.\n",
      "[I 2025-02-11 16:15:51,040] Trial 11 finished with value: 38.19597440367841 and parameters: {'x': 2.657489792970937, 'y': -11.170790967271483}. Best is trial 3 with value: 1.4672361753557046.\n",
      "[I 2025-02-11 16:15:51,046] Trial 12 finished with value: 64.70727423098259 and parameters: {'x': 2.887081510328453, 'y': -13.043290598111751}. Best is trial 3 with value: 1.4672361753557046.\n",
      "[I 2025-02-11 16:15:51,052] Trial 13 finished with value: 37.3480370818867 and parameters: {'x': -1.1927386031007607, 'y': -9.446232122590473}. Best is trial 3 with value: 1.4672361753557046.\n",
      "[I 2025-02-11 16:15:51,059] Trial 14 finished with value: 35.297403254453364 and parameters: {'x': -1.7162039629263788, 'y': -8.613145919352121}. Best is trial 3 with value: 1.4672361753557046.\n",
      "[I 2025-02-11 16:15:51,065] Trial 15 finished with value: 53.41532584630738 and parameters: {'x': -3.5178664707719483, 'y': -8.306469796549518}. Best is trial 3 with value: 1.4672361753557046.\n",
      "[I 2025-02-11 16:15:51,070] Trial 16 finished with value: 13.211184030473472 and parameters: {'x': 0.8172746056187354, 'y': -2.0936459466891124}. Best is trial 3 with value: 1.4672361753557046.\n",
      "[I 2025-02-11 16:15:51,078] Trial 17 finished with value: 161.13916030565625 and parameters: {'x': 5.442126615894331, 'y': 7.456932924985859}. Best is trial 3 with value: 1.4672361753557046.\n",
      "[I 2025-02-11 16:15:51,090] Trial 18 finished with value: 15.326933930638845 and parameters: {'x': 0.6626942485367384, 'y': -1.859309669067069}. Best is trial 3 with value: 1.4672361753557046.\n",
      "[I 2025-02-11 16:15:51,102] Trial 19 finished with value: 18.261465834671082 and parameters: {'x': 4.688034041017694, 'y': -1.0741871018811207}. Best is trial 3 with value: 1.4672361753557046.\n",
      "[I 2025-02-11 16:15:51,113] Trial 20 finished with value: 195.433274177327 and parameters: {'x': 0.598374645887063, 'y': 8.77190872159008}. Best is trial 3 with value: 1.4672361753557046.\n",
      "[I 2025-02-11 16:15:51,123] Trial 21 finished with value: 19.72840940201893 and parameters: {'x': 0.6320872696988842, 'y': -1.2421550452823573}. Best is trial 3 with value: 1.4672361753557046.\n",
      "[I 2025-02-11 16:15:51,126] Trial 22 finished with value: 2.1853720061063684 and parameters: {'x': 3.335409157899386, 'y': -3.560252555861413}. Best is trial 3 with value: 1.4672361753557046.\n",
      "[I 2025-02-11 16:15:51,136] Trial 23 finished with value: 0.4419320442242601 and parameters: {'x': 3.648613629287376, 'y': -4.854286568474563}. Best is trial 23 with value: 0.4419320442242601.\n",
      "[I 2025-02-11 16:15:51,144] Trial 24 finished with value: 4.695652759511313 and parameters: {'x': 3.677687030590568, 'y': -7.0582499964971825}. Best is trial 23 with value: 0.4419320442242601.\n",
      "[I 2025-02-11 16:15:51,151] Trial 25 finished with value: 14.54723006807254 and parameters: {'x': 6.813590279090153, 'y': -4.938687266398999}. Best is trial 23 with value: 0.4419320442242601.\n",
      "[I 2025-02-11 16:15:51,151] Trial 26 finished with value: 42.36260110429447 and parameters: {'x': 3.796221759623201, 'y': 1.4597702756210307}. Best is trial 23 with value: 0.4419320442242601.\n",
      "[I 2025-02-11 16:15:51,161] Trial 27 finished with value: 53.642013945548946 and parameters: {'x': 7.424425876784927, 'y': -10.836648833567502}. Best is trial 23 with value: 0.4419320442242601.\n",
      "[I 2025-02-11 16:15:51,169] Trial 28 finished with value: 4.763840611756697 and parameters: {'x': 1.5995866162381844, 'y': -6.674121550646033}. Best is trial 23 with value: 0.4419320442242601.\n",
      "[I 2025-02-11 16:15:51,169] Trial 29 finished with value: 5.339110182469392 and parameters: {'x': 4.136414391284367, 'y': -2.988117171962747}. Best is trial 23 with value: 0.4419320442242601.\n",
      "[I 2025-02-11 16:15:51,183] Trial 30 finished with value: 30.49441373607698 and parameters: {'x': 8.51889101055226, 'y': -4.809590573441234}. Best is trial 23 with value: 0.4419320442242601.\n",
      "[I 2025-02-11 16:15:51,190] Trial 31 finished with value: 3.6534237788547026 and parameters: {'x': 3.653970008535784, 'y': -6.796036471453297}. Best is trial 23 with value: 0.4419320442242601.\n",
      "[I 2025-02-11 16:15:51,190] Trial 32 finished with value: 7.835797094359462 and parameters: {'x': 5.717664149640178, 'y': -4.329106070887512}. Best is trial 23 with value: 0.4419320442242601.\n",
      "[I 2025-02-11 16:15:51,203] Trial 33 finished with value: 7.6370713883099075 and parameters: {'x': 4.967432779898895, 'y': -6.940690507239424}. Best is trial 23 with value: 0.4419320442242601.\n",
      "[I 2025-02-11 16:15:51,209] Trial 34 finished with value: 46.8771484990549 and parameters: {'x': -0.9351030148070847, 'y': -10.60286647725172}. Best is trial 23 with value: 0.4419320442242601.\n",
      "[I 2025-02-11 16:15:51,216] Trial 35 finished with value: 0.0034147471052381672 and parameters: {'x': 3.0216485783952405, 'y': -4.945722139331922}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,224] Trial 36 finished with value: 3.8576717412713077 and parameters: {'x': 2.1795732804297936, 'y': -3.2154631583835043}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,224] Trial 37 finished with value: 35.80314035064406 and parameters: {'x': 6.615821714757562, 'y': -0.23250865992063513}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,238] Trial 38 finished with value: 38.93279194189032 and parameters: {'x': -3.2332645630861587, 'y': -5.281433524059646}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,254] Trial 39 finished with value: 69.17156822353562 and parameters: {'x': 8.545537465142763, 'y': 1.198272537266622}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,269] Trial 40 finished with value: 100.59346842153678 and parameters: {'x': -0.3194648477066262, 'y': 4.464387013767813}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,278] Trial 41 finished with value: 1.3609143376982304 and parameters: {'x': 3.518997541044999, 'y': -6.0447755213860415}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,288] Trial 42 finished with value: 2.8734377744456676 and parameters: {'x': 3.013389836640753, 'y': -3.304931126260528}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,294] Trial 43 finished with value: 13.056622426982745 and parameters: {'x': 1.6760315365048875, 'y': -8.362102011339504}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,300] Trial 44 finished with value: 2.730993998286875 and parameters: {'x': 4.458128029662657, 'y': -5.777725303303791}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,300] Trial 45 finished with value: 61.86078430036696 and parameters: {'x': 2.987916072999653, 'y': -12.865153417389594}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,300] Trial 46 finished with value: 32.37140854218186 and parameters: {'x': 6.497616871202509, 'y': -9.487547745089898}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,320] Trial 47 finished with value: 27.29326051543849 and parameters: {'x': 1.9190851668694402, 'y': 0.11125069224322282}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,333] Trial 48 finished with value: 14.094815100915891 and parameters: {'x': 5.6549165455438715, 'y': -7.65447419221082}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,344] Trial 49 finished with value: 1.8115518683357348 and parameters: {'x': 2.9690014052890406, 'y': -3.654417986348777}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,352] Trial 50 finished with value: 395.19260501288716 and parameters: {'x': -0.30819993717655836, 'y': 14.60225543626427}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,360] Trial 51 finished with value: 171.9696010834352 and parameters: {'x': -9.90126902595849, 'y': -2.6490728205069187}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,367] Trial 52 finished with value: 1.6727581852627929 and parameters: {'x': 2.599585506528904, 'y': -3.770192527799136}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,374] Trial 53 finished with value: 3.520233855085437 and parameters: {'x': 1.2067652850616595, 'y': -4.448145750921998}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,385] Trial 54 finished with value: 18.955542669435857 and parameters: {'x': 2.4365785001070326, 'y': -9.317186454497213}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,396] Trial 55 finished with value: 16.68393658688008 and parameters: {'x': 4.930227037082496, 'y': -1.4002555407090616}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,410] Trial 56 finished with value: 3.2879782154890593 and parameters: {'x': 4.299143412724965, 'y': -6.264991940157087}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,423] Trial 57 finished with value: 0.6538457188436771 and parameters: {'x': 2.513887644617017, 'y': -5.646173735761278}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,430] Trial 58 finished with value: 9.13540445722889 and parameters: {'x': 0.15739356306269903, 'y': -6.027128571266282}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,446] Trial 59 finished with value: 7.995893315838365 and parameters: {'x': 2.5192729134428595, 'y': -7.786538136126733}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,451] Trial 60 finished with value: 3.293678050058414 and parameters: {'x': 1.2331569687385198, 'y': -5.41466100967074}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,461] Trial 61 finished with value: 8.934593641342607 and parameters: {'x': 3.1517601341383554, 'y': -2.0147759710485853}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,470] Trial 62 finished with value: 3.0539292004802157 and parameters: {'x': 4.021082427221665, 'y': -3.581789903681641}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,477] Trial 63 finished with value: 5.611499672991604 and parameters: {'x': 5.182496650775574, 'y': -4.079017892494646}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,488] Trial 64 finished with value: 21.702272114757704 and parameters: {'x': 2.4630320030665205, 'y': -0.3724804176506229}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,500] Trial 65 finished with value: 55.8801408675565 and parameters: {'x': 1.3144371276841111, 'y': 2.2827892095698274}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,511] Trial 66 finished with value: 7.606057508588901 and parameters: {'x': 3.7838495390645694, 'y': -2.3558295424278786}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,519] Trial 67 finished with value: 87.46276204912857 and parameters: {'x': -5.3882426516167925, 'y': -9.135232432007355}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,530] Trial 68 finished with value: 16.84888074441063 and parameters: {'x': 6.142448129544198, 'y': -7.640814362565987}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,539] Trial 69 finished with value: 0.10383654629046235 and parameters: {'x': 3.1545636735225964, 'y': -4.71725167176858}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,550] Trial 70 finished with value: 2.556830295301065 and parameters: {'x': 4.597987118389124, 'y': -5.057161742131331}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,564] Trial 71 finished with value: 1.7853089767181287 and parameters: {'x': 1.9890893463975963, 'y': -4.126290307280908}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,578] Trial 72 finished with value: 2.4896095219321497 and parameters: {'x': 1.9666833744245689, 'y': -6.192420342514146}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,586] Trial 73 finished with value: 6.255463109585774 and parameters: {'x': 0.5417124057519986, 'y': -4.539255804646279}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,596] Trial 74 finished with value: 3.8933782395063643 and parameters: {'x': 3.2418635039433825, 'y': -6.958285036700887}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,608] Trial 75 finished with value: 0.6561681153525516 and parameters: {'x': 3.583645382458977, 'y': -5.561717173394998}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,617] Trial 76 finished with value: 0.9388516158961486 and parameters: {'x': 3.7688780833865634, 'y': -5.589642356673902}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,627] Trial 77 finished with value: 55.908702284305626 and parameters: {'x': 3.5532525189560626, 'y': -12.456716028827596}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,639] Trial 78 finished with value: 32.703927478795485 and parameters: {'x': 5.19996638932962, 'y': -10.278643326141243}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,653] Trial 79 finished with value: 1.2420199938571286 and parameters: {'x': 3.965892006722038, 'y': -5.555943005359006}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,665] Trial 80 finished with value: 18.912282601246506 and parameters: {'x': 7.31017080184095, 'y': -5.578541493934746}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,677] Trial 81 finished with value: 8.421329231959401 and parameters: {'x': 4.582456320964872, 'y': -7.432521577334459}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,688] Trial 82 finished with value: 13.481113057958286 and parameters: {'x': 4.220391616596503, 'y': -8.462911688175033}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,708] Trial 83 finished with value: 2.3491914595573955 and parameters: {'x': 3.6225189789019288, 'y': -6.400593295880105}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,723] Trial 84 finished with value: 0.2359997492680227 and parameters: {'x': 3.366593048151403, 'y': -5.318762115558116}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,738] Trial 85 finished with value: 13.225451830181314 and parameters: {'x': 5.879871248856949, 'y': -2.779235847689262}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,749] Trial 86 finished with value: 1.0924134878631464 and parameters: {'x': 4.043019017214013, 'y': -4.93273323559839}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,758] Trial 87 finished with value: 5.708243212649579 and parameters: {'x': 5.389167727138714, 'y': -5.010990188734054}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,767] Trial 88 finished with value: 0.17557234423509868 and parameters: {'x': 2.8014452045430795, 'y': -5.368982841655488}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,777] Trial 89 finished with value: 137.88414133644267 and parameters: {'x': 2.912376384360331, 'y': 6.742080881957206}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,786] Trial 90 finished with value: 20.919038266648798 and parameters: {'x': 1.4915284066146244, 'y': -0.682182065140057}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,796] Trial 91 finished with value: 0.9549560312124076 and parameters: {'x': 3.95335682973051, 'y': -4.785368253935726}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,807] Trial 92 finished with value: 3.1554218598456116 and parameters: {'x': 4.746926676959193, 'y': -4.678023222617029}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,817] Trial 93 finished with value: 4.067363565480362 and parameters: {'x': 3.35658181958417, 'y': -3.015003029870724}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,830] Trial 94 finished with value: 4.100891057919457 and parameters: {'x': 2.3127642522543406, 'y': -6.904887945507536}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,841] Trial 95 finished with value: 12.074859452734563 and parameters: {'x': 4.232919636704311, 'y': -1.7511896604813213}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,852] Trial 96 finished with value: 8.68697628063924 and parameters: {'x': 2.703158603897531, 'y': -7.9323815348960265}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,862] Trial 97 finished with value: 0.6564234208315368 and parameters: {'x': 3.2708909727812974, 'y': -4.236428456726458}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,874] Trial 98 finished with value: 5.195071445248129 and parameters: {'x': 0.9324891828660382, 'y': -4.040588479179979}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,888] Trial 99 finished with value: 1.7330849403633415 and parameters: {'x': 1.8413597443873493, 'y': -5.6250101586671954}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,900] Trial 100 finished with value: 28.008104144176638 and parameters: {'x': 3.21831331466042, 'y': 0.2877635575750377}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,915] Trial 101 finished with value: 0.531355329818981 and parameters: {'x': 3.728054546413455, 'y': -4.964056888480835}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,926] Trial 102 finished with value: 2.3899846438980688 and parameters: {'x': 2.7399194679465007, 'y': -6.523923476013424}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,938] Trial 103 finished with value: 3.4575893232474906 and parameters: {'x': 3.741365760621308, 'y': -3.2947240304789727}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,952] Trial 104 finished with value: 9.608893198571401 and parameters: {'x': 4.8190141252141405, 'y': -2.4900038225441783}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,964] Trial 105 finished with value: 1.066077302007435 and parameters: {'x': 2.1253366661473745, 'y': -4.451327643833548}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,974] Trial 106 finished with value: 0.7015617507876419 and parameters: {'x': 3.396106431680106, 'y': -5.738011819396746}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,983] Trial 107 finished with value: 5.529498954758632 and parameters: {'x': 3.232572195166462, 'y': -7.339959215198864}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:51,995] Trial 108 finished with value: 0.953768836332742 and parameters: {'x': 2.796304910296459, 'y': -5.955132004889067}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,005] Trial 109 finished with value: 3.972017959444164 and parameters: {'x': 4.463266000311749, 'y': -3.6469033398253394}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,028] Trial 110 finished with value: 0.6872160997083968 and parameters: {'x': 2.233908151075446, 'y': -5.316732345553395}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,043] Trial 111 finished with value: 2.2600286407077896 and parameters: {'x': 1.5539797663126298, 'y': -5.411161920019976}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,053] Trial 112 finished with value: 2.8486930510547217 and parameters: {'x': 2.3808193970541276, 'y': -6.570130068494425}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,065] Trial 113 finished with value: 0.9781205530152279 and parameters: {'x': 3.5269991228736255, 'y': -4.163105456162094}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,080] Trial 114 finished with value: 15.432807086033673 and parameters: {'x': 3.0739664595192453, 'y': -8.92776476496491}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,095] Trial 115 finished with value: 30.853653469863254 and parameters: {'x': 0.2986257868277984, 'y': -9.853476159441964}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,108] Trial 116 finished with value: 1.4879061998849412 and parameters: {'x': 2.255433208725281, 'y': -5.966191747644229}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,120] Trial 117 finished with value: 13.295526717458575 and parameters: {'x': 0.8832497961918999, 'y': -7.968988934323761}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,136] Trial 118 finished with value: 9.330890711128994 and parameters: {'x': 5.16336904432662, 'y': -7.156553984758629}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,147] Trial 119 finished with value: 0.24825806573799342 and parameters: {'x': 3.4975409782129168, 'y': -5.0266653471180724}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,152] Trial 120 finished with value: 3.2905468957459485 and parameters: {'x': 2.803625563518089, 'y': -3.1966741901579847}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,166] Trial 121 finished with value: 0.2689256283049509 and parameters: {'x': 3.4949894111231283, 'y': -5.154632180288999}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,168] Trial 122 finished with value: 0.10298205575060182 and parameters: {'x': 3.3134769527468446, 'y': -5.0686604387340655}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,181] Trial 123 finished with value: 1.787553377215131 and parameters: {'x': 4.335032735818652, 'y': -5.072394554406363}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,191] Trial 124 finished with value: 2.324404918547088 and parameters: {'x': 1.6429124113544393, 'y': -4.305220757872498}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,193] Trial 125 finished with value: 2.1697356414014144 and parameters: {'x': 2.4860163709109, 'y': -3.6195810525678036}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,210] Trial 126 finished with value: 2.4045897232696136 and parameters: {'x': 3.7979104351159805, 'y': -6.329634784744533}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,210] Trial 127 finished with value: 0.01900332987799084 and parameters: {'x': 3.1095052071011478, 'y': -5.083737324388385}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,232] Trial 128 finished with value: 12.91342577260379 and parameters: {'x': 4.876417491175637, 'y': -1.9352841613921337}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,241] Trial 129 finished with value: 1.037276031561213 and parameters: {'x': 3.159507012625737, 'y': -3.99410062904661}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,252] Trial 130 finished with value: 1.5365397735389323 and parameters: {'x': 4.169346458991724, 'y': -4.588698854387142}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,264] Trial 131 finished with value: 0.28001245428953525 and parameters: {'x': 3.462127768951988, 'y': -5.2577797110964966}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,270] Trial 132 finished with value: 0.19073152707644855 and parameters: {'x': 3.4364209802589305, 'y': -5.016378494017545}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,283] Trial 133 finished with value: 2.996091336982016 and parameters: {'x': 3.6165442418745304, 'y': -6.617394365884022}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,299] Trial 134 finished with value: 0.038986615293083664 and parameters: {'x': 2.809291293150419, 'y': -4.948845289319123}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,304] Trial 135 finished with value: 0.054147916246852015 and parameters: {'x': 2.7873831951075787, 'y': -4.905437795477315}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,314] Trial 136 finished with value: 4.731312932321391 and parameters: {'x': 2.787549129584373, 'y': -2.8352419165225338}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,328] Trial 137 finished with value: 1.3009374789447146 and parameters: {'x': 1.859906060535098, 'y': -4.966484508953096}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,342] Trial 138 finished with value: 2.2738648782052526 and parameters: {'x': 4.507090659860156, 'y': -4.9495755895668285}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,355] Trial 139 finished with value: 2.807815765418329 and parameters: {'x': 3.949107827054264, 'y': -3.6190546361123976}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,368] Trial 140 finished with value: 6.492844774567884 and parameters: {'x': 3.031547083879511, 'y': -2.452089178156625}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,378] Trial 141 finished with value: 1.362733957534469 and parameters: {'x': 2.5794289919748543, 'y': -6.088969230393211}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,389] Trial 142 finished with value: 4.241951325926502 and parameters: {'x': 3.422829771250565, 'y': -7.015729721582409}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,397] Trial 143 finished with value: 0.9152274228424239 and parameters: {'x': 2.0772160820766112, 'y': -5.252383168346038}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,413] Trial 144 finished with value: 0.13176898433254164 and parameters: {'x': 2.870507652816312, 'y': -4.660882444639914}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,419] Trial 145 finished with value: 0.1414126710156717 and parameters: {'x': 2.908881683064724, 'y': -4.635157399232828}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,434] Trial 146 finished with value: 0.9880730762516261 and parameters: {'x': 3.051451470005008, 'y': -4.0073138348471105}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,445] Trial 147 finished with value: 2.8507797244965536 and parameters: {'x': 1.3548324312175601, 'y': -4.620258778741325}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,463] Trial 148 finished with value: 4.5845521279998716 and parameters: {'x': 4.145970732838968, 'y': -3.191325566201482}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,475] Trial 149 finished with value: 1.4030673781271525 and parameters: {'x': 2.7534459852431636, 'y': -6.158567432622909}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,490] Trial 150 finished with value: 0.7580316025359402 and parameters: {'x': 2.2880053670726475, 'y': -4.498905951723048}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,514] Trial 151 finished with value: 0.3582050468160008 and parameters: {'x': 3.532650131301188, 'y': -5.272926518390625}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,528] Trial 152 finished with value: 1.1349977121014678 and parameters: {'x': 3.426848955418518, 'y': -5.976113559663827}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,543] Trial 153 finished with value: 0.13431204091057128 and parameters: {'x': 3.0559559683475133, 'y': -5.3621891363871415}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,555] Trial 154 finished with value: 0.22142052246167968 and parameters: {'x': 2.8099824012246986, 'y': -5.430480934092729}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,569] Trial 155 finished with value: 285.1876880738851 and parameters: {'x': 2.7616868990896095, 'y': 11.885819344640035}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,582] Trial 156 finished with value: 1.3666155446933903 and parameters: {'x': 3.179767441979331, 'y': -3.8448812998234345}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,593] Trial 157 finished with value: 5.360321623148577 and parameters: {'x': 1.9965924326222266, 'y': -7.086503025849135}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,600] Trial 158 finished with value: 198.14642651841515 and parameters: {'x': -7.212073290868677, 'y': -14.688136333699157}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,615] Trial 159 finished with value: 28.695529107277096 and parameters: {'x': -2.309761308679512, 'y': -5.708494144031643}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,628] Trial 160 finished with value: 0.9985242229349535 and parameters: {'x': 3.927788223984285, 'y': -4.628875715735227}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,637] Trial 161 finished with value: 0.27413390287673395 and parameters: {'x': 2.5379054810904487, 'y': -5.246175868984928}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,648] Trial 162 finished with value: 2.909759015313998 and parameters: {'x': 2.5882549067646115, 'y': -6.65536249610488}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,657] Trial 163 finished with value: 0.15946182449654708 and parameters: {'x': 3.0865155752536007, 'y': -5.3898421215506165}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,669] Trial 164 finished with value: 0.5258062252553796 and parameters: {'x': 2.9823672270795316, 'y': -5.724910553499199}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,683] Trial 165 finished with value: 2.2947773319441502 and parameters: {'x': 1.8285346251688732, 'y': -4.0395593680419815}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,696] Trial 166 finished with value: 2.5232818887964408 and parameters: {'x': 2.3924934677779, 'y': -6.467725349683625}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,701] Trial 167 finished with value: 0.03725118494701189 and parameters: {'x': 3.0058358666825815, 'y': -4.807082588636808}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,717] Trial 168 finished with value: 2.488751581879513 and parameters: {'x': 3.0035511308952745, 'y': -3.4224262390148352}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,734] Trial 169 finished with value: 1.163394722989691 and parameters: {'x': 3.9690478932110262, 'y': -4.526353609057387}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,746] Trial 170 finished with value: 9.192428758491547 and parameters: {'x': 4.4251437391213875, 'y': -7.6760781157011575}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,756] Trial 171 finished with value: 0.18761052422455404 and parameters: {'x': 2.568887762452271, 'y': -5.041866010810016}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,764] Trial 172 finished with value: 0.09498915846119736 and parameters: {'x': 3.26313168595494, 'y': -4.839529210422245}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,778] Trial 173 finished with value: 0.35888712034280296 and parameters: {'x': 2.975623044868037, 'y': -4.401424286826389}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,793] Trial 174 finished with value: 1.4582071455864916 and parameters: {'x': 2.146708170972781, 'y': -5.8544590101940965}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,806] Trial 175 finished with value: 1.7010537350687365 and parameters: {'x': 3.269946338635134, 'y': -3.723997370956383}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,814] Trial 176 finished with value: 0.07914307207816854 and parameters: {'x': 2.756444618706996, 'y': -4.859202811386775}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,824] Trial 177 finished with value: 7.519100927236021 and parameters: {'x': 1.0818672355036678, 'y': -3.040441982231279}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,844] Trial 178 finished with value: 1.7489146486359715 and parameters: {'x': 2.665132444694522, 'y': -6.27936639358696}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,856] Trial 179 finished with value: 2.592002105927614 and parameters: {'x': 1.526065558241633, 'y': -4.352296852465526}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,871] Trial 180 finished with value: 0.6367864033888716 and parameters: {'x': 2.3906156353407284, 'y': -5.515205880690125}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,884] Trial 181 finished with value: 0.036095278367581224 and parameters: {'x': 3.1404260417601972, 'y': -4.872032015085239}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,893] Trial 182 finished with value: 0.028578477308975767 and parameters: {'x': 2.9820049018204178, 'y': -4.831908793357645}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,910] Trial 183 finished with value: 0.027896065572671096 and parameters: {'x': 2.888797392734774, 'y': -4.87538039596401}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,925] Trial 184 finished with value: 1.2957742813352833 and parameters: {'x': 1.8893804506490115, 'y': -4.7504033294799575}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,935] Trial 185 finished with value: 0.99320969478322 and parameters: {'x': 3.043974988771996, 'y': -4.004371607904976}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,948] Trial 186 finished with value: 47.23613345294734 and parameters: {'x': 9.734123442149956, 'y': -3.6260586188509443}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,962] Trial 187 finished with value: 0.7969394098663473 and parameters: {'x': 3.8484468875516473, 'y': -4.722372031541724}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,978] Trial 188 finished with value: 1.5703929992062995 and parameters: {'x': 2.195281571797783, 'y': -5.960635857397616}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:52,984] Trial 189 finished with value: 4.734917489819903 and parameters: {'x': 2.6977471894930405, 'y': -2.8451077223302907}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,001] Trial 190 finished with value: 0.6761595771709361 and parameters: {'x': 3.1725860641691632, 'y': -4.196026351410985}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,012] Trial 191 finished with value: 0.08085620730271126 and parameters: {'x': 2.8114735064785417, 'y': -5.212870778979208}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,027] Trial 192 finished with value: 0.024495862008745338 and parameters: {'x': 2.901240765207861, 'y': -5.121418596401114}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,037] Trial 193 finished with value: 0.3424681384852067 and parameters: {'x': 2.4412449632875637, 'y': -4.826043259878524}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,047] Trial 194 finished with value: 0.4714060386260148 and parameters: {'x': 2.8811931320942468, 'y': -5.6762329234549584}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,058] Trial 195 finished with value: 3.789118584684718 and parameters: {'x': 2.0937219125859414, 'y': -6.722724183657336}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,070] Trial 196 finished with value: 0.6235997121375366 and parameters: {'x': 3.0782958664958193, 'y': -4.214207744103312}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,083] Trial 197 finished with value: 0.5229339768403523 and parameters: {'x': 3.715329822766225, 'y': -5.106005761643381}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,093] Trial 198 finished with value: 1.4821491820715902 and parameters: {'x': 2.461927484587714, 'y': -6.092074699931047}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,102] Trial 199 finished with value: 4.217538637054062 and parameters: {'x': 1.680078312781708, 'y': -3.4266769636642067}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,115] Trial 200 finished with value: 0.14322897617853797 and parameters: {'x': 3.198506878003906, 'y': -4.677782688913708}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,130] Trial 201 finished with value: 0.23330596191487274 and parameters: {'x': 3.314895778984882, 'y': -4.63373969599153}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,138] Trial 202 finished with value: 0.25765632883744083 and parameters: {'x': 2.762332566319437, 'y': -5.4485203672132805}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,150] Trial 203 finished with value: 0.9553759381599647 and parameters: {'x': 3.289023930149987, 'y': -4.066275679892282}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,158] Trial 204 finished with value: 0.053460737664183654 and parameters: {'x': 2.771054002104294, 'y': -4.967681774310414}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,167] Trial 205 finished with value: 1.3063709197693192 and parameters: {'x': 3.7677156346206493, 'y': -5.846748855404206}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,180] Trial 206 finished with value: 0.1982166205228699 and parameters: {'x': 2.8897664036577373, 'y': -4.568647273382536}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,197] Trial 207 finished with value: 0.7810908847645477 and parameters: {'x': 2.172206136626782, 'y': -5.3095936118949965}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,211] Trial 208 finished with value: 2.0466103176619557 and parameters: {'x': 3.12074627661628, 'y': -6.425493126726769}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,218] Trial 209 finished with value: 1.7817818590453602 and parameters: {'x': 3.6109183472724977, 'y': -3.8131720293103974}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,230] Trial 210 finished with value: 1.517919432982076 and parameters: {'x': 4.198626732420071, 'y': -4.71502037035946}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,238] Trial 211 finished with value: 0.18564071683109915 and parameters: {'x': 2.5949675097499214, 'y': -5.146933313693387}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,251] Trial 212 finished with value: 0.3278055698233962 and parameters: {'x': 2.703950389412949, 'y': -5.490061422573387}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,264] Trial 213 finished with value: 0.03900491072253665 and parameters: {'x': 3.1951836876552266, 'y': -5.030137000445359}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,278] Trial 214 finished with value: 0.39168724190414256 and parameters: {'x': 3.265269121270611, 'y': -4.433149459553525}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,292] Trial 215 finished with value: 1.0199139909493324 and parameters: {'x': 3.052061593609949, 'y': -6.008565110154087}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,303] Trial 216 finished with value: 1.7375044600759826 and parameters: {'x': 3.6630582763384165, 'y': -3.8607642112999123}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,321] Trial 217 finished with value: 0.6716872118045001 and parameters: {'x': 2.2349837777879586, 'y': -4.705997633416129}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,331] Trial 218 finished with value: 0.6566560200080841 and parameters: {'x': 3.3773281526999197, 'y': -5.7171328225567075}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,341] Trial 219 finished with value: 2.6972851150035506 and parameters: {'x': 2.834672696112396, 'y': -3.3660012247272624}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,351] Trial 220 finished with value: 0.824616543883544 and parameters: {'x': 3.9077635008476097, 'y': -5.0241240629338355}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,367] Trial 221 finished with value: 0.38788673485907155 and parameters: {'x': 2.46079051088478, 'y': -5.311672683607619}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,378] Trial 222 finished with value: 0.5692011796146761 and parameters: {'x': 2.825766387560132, 'y': -4.265940174160968}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,389] Trial 223 finished with value: 0.06243408999852723 and parameters: {'x': 3.243176241909896, 'y': -5.0574404506346085}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,396] Trial 224 finished with value: 1.6282082092587025 and parameters: {'x': 3.3370466373053564, 'y': -6.2306940210872295}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,405] Trial 225 finished with value: 0.025788392083671223 and parameters: {'x': 3.0819315199188866, 'y': -4.861885489077171}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,416] Trial 226 finished with value: 0.700745298799365 and parameters: {'x': 3.514754839293346, 'y': -4.339869138561568}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,432] Trial 227 finished with value: 0.03285777350005743 and parameters: {'x': 3.0736062667558044, 'y': -4.834350095097127}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,436] Trial 228 finished with value: 2.2900327809398777 and parameters: {'x': 3.9393080579492303, 'y': -3.813520689935335}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,449] Trial 229 finished with value: 0.05650900086114555 and parameters: {'x': 3.13946335700827, 'y': -4.807492927628283}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,458] Trial 230 finished with value: 0.5253785568431015 and parameters: {'x': 2.286944981167666, 'y': -4.86988045127222}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,459] Trial 231 finished with value: 0.1301310394360742 and parameters: {'x': 3.0525808776133725, 'y': -4.643115858091899}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,476] Trial 232 finished with value: 0.3887351133900825 and parameters: {'x': 2.980838974353188, 'y': -4.376808240999414}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,479] Trial 233 finished with value: 44.72065553193265 and parameters: {'x': -3.6855327907429047, 'y': -5.155906497087344}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,494] Trial 234 finished with value: 1.5068869741412156 and parameters: {'x': 3.532246933918162, 'y': -3.893835375960734}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,494] Trial 235 finished with value: 0.7378247843122274 and parameters: {'x': 2.637561536436844, 'y': -5.778757436203473}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,514] Trial 236 finished with value: 0.025329943274452284 and parameters: {'x': 2.982991764426272, 'y': -4.841757580917376}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,528] Trial 237 finished with value: 0.09631708046109655 and parameters: {'x': 3.2852719901611347, 'y': -5.122216905911588}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,538] Trial 238 finished with value: 0.24915149647328289 and parameters: {'x': 3.4149654754844017, 'y': -4.722592086217269}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,547] Trial 239 finished with value: 4.033764176171667 and parameters: {'x': 4.101681892187785, 'y': -3.3206962202754355}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,555] Trial 240 finished with value: 1.1904896406711885 and parameters: {'x': 3.7513882948408988, 'y': -4.2088582484489425}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,568] Trial 241 finished with value: 30.76343032339084 and parameters: {'x': 8.53039877973666, 'y': -5.422042249636348}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,579] Trial 242 finished with value: 79.30304800073966 and parameters: {'x': 3.071857440955154, 'y': 3.904935963212707}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,579] Trial 243 finished with value: 0.21934359348189042 and parameters: {'x': 2.5319104581789147, 'y': -4.984645055531951}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,593] Trial 244 finished with value: 0.5571263949352124 and parameters: {'x': 3.1950473959957657, 'y': -5.72047408575915}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,605] Trial 245 finished with value: 0.0215744589986777 and parameters: {'x': 2.8592250404775155, 'y': -4.958084969639513}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,612] Trial 246 finished with value: 0.058705375295322826 and parameters: {'x': 2.774071933997618, 'y': -4.912467809991146}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,612] Trial 247 finished with value: 2.5923090909162707 and parameters: {'x': 2.0314314650991614, 'y': -6.286150879219197}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,626] Trial 248 finished with value: 0.21793545772302014 and parameters: {'x': 2.5334071619793685, 'y': -5.015052615416363}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,650] Trial 249 finished with value: 0.9199778781878123 and parameters: {'x': 3.616767685484142, 'y': -4.265441969392243}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,680] Trial 250 finished with value: 0.5450002706145965 and parameters: {'x': 2.7990224427034214, 'y': -5.710357861980634}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,696] Trial 251 finished with value: 0.17599832731841103 and parameters: {'x': 3.37094911829481, 'y': -4.804053377281684}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,713] Trial 252 finished with value: 1.499551069763986 and parameters: {'x': 2.353345067899103, 'y': -3.960101702783599}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,725] Trial 253 finished with value: 48.199817376935485 and parameters: {'x': 2.9798961753274793, 'y': 1.942579723213052}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,737] Trial 254 finished with value: 47.0546637274818 and parameters: {'x': 3.3505338041327253, 'y': -11.850678052546481}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,753] Trial 255 finished with value: 0.17622531179064793 and parameters: {'x': 2.7536143985955257, 'y': -5.3398815193728595}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,765] Trial 256 finished with value: 3.1801937285587325 and parameters: {'x': 1.864495510214013, 'y': -6.375072100740393}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,775] Trial 257 finished with value: 0.827543393474181 and parameters: {'x': 3.7680540883948814, 'y': -4.512520450917078}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,789] Trial 258 finished with value: 0.9653327800883094 and parameters: {'x': 2.3982661563354752, 'y': -5.776691162224102}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,798] Trial 259 finished with value: 19.400191704135537 and parameters: {'x': -1.2057883157334928, 'y': -3.691743011723169}. Best is trial 35 with value: 0.0034147471052381672.\n",
      "[I 2025-02-11 16:15:53,808] Trial 260 finished with value: 0.00016793996632639578 and parameters: {'x': 3.0127152843336997, 'y': -5.00250230106893}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:53,816] Trial 261 finished with value: 3.648113335787717 and parameters: {'x': 3.3957659331511523, 'y': -6.868550952461483}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:53,826] Trial 262 finished with value: 1.7770085752600442 and parameters: {'x': 4.316595565456271, 'y': -5.2087694716210375}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:53,834] Trial 263 finished with value: 1.219332323587461 and parameters: {'x': 2.634863715210891, 'y': -6.042116988210953}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:53,844] Trial 264 finished with value: 0.7374035157304658 and parameters: {'x': 2.151263881577017, 'y': -5.13057762830881}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:53,856] Trial 265 finished with value: 132.94386812453524 and parameters: {'x': 3.8397907504165065, 'y': 6.499505190226669}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:53,870] Trial 266 finished with value: 0.848433127624037 and parameters: {'x': 3.1693078994963653, 'y': -4.094589616366056}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:53,885] Trial 267 finished with value: 4.870836178315173 and parameters: {'x': 2.813946457335121, 'y': -2.8008592001472437}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:53,901] Trial 268 finished with value: 0.5897183176607805 and parameters: {'x': 3.5757439912988467, 'y': -5.508170418407107}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:53,909] Trial 269 finished with value: 0.3228101362523653 and parameters: {'x': 2.4560901129201653, 'y': -4.8357679355632195}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:53,919] Trial 270 finished with value: 2.167240710659826 and parameters: {'x': 3.1095896485928174, 'y': -3.531929559053405}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:53,936] Trial 271 finished with value: 2.302535441222657 and parameters: {'x': 1.7386043503732114, 'y': -4.156544929278821}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:53,949] Trial 272 finished with value: 1.2214363758215554 and parameters: {'x': 2.7532562635317124, 'y': -6.077290074369584}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:53,962] Trial 273 finished with value: 0.8825747574207873 and parameters: {'x': 3.9390780377554506, 'y': -4.973406834972878}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:53,979] Trial 274 finished with value: 160.51479548164096 and parameters: {'x': -9.654817023461034, 'y': -4.391393736179303}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:53,987] Trial 275 finished with value: 0.504797621949225 and parameters: {'x': 3.3530253609483887, 'y': -5.616579854095546}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,001] Trial 276 finished with value: 3.3042880269373587 and parameters: {'x': 2.316663175299123, 'y': -6.684440206996105}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,009] Trial 277 finished with value: 0.0015686638291251464 and parameters: {'x': 3.030392591808035, 'y': -4.974604051655524}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,027] Trial 278 finished with value: 0.06893664504361748 and parameters: {'x': 2.8962144417426416, 'y': -5.241174631627843}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,029] Trial 279 finished with value: 1.8930804017993481 and parameters: {'x': 1.9114509747289192, 'y': -5.8415113911176295}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,043] Trial 280 finished with value: 2.79871850488605 and parameters: {'x': 2.768199974115427, 'y': -3.3431996943246416}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,060] Trial 281 finished with value: 0.019033601369570864 and parameters: {'x': 2.9641265538720454, 'y': -5.13321673030245}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,069] Trial 282 finished with value: 1.175843268033821 and parameters: {'x': 2.157653009122825, 'y': -4.317142170730986}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,076] Trial 283 finished with value: 0.3726716886454584 and parameters: {'x': 2.616600326042296, 'y': -5.475054079715757}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,097] Trial 284 finished with value: 1.3205909595474348 and parameters: {'x': 2.912889378971168, 'y': -6.14586329867546}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,119] Trial 285 finished with value: 0.36350367067284345 and parameters: {'x': 2.4027555481137592, 'y': -4.917521303575121}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,132] Trial 286 finished with value: 1.5004130444312715 and parameters: {'x': 3.6454299259514213, 'y': -3.9589268733092693}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,147] Trial 287 finished with value: 0.33598055183963016 and parameters: {'x': 3.0910551896131175, 'y': -4.427558296169689}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,162] Trial 288 finished with value: 5.496172348929121 and parameters: {'x': 2.873458667482369, 'y': -7.340974079329753}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,172] Trial 289 finished with value: 0.9506017364881715 and parameters: {'x': 2.1621044723564635, 'y': -5.4985306622898245}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,181] Trial 290 finished with value: 3.540379336479533 and parameters: {'x': 4.192415408737313, 'y': -6.455515314067619}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,192] Trial 291 finished with value: 0.3859832022370451 and parameters: {'x': 3.570392204222591, 'y': -4.753756349119131}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,199] Trial 292 finished with value: 4.229346380735306 and parameters: {'x': 1.414055297315731, 'y': -3.690753735631447}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,211] Trial 293 finished with value: 0.28026913632981465 and parameters: {'x': 2.5173973932243827, 'y': -5.217632397090124}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,211] Trial 294 finished with value: 0.3140817921258818 and parameters: {'x': 3.0830408552346693, 'y': -4.4457563636019115}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,234] Trial 295 finished with value: 0.7117690006944214 and parameters: {'x': 2.67246894804517, 'y': -5.77749110007754}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,251] Trial 296 finished with value: 5.008237658239695 and parameters: {'x': 1.9200081726528584, 'y': -3.0399348706986604}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,264] Trial 297 finished with value: 0.22635788462060785 and parameters: {'x': 3.4147812682376273, 'y': -4.766945533962995}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,273] Trial 298 finished with value: 1.161989155837424 and parameters: {'x': 3.0169613098866055, 'y': -3.922177440482732}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,283] Trial 299 finished with value: 3.372644996540574 and parameters: {'x': 3.761803460424336, 'y': -6.671017798895655}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,296] Trial 300 finished with value: 0.44769697800408553 and parameters: {'x': 2.4323820943340726, 'y': -5.354269517700171}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,304] Trial 301 finished with value: 1.1528445235217957 and parameters: {'x': 3.218355646562176, 'y': -6.051268441044536}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,316] Trial 302 finished with value: 30.478181309291436 and parameters: {'x': 7.849701755824128, 'y': -2.3620890483475745}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,330] Trial 303 finished with value: 0.07053220652405773 and parameters: {'x': 2.736982390153997, 'y': -4.963204029637018}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,341] Trial 304 finished with value: 373.7459013621844 and parameters: {'x': 2.168220001978306, 'y': 14.314606995667178}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,352] Trial 305 finished with value: 0.20385214636063448 and parameters: {'x': 2.6407392744241043, 'y': -5.273466410038446}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,362] Trial 306 finished with value: 2.5295652173465832 and parameters: {'x': 1.707609622321453, 'y': -4.073019779590478}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,368] Trial 307 finished with value: 0.7736749887579296 and parameters: {'x': 2.7774295714248423, 'y': -5.850962627312034}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,379] Trial 308 finished with value: 0.17452712768646705 and parameters: {'x': 2.955347906158043, 'y': -4.584628698389024}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,383] Trial 309 finished with value: 2.57270165841669 and parameters: {'x': 2.285562209252727, 'y': -3.563935829578342}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,393] Trial 310 finished with value: 0.33329131663005107 and parameters: {'x': 3.5767123371745657, 'y': -4.973652385673441}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,401] Trial 311 finished with value: 3.8458239784699844 and parameters: {'x': 4.507605443413041, 'y': -6.2541729567573014}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,410] Trial 312 finished with value: 1.3098738025697674 and parameters: {'x': 3.9537113365024394, 'y': -5.632699367153546}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,418] Trial 313 finished with value: 32.33664881876287 and parameters: {'x': 2.7268924017769756, 'y': 0.6799701635268924}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,435] Trial 314 finished with value: 0.624472850629346 and parameters: {'x': 3.307071627467254, 'y': -4.271865488914337}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,448] Trial 315 finished with value: 0.36494225975784905 and parameters: {'x': 2.3964409514772793, 'y': -5.025665827557224}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,465] Trial 316 finished with value: 231.8211292494077 and parameters: {'x': 2.9889185453351748, 'y': 10.225669326856217}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,479] Trial 317 finished with value: 53.6971402737344 and parameters: {'x': -4.313864311419994, 'y': -4.547751055422645}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,490] Trial 318 finished with value: 3.698987358299439 and parameters: {'x': 3.5211894712620495, 'y': -6.851310047870163}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,502] Trial 319 finished with value: 1.5746357319576472 and parameters: {'x': 1.8468349276116482, 'y': -5.4948192071668345}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,519] Trial 320 finished with value: 1.2758139132615698 and parameters: {'x': 3.044248560858059, 'y': -3.8713477160243017}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,529] Trial 321 finished with value: 3.4622137455491924 and parameters: {'x': 2.5732163136594544, 'y': -3.1889038041498825}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,535] Trial 322 finished with value: 1.3662585573683232 and parameters: {'x': 4.168798431355771, 'y': -4.98700830155016}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,552] Trial 323 finished with value: 1.901667932005254 and parameters: {'x': 2.0618685511586583, 'y': -6.010731080307764}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,561] Trial 324 finished with value: 0.5813894717351972 and parameters: {'x': 3.3252858674717363, 'y': -4.310377946873538}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,567] Trial 325 finished with value: 0.30528574173336537 and parameters: {'x': 2.8214521664731205, 'y': -5.522882790763115}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,580] Trial 326 finished with value: 0.7096690196311458 and parameters: {'x': 3.7642362052044698, 'y': -4.645582107836219}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,589] Trial 327 finished with value: 2.2390799796872747 and parameters: {'x': 1.5156293473236873, 'y': -5.189007262190033}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,596] Trial 328 finished with value: 1.8629441612929467 and parameters: {'x': 2.4204903338893375, 'y': -6.235764017997472}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,608] Trial 329 finished with value: 1.4968969226949451 and parameters: {'x': 3.1627823601007004, 'y': -3.7873999728125556}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,618] Trial 330 finished with value: 0.14283785684667413 and parameters: {'x': 2.877256810384062, 'y': -4.642547952517292}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,631] Trial 331 finished with value: 26.26366833831741 and parameters: {'x': -0.146171495104493, 'y': -0.9545985042632212}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,632] Trial 332 finished with value: 4.567889932236663 and parameters: {'x': 3.5175226845675307, 'y': -7.073658651561216}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,651] Trial 333 finished with value: 1.0230088127080526 and parameters: {'x': 2.164919980971697, 'y': -5.570657668421044}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,659] Trial 334 finished with value: 0.7286895214278738 and parameters: {'x': 2.6730258255572816, 'y': -4.211471363439871}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,666] Trial 335 finished with value: 0.04143164684743235 and parameters: {'x': 3.199285570106469, 'y': -4.958564406668034}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,676] Trial 336 finished with value: 4.160469223599238 and parameters: {'x': 3.7969573000618557, 'y': -3.1224142401803974}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,680] Trial 337 finished with value: 0.09367365959526269 and parameters: {'x': 3.27388525707337, 'y': -4.8633964658102995}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,697] Trial 338 finished with value: 2.142958123829176 and parameters: {'x': 3.518276999635596, 'y': -3.6309320413223087}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,712] Trial 339 finished with value: 2.0522366852985017 and parameters: {'x': 3.9203910997049336, 'y': -6.097778169250256}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,722] Trial 340 finished with value: 0.6503616335045006 and parameters: {'x': 3.1060982951388527, 'y': -4.200559704997847}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,731] Trial 341 finished with value: 0.3568046935066491 and parameters: {'x': 2.44420354828368, 'y': -5.21884925808921}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,739] Trial 342 finished with value: 2.8228963586322244 and parameters: {'x': 4.65442120473091, 'y': -4.707106101174931}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,747] Trial 343 finished with value: 14.377775595891393 and parameters: {'x': -0.7406702031305552, 'y': -5.620614233886562}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,759] Trial 344 finished with value: 85.73694204031382 and parameters: {'x': 3.0437644788173586, 'y': -14.259321071801521}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,765] Trial 345 finished with value: 3.7482994081656686 and parameters: {'x': 4.148580495996205, 'y': -6.558544915099588}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,775] Trial 346 finished with value: 0.6608139902017569 and parameters: {'x': 2.700241617413417, 'y': -4.244381774789125}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,791] Trial 347 finished with value: 0.22670128859733377 and parameters: {'x': 3.4594485491522926, 'y': -5.124933259299464}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,806] Trial 348 finished with value: 1.5353681279525997 and parameters: {'x': 2.099272947897003, 'y': -5.850916509160825}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,821] Trial 349 finished with value: 2.118926325393513 and parameters: {'x': 3.2615955059207296, 'y': -3.568045351040896}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,830] Trial 350 finished with value: 0.32074319545424496 and parameters: {'x': 2.515088335777189, 'y': -4.707418603881059}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,842] Trial 351 finished with value: 0.6807906789038374 and parameters: {'x': 3.7343572259402955, 'y': -5.376178340170073}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,842] Trial 352 finished with value: 0.7654097564840029 and parameters: {'x': 2.935007791617798, 'y': -4.127540391001619}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,862] Trial 353 finished with value: 6.954840622818517 and parameters: {'x': 1.8804891045390604, 'y': -2.612211069260358}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,876] Trial 354 finished with value: 5.7850170556909895 and parameters: {'x': 1.0833253361836166, 'y': -6.4530572214387645}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,879] Trial 355 finished with value: 0.13849662911688124 and parameters: {'x': 2.9986643386939704, 'y': -4.6278510444381755}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,898] Trial 356 finished with value: 0.8278669004876877 and parameters: {'x': 2.4713124254984207, 'y': -5.740510870315436}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,899] Trial 357 finished with value: 0.1146513827623122 and parameters: {'x': 3.3385837979804185, 'y': -4.996479416601279}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,916] Trial 358 finished with value: 3.0338324493548123 and parameters: {'x': 4.1129741463178116, 'y': -3.6601787436441566}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,920] Trial 359 finished with value: 0.09756013074675057 and parameters: {'x': 2.805039215903548, 'y': -5.244029554380709}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,932] Trial 360 finished with value: 0.9744677730202465 and parameters: {'x': 3.6720519486929923, 'y': -4.276941253231663}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,942] Trial 361 finished with value: 1.231029680136078 and parameters: {'x': 2.338820005493764, 'y': -5.890994217153406}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,952] Trial 362 finished with value: 5.677847537453246 and parameters: {'x': 3.179581675705949, 'y': -7.376046708127576}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,962] Trial 363 finished with value: 0.18224774547478584 and parameters: {'x': 2.690211836793657, 'y': -4.70626706107073}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,971] Trial 364 finished with value: 12.28925775209548 and parameters: {'x': 1.9985036607496809, 'y': -1.6404966387033202}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,983] Trial 365 finished with value: 0.3102125272941885 and parameters: {'x': 3.5146706373170487, 'y': -5.212900592713716}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,990] Trial 366 finished with value: 5.756504053240873 and parameters: {'x': 1.5419681079785734, 'y': -3.0945743113179955}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,993] Trial 367 finished with value: 1.8184947444188488 and parameters: {'x': 2.9543281603022, 'y': -6.347742122023893}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:54,993] Trial 368 finished with value: 1.0914330229842166 and parameters: {'x': 2.34440829926396, 'y': -4.186592018166626}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,016] Trial 369 finished with value: 10.175237649453814 and parameters: {'x': 6.116128706456317, 'y': -5.681894078470179}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,029] Trial 370 finished with value: 1.7530733983971987 and parameters: {'x': 3.263051958026661, 'y': -3.7023571116152416}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,034] Trial 371 finished with value: 0.9032943604854542 and parameters: {'x': 3.9355356658953813, 'y': -4.832466784418314}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,045] Trial 372 finished with value: 11.36398237298839 and parameters: {'x': 2.7867021428272394, 'y': -8.364295824851599}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,049] Trial 373 finished with value: 2.28682660781605 and parameters: {'x': 4.469443846247637, 'y': -5.357157375033752}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,066] Trial 374 finished with value: 63.78649247948275 and parameters: {'x': 3.673601458311508, 'y': 2.958187831085879}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,069] Trial 375 finished with value: 0.6831713326144916 and parameters: {'x': 3.1489399357542402, 'y': -4.1869881746542585}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,082] Trial 376 finished with value: 1.6438847638569523 and parameters: {'x': 2.252105854541348, 'y': -6.041412075523241}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,082] Trial 377 finished with value: 0.21834908248466767 and parameters: {'x': 2.6245765234202825, 'y': -4.721780130620644}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,100] Trial 378 finished with value: 0.3842487078091781 and parameters: {'x': 3.5634475308223235, 'y': -5.258409728569582}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,112] Trial 379 finished with value: 2.5396323905044436 and parameters: {'x': 3.041629387029316, 'y': -3.4069214129114638}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,132] Trial 380 finished with value: 3.761953675903776 and parameters: {'x': 2.612154473705066, 'y': -6.900402463594694}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,155] Trial 381 finished with value: 1.5060867816063082 and parameters: {'x': 1.9061020880340953, 'y': -4.44369600055101}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,167] Trial 382 finished with value: 0.7974725467990006 and parameters: {'x': 3.360288666282932, 'y': -5.817107473804436}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,180] Trial 383 finished with value: 1.1479441353465947 and parameters: {'x': 4.070324987508914, 'y': -5.0484619073153105}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,190] Trial 384 finished with value: 1.0179687558030932 and parameters: {'x': 2.8579588734503067, 'y': -4.001104072402141}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,192] Trial 385 finished with value: 2.6237962373228005 and parameters: {'x': 2.1928622304279766, 'y': -6.404394837021662}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,211] Trial 386 finished with value: 5.948628069612248 and parameters: {'x': 0.5666655691521667, 'y': -4.834133736815772}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,218] Trial 387 finished with value: 0.6102772011014415 and parameters: {'x': 3.2336622496881686, 'y': -5.745438900361462}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,229] Trial 388 finished with value: 37.12702857949618 and parameters: {'x': 9.058281694147269, 'y': -4.348654090473982}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,229] Trial 389 finished with value: 110.26079378568332 and parameters: {'x': 2.5340198380260417, 'y': 5.490169506463184}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,251] Trial 390 finished with value: 0.6525725736943367 and parameters: {'x': 3.608343159291885, 'y': -5.53149898799255}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,260] Trial 391 finished with value: 5.102089015404284 and parameters: {'x': 2.9444216538977015, 'y': -2.7419034425320032}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,263] Trial 392 finished with value: 1.7613483228398692 and parameters: {'x': 3.296162073723698, 'y': -3.7063090210844214}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,278] Trial 393 finished with value: 15.775965743541907 and parameters: {'x': 6.971487624825641, 'y': -4.942975536839915}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,283] Trial 394 finished with value: 86.75286551454076 and parameters: {'x': -6.3043290893969495, 'y': -4.573003851606956}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,296] Trial 395 finished with value: 2.4092222692471754 and parameters: {'x': 3.9089151592573392, 'y': -6.258211231280098}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,304] Trial 396 finished with value: 0.3304258565318326 and parameters: {'x': 2.52326212924819, 'y': -5.321164847271402}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,313] Trial 397 finished with value: 4.967672156629627 and parameters: {'x': 4.914840991191406, 'y': -3.859361523057047}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,319] Trial 398 finished with value: 0.23912682921722722 and parameters: {'x': 2.8954902466598713, 'y': -4.522292410910175}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,333] Trial 399 finished with value: 2.1115746296687563 and parameters: {'x': 1.6217022649911619, 'y': -5.4602933666024995}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,340] Trial 400 finished with value: 1.9695373461339245 and parameters: {'x': 2.051371285861147, 'y': -6.03423445545253}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,343] Trial 401 finished with value: 3.493887940354605 and parameters: {'x': 3.3543820588075524, 'y': -6.835293245437885}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,343] Trial 402 finished with value: 0.0837143602091913 and parameters: {'x': 2.715084829485521, 'y': -4.9496243529084065}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,365] Trial 403 finished with value: 4.06778168512384 and parameters: {'x': 4.2745644588757035, 'y': -3.4369046333333575}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,376] Trial 404 finished with value: 31.120046602640254 and parameters: {'x': -2.4976753720980387, 'y': -4.053632150975665}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,385] Trial 405 finished with value: 35.91327131499644 and parameters: {'x': 3.6675115948126353, 'y': -10.95547643650675}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,393] Trial 406 finished with value: 0.5406055455715462 and parameters: {'x': 2.3434830581873713, 'y': -5.331045390671037}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,393] Trial 407 finished with value: 0.2402406430121301 and parameters: {'x': 3.023503792344169, 'y': -4.510420369339601}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,417] Trial 408 finished with value: 0.7916126964638823 and parameters: {'x': 3.1691825286592383, 'y': -5.873492969897496}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,426] Trial 409 finished with value: 0.14462433913469033 and parameters: {'x': 2.6251702744454795, 'y': -4.9357581446764405}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,431] Trial 410 finished with value: 1.282762634635099 and parameters: {'x': 3.7101498209060955, 'y': -4.11770194010066}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,448] Trial 411 finished with value: 3.2299753037749777 and parameters: {'x': 2.9640450973906103, 'y': -3.2031464865623223}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,462] Trial 412 finished with value: 0.752279738608707 and parameters: {'x': 2.300005252377797, 'y': -5.512139719129492}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,476] Trial 413 finished with value: 2.765246019078255 and parameters: {'x': 3.4173384443019152, 'y': -6.609681534337122}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,491] Trial 414 finished with value: 1.390163405315539 and parameters: {'x': 1.8224769707147632, 'y': -4.939975664781205}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,502] Trial 415 finished with value: 190.1107088998592 and parameters: {'x': 2.7464019620249887, 'y': 8.785731643079174}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,516] Trial 416 finished with value: 1.2772583212055084 and parameters: {'x': 3.9657500289228644, 'y': -4.412986198764463}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,530] Trial 417 finished with value: 9.18786936786568 and parameters: {'x': 1.3526154580538807, 'y': -7.544404358356323}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,540] Trial 418 finished with value: 26.428173244339046 and parameters: {'x': 3.1750749704321932, 'y': -10.137851885668486}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,555] Trial 419 finished with value: 1.785779423740365 and parameters: {'x': 2.191912273582441, 'y': -6.064318396981686}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,568] Trial 420 finished with value: 0.4003077365091259 and parameters: {'x': 3.5709879490097536, 'y': -5.2725444892027005}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,578] Trial 421 finished with value: 1.708858536937476 and parameters: {'x': 2.6038266140713855, 'y': -3.754245134378624}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,588] Trial 422 finished with value: 0.028782742642193868 and parameters: {'x': 2.950246467086118, 'y': -4.837804659115062}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,597] Trial 423 finished with value: 0.36021933091796177 and parameters: {'x': 3.205382707222124, 'y': -4.436052064023572}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,597] Trial 424 finished with value: 1.632625303145267 and parameters: {'x': 4.097775659912738, 'y': -5.653845473830338}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,614] Trial 425 finished with value: 0.0005693282836857415 and parameters: {'x': 2.9884835612449487, 'y': -5.020897366391172}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,629] Trial 426 finished with value: 4.08122900412297 and parameters: {'x': 4.506764602210172, 'y': -6.3456929210073865}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,634] Trial 427 finished with value: 1.4964034924098346 and parameters: {'x': 3.5404889784653077, 'y': -3.902605286796331}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,648] Trial 428 finished with value: 8.108048185266718 and parameters: {'x': 3.0965630978107557, 'y': -2.1541743283525063}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,648] Trial 429 finished with value: 0.5454210189315409 and parameters: {'x': 3.4639215123709297, 'y': -5.574628444554401}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,666] Trial 430 finished with value: 3.8040857892818765 and parameters: {'x': 2.9508529338164387, 'y': -3.0502127410490587}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,679] Trial 431 finished with value: 0.5616218671578281 and parameters: {'x': 2.3061722730712777, 'y': -4.7167599030808836}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,683] Trial 432 finished with value: 0.6580456766461675 and parameters: {'x': 3.795460123730554, 'y': -5.159024740844748}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,697] Trial 433 finished with value: 1.0777465275948948 and parameters: {'x': 3.2256529184682776, 'y': -3.9866751320619613}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,697] Trial 434 finished with value: 1.1487010283447296 and parameters: {'x': 2.572267963517948, 'y': -5.982723935452702}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,715] Trial 435 finished with value: 1.177797205235365 and parameters: {'x': 3.8421847407159158, 'y': -4.315513281545485}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,715] Trial 436 finished with value: 8.83474940301126 and parameters: {'x': 5.4161768198025335, 'y': -6.731138058752154}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,731] Trial 437 finished with value: 0.03445042229263061 and parameters: {'x': 2.983928370942838, 'y': -4.8150888726115175}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,743] Trial 438 finished with value: 2.74181766329035 and parameters: {'x': 3.3613155858444244, 'y': -3.38405794945603}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,751] Trial 439 finished with value: 1.0500883587078311 and parameters: {'x': 2.0362810381243146, 'y': -4.651669522968371}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,760] Trial 440 finished with value: 0.016416572735026537 and parameters: {'x': 2.9020140498399574, 'y': -5.082554989590334}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,768] Trial 441 finished with value: 0.6098339993442694 and parameters: {'x': 2.558396333175594, 'y': -4.355934630032395}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,777] Trial 442 finished with value: 0.3749312919954564 and parameters: {'x': 2.9432471205319857, 'y': -5.609680574290788}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,777] Trial 443 finished with value: 1.2424898058575806 and parameters: {'x': 1.8874797097669682, 'y': -4.93080166420071}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,795] Trial 444 finished with value: 2.1552005387945283 and parameters: {'x': 2.373288330662362, 'y': -3.6724334207616707}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,811] Trial 445 finished with value: 0.966406623441419 and parameters: {'x': 2.8539619259718414, 'y': -5.972151996539412}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,826] Trial 446 finished with value: 138.53677900484104 and parameters: {'x': -8.756613627964576, 'y': -4.435362941706203}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,836] Trial 447 finished with value: 5.248923183218377 and parameters: {'x': 3.633554025063945, 'y': -2.7982887381530586}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,845] Trial 448 finished with value: 1.4524302012046402 and parameters: {'x': 4.204077731590624, 'y': -5.051254438756233}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,859] Trial 449 finished with value: 0.2502238202167286 and parameters: {'x': 3.0307866926317004, 'y': -5.499275474836818}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,872] Trial 450 finished with value: 1.2254816850737023 and parameters: {'x': 2.38770733337223, 'y': -4.077731397331799}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,883] Trial 451 finished with value: 0.23731234371308002 and parameters: {'x': 3.417411890192266, 'y': -4.748843360352151}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,891] Trial 452 finished with value: 1.8210543949068492 and parameters: {'x': 2.803060474442768, 'y': -6.335016561013436}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,905] Trial 453 finished with value: 0.26895508681432484 and parameters: {'x': 3.239704237111067, 'y': -5.459887992369149}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,917] Trial 454 finished with value: 4.966199142934723 and parameters: {'x': 2.0968610811065043, 'y': -7.037287224746332}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,926] Trial 455 finished with value: 1.960006768756412 and parameters: {'x': 2.555049007191125, 'y': -3.6725869584960344}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,934] Trial 456 finished with value: 0.5384536297131914 and parameters: {'x': 3.6611141756506402, 'y': -4.6815951060882295}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,942] Trial 457 finished with value: 2.605962060958759 and parameters: {'x': 1.6341168394665333, 'y': -5.860421555244792}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,950] Trial 458 finished with value: 0.8074724454365602 and parameters: {'x': 2.875608969442941, 'y': -4.1100565653068095}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,959] Trial 459 finished with value: 0.9546817339322323 and parameters: {'x': 3.97275678469168, 'y': -5.091793092161321}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,959] Trial 460 finished with value: 2.7766117755674915 and parameters: {'x': 3.1015647111382068, 'y': -3.336781317739936}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,976] Trial 461 finished with value: 0.40033424171413895 and parameters: {'x': 2.460158268628545, 'y': -5.330007798065453}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,981] Trial 462 finished with value: 0.5838819733254169 and parameters: {'x': 3.377488044498033, 'y': -4.335632067611276}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,991] Trial 463 finished with value: 1.1032275877307953 and parameters: {'x': 2.8698600700973853, 'y': -6.042252937811037}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:55,997] Trial 464 finished with value: 0.9341507505130634 and parameters: {'x': 2.050067390701024, 'y': -4.821733939563634}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:56,012] Trial 465 finished with value: 0.4185306837569891 and parameters: {'x': 3.4162999258017144, 'y': -5.495202035066978}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:56,014] Trial 466 finished with value: 1.3222270635430882 and parameters: {'x': 2.655964593837271, 'y': -3.9027914041306757}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:56,029] Trial 467 finished with value: 2.3939407454090356 and parameters: {'x': 4.494749042914522, 'y': -4.600417662908938}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:56,030] Trial 468 finished with value: 2.9649187783205297 and parameters: {'x': 3.800069043587726, 'y': -6.524732207245965}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:56,046] Trial 469 finished with value: 3.4954735509639145 and parameters: {'x': 1.1326808586240766, 'y': -5.092697223340287}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:56,052] Trial 470 finished with value: 0.5629885547434222 and parameters: {'x': 3.1413050837137164, 'y': -5.736899876550459}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:56,065] Trial 471 finished with value: 1.0813972399763272 and parameters: {'x': 2.275379162805811, 'y': -4.254130117057727}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:56,073] Trial 472 finished with value: 3.3186946696907262 and parameters: {'x': 2.7512813882421114, 'y': -3.195330024116333}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:56,085] Trial 473 finished with value: 0.3105020454360556 and parameters: {'x': 3.5571738740083307, 'y': -5.00770191915073}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:56,094] Trial 474 finished with value: 1.6757360296768282 and parameters: {'x': 3.0897921684388843, 'y': -6.2913842945319844}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:56,097] Trial 475 finished with value: 74.44263422888034 and parameters: {'x': 4.101522310552621, 'y': -13.557410988624722}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:56,114] Trial 476 finished with value: 1.5739709591108637 and parameters: {'x': 2.4998860673222443, 'y': -3.8494101454243337}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:56,115] Trial 477 finished with value: 1.8548656226559976 and parameters: {'x': 1.6969669915288519, 'y': -4.603804844185815}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:56,135] Trial 478 finished with value: 6.792940401074967 and parameters: {'x': 3.0472726723129657, 'y': -2.394101748815323}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:56,151] Trial 479 finished with value: 0.44082111718135736 and parameters: {'x': 3.494458426050573, 'y': -5.443093649343959}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:56,166] Trial 480 finished with value: 1.3984634384404702 and parameters: {'x': 2.21822338872409, 'y': -5.887292944017039}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:56,177] Trial 481 finished with value: 0.04717443526928811 and parameters: {'x': 2.7857182867712837, 'y': -5.035465231495851}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:56,195] Trial 482 finished with value: 1.1266497374865585 and parameters: {'x': 3.8384379796782895, 'y': -4.349099476325647}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:56,204] Trial 483 finished with value: 25.474155762175183 and parameters: {'x': 2.6805719869029723, 'y': 0.03707469734409141}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:56,213] Trial 484 finished with value: 0.1816093417370605 and parameters: {'x': 3.2786146112786207, 'y': -5.3224643237927625}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:56,222] Trial 485 finished with value: 4.862433479448509 and parameters: {'x': 2.9724032998375356, 'y': -7.204919930879272}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:56,232] Trial 486 finished with value: 2.5894880871023234 and parameters: {'x': 2.354569296754705, 'y': -3.525921544011104}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:56,241] Trial 487 finished with value: 0.19444600065453532 and parameters: {'x': 3.4163779305147566, 'y': -4.854826243298646}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:56,252] Trial 488 finished with value: 0.8579625582478059 and parameters: {'x': 2.749433379705125, 'y': -5.891728056664031}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:56,268] Trial 489 finished with value: 1.5321359366516158 and parameters: {'x': 1.992056240660375, 'y': -4.281539622066798}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:56,278] Trial 490 finished with value: 4.32883134328129 and parameters: {'x': 4.327253109643476, 'y': -6.602257946219338}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:56,286] Trial 491 finished with value: 9.441240523657019 and parameters: {'x': 3.787475467746401, 'y': -7.970037526926992}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:56,294] Trial 492 finished with value: 0.046959625706392984 and parameters: {'x': 3.0465012314237057, 'y': -5.211653634938009}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:56,301] Trial 493 finished with value: 0.47613860513754913 and parameters: {'x': 2.5240936520457318, 'y': -5.499651631753945}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:56,311] Trial 494 finished with value: 23.364234451501595 and parameters: {'x': 7.831062301104426, 'y': -5.15833980658445}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:56,318] Trial 495 finished with value: 1.368628297970342 and parameters: {'x': 3.081401406579649, 'y': -6.1670484604236435}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:56,327] Trial 496 finished with value: 18.440566552816623 and parameters: {'x': 3.439201824692444, 'y': -9.271728960269302}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:56,338] Trial 497 finished with value: 0.4642668062951109 and parameters: {'x': 2.808865224661939, 'y': -5.6540139936970615}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:56,347] Trial 498 finished with value: 1.63000930459099 and parameters: {'x': 2.1360212557810225, 'y': -4.060026577966808}. Best is trial 260 with value: 0.00016793996632639578.\n",
      "[I 2025-02-11 16:15:56,355] Trial 499 finished with value: 0.060372559629127416 and parameters: {'x': 3.1537481095436526, 'y': -4.808338636024679}. Best is trial 260 with value: 0.00016793996632639578.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00016793996632639578\n",
      "{'x': 3.0127152843336997, 'y': -5.00250230106893}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    x = trial.suggest_uniform('x',-10,10)\n",
    "    y = trial.suggest_uniform('y',-15,15)\n",
    "\n",
    "    return (x-3) ** 2 + (y+5) ** 2\n",
    "\n",
    "# 스터디 생성\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "# 최적화 실행\n",
    "study.optimize(objective, n_trials=500)\n",
    "\n",
    "# 결과 확인\n",
    "print(study.best_value)\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "cliponaxis": false,
         "hovertemplate": [
          "x (FloatDistribution): 0.08321753497766751<extra></extra>",
          "y (FloatDistribution): 0.9167824650223325<extra></extra>"
         ],
         "name": "Objective Value",
         "orientation": "h",
         "text": [
          "0.08",
          "0.92"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          0.08321753497766751,
          0.9167824650223325
         ],
         "y": [
          "x",
          "y"
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Hyperparameter Importances"
        },
        "xaxis": {
         "title": {
          "text": "Hyperparameter Importance"
         }
        },
        "yaxis": {
         "title": {
          "text": "Hyperparameter"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import optuna.visualization as vis\n",
    "\n",
    "vis.plot_param_importances(study).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers",
         "name": "Objective Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499
         ],
         "y": [
          77.26626068286728,
          394.97872770692067,
          141.38086734431718,
          1.4672361753557046,
          41.83665935722324,
          129.7604177008255,
          98.90155372609271,
          55.68398333502307,
          163.60836995984366,
          373.78971420199844,
          100.18486720957561,
          38.19597440367841,
          64.70727423098259,
          37.3480370818867,
          35.297403254453364,
          53.41532584630738,
          13.211184030473472,
          161.13916030565625,
          15.326933930638845,
          18.261465834671082,
          195.433274177327,
          19.72840940201893,
          2.1853720061063684,
          0.4419320442242601,
          4.695652759511313,
          14.54723006807254,
          42.36260110429447,
          53.642013945548946,
          4.763840611756697,
          5.339110182469392,
          30.49441373607698,
          3.6534237788547026,
          7.835797094359462,
          7.6370713883099075,
          46.8771484990549,
          0.0034147471052381672,
          3.8576717412713077,
          35.80314035064406,
          38.93279194189032,
          69.17156822353562,
          100.59346842153678,
          1.3609143376982304,
          2.8734377744456676,
          13.056622426982745,
          2.730993998286875,
          61.86078430036696,
          32.37140854218186,
          27.29326051543849,
          14.094815100915891,
          1.8115518683357348,
          395.19260501288716,
          171.9696010834352,
          1.6727581852627929,
          3.520233855085437,
          18.955542669435857,
          16.68393658688008,
          3.2879782154890593,
          0.6538457188436771,
          9.13540445722889,
          7.995893315838365,
          3.293678050058414,
          8.934593641342607,
          3.0539292004802157,
          5.611499672991604,
          21.702272114757704,
          55.8801408675565,
          7.606057508588901,
          87.46276204912857,
          16.84888074441063,
          0.10383654629046235,
          2.556830295301065,
          1.7853089767181287,
          2.4896095219321497,
          6.255463109585774,
          3.8933782395063643,
          0.6561681153525516,
          0.9388516158961486,
          55.908702284305626,
          32.703927478795485,
          1.2420199938571286,
          18.912282601246506,
          8.421329231959401,
          13.481113057958286,
          2.3491914595573955,
          0.2359997492680227,
          13.225451830181314,
          1.0924134878631464,
          5.708243212649579,
          0.17557234423509868,
          137.88414133644267,
          20.919038266648798,
          0.9549560312124076,
          3.1554218598456116,
          4.067363565480362,
          4.100891057919457,
          12.074859452734563,
          8.68697628063924,
          0.6564234208315368,
          5.195071445248129,
          1.7330849403633415,
          28.008104144176638,
          0.531355329818981,
          2.3899846438980688,
          3.4575893232474906,
          9.608893198571401,
          1.066077302007435,
          0.7015617507876419,
          5.529498954758632,
          0.953768836332742,
          3.972017959444164,
          0.6872160997083968,
          2.2600286407077896,
          2.8486930510547217,
          0.9781205530152279,
          15.432807086033673,
          30.853653469863254,
          1.4879061998849412,
          13.295526717458575,
          9.330890711128994,
          0.24825806573799342,
          3.2905468957459485,
          0.2689256283049509,
          0.10298205575060182,
          1.787553377215131,
          2.324404918547088,
          2.1697356414014144,
          2.4045897232696136,
          0.01900332987799084,
          12.91342577260379,
          1.037276031561213,
          1.5365397735389323,
          0.28001245428953525,
          0.19073152707644855,
          2.996091336982016,
          0.038986615293083664,
          0.054147916246852015,
          4.731312932321391,
          1.3009374789447146,
          2.2738648782052526,
          2.807815765418329,
          6.492844774567884,
          1.362733957534469,
          4.241951325926502,
          0.9152274228424239,
          0.13176898433254164,
          0.1414126710156717,
          0.9880730762516261,
          2.8507797244965536,
          4.5845521279998716,
          1.4030673781271525,
          0.7580316025359402,
          0.3582050468160008,
          1.1349977121014678,
          0.13431204091057128,
          0.22142052246167968,
          285.1876880738851,
          1.3666155446933903,
          5.360321623148577,
          198.14642651841515,
          28.695529107277096,
          0.9985242229349535,
          0.27413390287673395,
          2.909759015313998,
          0.15946182449654708,
          0.5258062252553796,
          2.2947773319441502,
          2.5232818887964408,
          0.03725118494701189,
          2.488751581879513,
          1.163394722989691,
          9.192428758491547,
          0.18761052422455404,
          0.09498915846119736,
          0.35888712034280296,
          1.4582071455864916,
          1.7010537350687365,
          0.07914307207816854,
          7.519100927236021,
          1.7489146486359715,
          2.592002105927614,
          0.6367864033888716,
          0.036095278367581224,
          0.028578477308975767,
          0.027896065572671096,
          1.2957742813352833,
          0.99320969478322,
          47.23613345294734,
          0.7969394098663473,
          1.5703929992062995,
          4.734917489819903,
          0.6761595771709361,
          0.08085620730271126,
          0.024495862008745338,
          0.3424681384852067,
          0.4714060386260148,
          3.789118584684718,
          0.6235997121375366,
          0.5229339768403523,
          1.4821491820715902,
          4.217538637054062,
          0.14322897617853797,
          0.23330596191487274,
          0.25765632883744083,
          0.9553759381599647,
          0.053460737664183654,
          1.3063709197693192,
          0.1982166205228699,
          0.7810908847645477,
          2.0466103176619557,
          1.7817818590453602,
          1.517919432982076,
          0.18564071683109915,
          0.3278055698233962,
          0.03900491072253665,
          0.39168724190414256,
          1.0199139909493324,
          1.7375044600759826,
          0.6716872118045001,
          0.6566560200080841,
          2.6972851150035506,
          0.824616543883544,
          0.38788673485907155,
          0.5692011796146761,
          0.06243408999852723,
          1.6282082092587025,
          0.025788392083671223,
          0.700745298799365,
          0.03285777350005743,
          2.2900327809398777,
          0.05650900086114555,
          0.5253785568431015,
          0.1301310394360742,
          0.3887351133900825,
          44.72065553193265,
          1.5068869741412156,
          0.7378247843122274,
          0.025329943274452284,
          0.09631708046109655,
          0.24915149647328289,
          4.033764176171667,
          1.1904896406711885,
          30.76343032339084,
          79.30304800073966,
          0.21934359348189042,
          0.5571263949352124,
          0.0215744589986777,
          0.058705375295322826,
          2.5923090909162707,
          0.21793545772302014,
          0.9199778781878123,
          0.5450002706145965,
          0.17599832731841103,
          1.499551069763986,
          48.199817376935485,
          47.0546637274818,
          0.17622531179064793,
          3.1801937285587325,
          0.827543393474181,
          0.9653327800883094,
          19.400191704135537,
          0.00016793996632639578,
          3.648113335787717,
          1.7770085752600442,
          1.219332323587461,
          0.7374035157304658,
          132.94386812453524,
          0.848433127624037,
          4.870836178315173,
          0.5897183176607805,
          0.3228101362523653,
          2.167240710659826,
          2.302535441222657,
          1.2214363758215554,
          0.8825747574207873,
          160.51479548164096,
          0.504797621949225,
          3.3042880269373587,
          0.0015686638291251464,
          0.06893664504361748,
          1.8930804017993481,
          2.79871850488605,
          0.019033601369570864,
          1.175843268033821,
          0.3726716886454584,
          1.3205909595474348,
          0.36350367067284345,
          1.5004130444312715,
          0.33598055183963016,
          5.496172348929121,
          0.9506017364881715,
          3.540379336479533,
          0.3859832022370451,
          4.229346380735306,
          0.28026913632981465,
          0.3140817921258818,
          0.7117690006944214,
          5.008237658239695,
          0.22635788462060785,
          1.161989155837424,
          3.372644996540574,
          0.44769697800408553,
          1.1528445235217957,
          30.478181309291436,
          0.07053220652405773,
          373.7459013621844,
          0.20385214636063448,
          2.5295652173465832,
          0.7736749887579296,
          0.17452712768646705,
          2.57270165841669,
          0.33329131663005107,
          3.8458239784699844,
          1.3098738025697674,
          32.33664881876287,
          0.624472850629346,
          0.36494225975784905,
          231.8211292494077,
          53.6971402737344,
          3.698987358299439,
          1.5746357319576472,
          1.2758139132615698,
          3.4622137455491924,
          1.3662585573683232,
          1.901667932005254,
          0.5813894717351972,
          0.30528574173336537,
          0.7096690196311458,
          2.2390799796872747,
          1.8629441612929467,
          1.4968969226949451,
          0.14283785684667413,
          26.26366833831741,
          4.567889932236663,
          1.0230088127080526,
          0.7286895214278738,
          0.04143164684743235,
          4.160469223599238,
          0.09367365959526269,
          2.142958123829176,
          2.0522366852985017,
          0.6503616335045006,
          0.3568046935066491,
          2.8228963586322244,
          14.377775595891393,
          85.73694204031382,
          3.7482994081656686,
          0.6608139902017569,
          0.22670128859733377,
          1.5353681279525997,
          2.118926325393513,
          0.32074319545424496,
          0.6807906789038374,
          0.7654097564840029,
          6.954840622818517,
          5.7850170556909895,
          0.13849662911688124,
          0.8278669004876877,
          0.1146513827623122,
          3.0338324493548123,
          0.09756013074675057,
          0.9744677730202465,
          1.231029680136078,
          5.677847537453246,
          0.18224774547478584,
          12.28925775209548,
          0.3102125272941885,
          5.756504053240873,
          1.8184947444188488,
          1.0914330229842166,
          10.175237649453814,
          1.7530733983971987,
          0.9032943604854542,
          11.36398237298839,
          2.28682660781605,
          63.78649247948275,
          0.6831713326144916,
          1.6438847638569523,
          0.21834908248466767,
          0.3842487078091781,
          2.5396323905044436,
          3.761953675903776,
          1.5060867816063082,
          0.7974725467990006,
          1.1479441353465947,
          1.0179687558030932,
          2.6237962373228005,
          5.948628069612248,
          0.6102772011014415,
          37.12702857949618,
          110.26079378568332,
          0.6525725736943367,
          5.102089015404284,
          1.7613483228398692,
          15.775965743541907,
          86.75286551454076,
          2.4092222692471754,
          0.3304258565318326,
          4.967672156629627,
          0.23912682921722722,
          2.1115746296687563,
          1.9695373461339245,
          3.493887940354605,
          0.0837143602091913,
          4.06778168512384,
          31.120046602640254,
          35.91327131499644,
          0.5406055455715462,
          0.2402406430121301,
          0.7916126964638823,
          0.14462433913469033,
          1.282762634635099,
          3.2299753037749777,
          0.752279738608707,
          2.765246019078255,
          1.390163405315539,
          190.1107088998592,
          1.2772583212055084,
          9.18786936786568,
          26.428173244339046,
          1.785779423740365,
          0.4003077365091259,
          1.708858536937476,
          0.028782742642193868,
          0.36021933091796177,
          1.632625303145267,
          0.0005693282836857415,
          4.08122900412297,
          1.4964034924098346,
          8.108048185266718,
          0.5454210189315409,
          3.8040857892818765,
          0.5616218671578281,
          0.6580456766461675,
          1.0777465275948948,
          1.1487010283447296,
          1.177797205235365,
          8.83474940301126,
          0.03445042229263061,
          2.74181766329035,
          1.0500883587078311,
          0.016416572735026537,
          0.6098339993442694,
          0.3749312919954564,
          1.2424898058575806,
          2.1552005387945283,
          0.966406623441419,
          138.53677900484104,
          5.248923183218377,
          1.4524302012046402,
          0.2502238202167286,
          1.2254816850737023,
          0.23731234371308002,
          1.8210543949068492,
          0.26895508681432484,
          4.966199142934723,
          1.960006768756412,
          0.5384536297131914,
          2.605962060958759,
          0.8074724454365602,
          0.9546817339322323,
          2.7766117755674915,
          0.40033424171413895,
          0.5838819733254169,
          1.1032275877307953,
          0.9341507505130634,
          0.4185306837569891,
          1.3222270635430882,
          2.3939407454090356,
          2.9649187783205297,
          3.4954735509639145,
          0.5629885547434222,
          1.0813972399763272,
          3.3186946696907262,
          0.3105020454360556,
          1.6757360296768282,
          74.44263422888034,
          1.5739709591108637,
          1.8548656226559976,
          6.792940401074967,
          0.44082111718135736,
          1.3984634384404702,
          0.04717443526928811,
          1.1266497374865585,
          25.474155762175183,
          0.1816093417370605,
          4.862433479448509,
          2.5894880871023234,
          0.19444600065453532,
          0.8579625582478059,
          1.5321359366516158,
          4.32883134328129,
          9.441240523657019,
          0.046959625706392984,
          0.47613860513754913,
          23.364234451501595,
          1.368628297970342,
          18.440566552816623,
          0.4642668062951109,
          1.63000930459099,
          0.060372559629127416
         ]
        },
        {
         "mode": "lines",
         "name": "Best Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499
         ],
         "y": [
          77.26626068286728,
          77.26626068286728,
          77.26626068286728,
          1.4672361753557046,
          1.4672361753557046,
          1.4672361753557046,
          1.4672361753557046,
          1.4672361753557046,
          1.4672361753557046,
          1.4672361753557046,
          1.4672361753557046,
          1.4672361753557046,
          1.4672361753557046,
          1.4672361753557046,
          1.4672361753557046,
          1.4672361753557046,
          1.4672361753557046,
          1.4672361753557046,
          1.4672361753557046,
          1.4672361753557046,
          1.4672361753557046,
          1.4672361753557046,
          1.4672361753557046,
          0.4419320442242601,
          0.4419320442242601,
          0.4419320442242601,
          0.4419320442242601,
          0.4419320442242601,
          0.4419320442242601,
          0.4419320442242601,
          0.4419320442242601,
          0.4419320442242601,
          0.4419320442242601,
          0.4419320442242601,
          0.4419320442242601,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.0034147471052381672,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578,
          0.00016793996632639578
         ]
        },
        {
         "marker": {
          "color": "#cccccc"
         },
         "mode": "markers",
         "name": "Infeasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [],
         "y": []
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Optimization History Plot"
        },
        "xaxis": {
         "title": {
          "text": "Trial"
         }
        },
        "yaxis": {
         "title": {
          "text": "Objective Value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vis.plot_optimization_history(study).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- optuna를 활용한 XGBoost 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-11 17:12:49,056] A new study created in memory with name: no-name-c73b438b-7bd7-4ed7-8344-cc091f4c9113\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\832836957.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2025-02-11 17:12:49,234] Trial 0 finished with value: 0.960093896713615 and parameters: {'n_estimators': 100, 'max_depth': 4, 'learning_rate': 0.19539679759906894, 'colsample_bytree': 0.5687220664212533}. Best is trial 0 with value: 0.960093896713615.\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\832836957.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2025-02-11 17:12:49,806] Trial 1 finished with value: 0.960093896713615 and parameters: {'n_estimators': 500, 'max_depth': 5, 'learning_rate': 0.042980553036524684, 'colsample_bytree': 0.6481847097751632}. Best is trial 0 with value: 0.960093896713615.\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\832836957.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2025-02-11 17:12:50,072] Trial 2 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 200, 'max_depth': 10, 'learning_rate': 0.13174297167862123, 'colsample_bytree': 0.7100985851233451}. Best is trial 2 with value: 0.9624413145539906.\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\832836957.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2025-02-11 17:12:50,256] Trial 3 finished with value: 0.960093896713615 and parameters: {'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.12657111480306255, 'colsample_bytree': 0.8145817338416919}. Best is trial 2 with value: 0.9624413145539906.\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\832836957.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2025-02-11 17:12:50,666] Trial 4 finished with value: 0.960093896713615 and parameters: {'n_estimators': 400, 'max_depth': 7, 'learning_rate': 0.1336892266611005, 'colsample_bytree': 0.7576662946879051}. Best is trial 2 with value: 0.9624413145539906.\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\832836957.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2025-02-11 17:12:50,928] Trial 5 finished with value: 0.9460093896713615 and parameters: {'n_estimators': 100, 'max_depth': 7, 'learning_rate': 0.01494363584982539, 'colsample_bytree': 0.7937567478171828}. Best is trial 2 with value: 0.9624413145539906.\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\832836957.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2025-02-11 17:12:51,385] Trial 6 finished with value: 0.960093896713615 and parameters: {'n_estimators': 500, 'max_depth': 7, 'learning_rate': 0.16705690325303668, 'colsample_bytree': 0.6569384692274398}. Best is trial 2 with value: 0.9624413145539906.\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\832836957.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2025-02-11 17:12:51,867] Trial 7 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 400, 'max_depth': 9, 'learning_rate': 0.0954018151031387, 'colsample_bytree': 0.619817184028231}. Best is trial 2 with value: 0.9624413145539906.\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\832836957.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2025-02-11 17:12:52,184] Trial 8 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.06481651735299275, 'colsample_bytree': 0.7552061699438449}. Best is trial 2 with value: 0.9624413145539906.\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\832836957.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2025-02-11 17:12:52,351] Trial 9 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.17817185152153572, 'colsample_bytree': 0.8825801321831284}. Best is trial 2 with value: 0.9624413145539906.\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\832836957.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2025-02-11 17:12:52,737] Trial 10 finished with value: 0.960093896713615 and parameters: {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.09303230040223705, 'colsample_bytree': 0.9675367480361123}. Best is trial 2 with value: 0.9624413145539906.\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\832836957.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2025-02-11 17:12:53,106] Trial 11 finished with value: 0.9694835680751174 and parameters: {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.09876109852081108, 'colsample_bytree': 0.5006904883553441}. Best is trial 11 with value: 0.9694835680751174.\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\832836957.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2025-02-11 17:12:53,444] Trial 12 finished with value: 0.960093896713615 and parameters: {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.14085725076413497, 'colsample_bytree': 0.5389843069826757}. Best is trial 11 with value: 0.9694835680751174.\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\832836957.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2025-02-11 17:12:53,797] Trial 13 finished with value: 0.9647887323943661 and parameters: {'n_estimators': 200, 'max_depth': 8, 'learning_rate': 0.07917579449155418, 'colsample_bytree': 0.5007403064888768}. Best is trial 11 with value: 0.9694835680751174.\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\832836957.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2025-02-11 17:12:54,119] Trial 14 finished with value: 0.9694835680751174 and parameters: {'n_estimators': 200, 'max_depth': 8, 'learning_rate': 0.06762111242960267, 'colsample_bytree': 0.5019971453518353}. Best is trial 11 with value: 0.9694835680751174.\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\832836957.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2025-02-11 17:12:54,553] Trial 15 finished with value: 0.9647887323943664 and parameters: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.05871636167746565, 'colsample_bytree': 0.5900832346214036}. Best is trial 11 with value: 0.9694835680751174.\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\832836957.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2025-02-11 17:12:55,124] Trial 16 finished with value: 0.9671361502347419 and parameters: {'n_estimators': 400, 'max_depth': 8, 'learning_rate': 0.03328642540676424, 'colsample_bytree': 0.5201538890765921}. Best is trial 11 with value: 0.9694835680751174.\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\832836957.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2025-02-11 17:12:55,417] Trial 17 finished with value: 0.9671361502347419 and parameters: {'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.10878785901371674, 'colsample_bytree': 0.6879449371470563}. Best is trial 11 with value: 0.9694835680751174.\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\832836957.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2025-02-11 17:12:55,860] Trial 18 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 300, 'max_depth': 3, 'learning_rate': 0.06612980650979755, 'colsample_bytree': 0.5666760389182006}. Best is trial 11 with value: 0.9694835680751174.\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\832836957.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2025-02-11 17:12:56,152] Trial 19 finished with value: 0.9671361502347419 and parameters: {'n_estimators': 200, 'max_depth': 9, 'learning_rate': 0.10887387691276547, 'colsample_bytree': 0.5016202117494318}. Best is trial 11 with value: 0.9694835680751174.\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\832836957.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2025-02-11 17:12:56,756] Trial 20 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 400, 'max_depth': 6, 'learning_rate': 0.039238537485286336, 'colsample_bytree': 0.9807875164508462}. Best is trial 11 with value: 0.9694835680751174.\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\832836957.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2025-02-11 17:12:57,537] Trial 21 finished with value: 0.9671361502347419 and parameters: {'n_estimators': 400, 'max_depth': 8, 'learning_rate': 0.015506973717589433, 'colsample_bytree': 0.5399522001930781}. Best is trial 11 with value: 0.9694835680751174.\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\832836957.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2025-02-11 17:12:58,149] Trial 22 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 400, 'max_depth': 8, 'learning_rate': 0.03749572637080917, 'colsample_bytree': 0.6080041449328262}. Best is trial 11 with value: 0.9694835680751174.\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\832836957.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2025-02-11 17:12:58,729] Trial 23 finished with value: 0.9647887323943664 and parameters: {'n_estimators': 300, 'max_depth': 9, 'learning_rate': 0.02870774839917886, 'colsample_bytree': 0.5025057071917254}. Best is trial 11 with value: 0.9694835680751174.\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\832836957.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2025-02-11 17:12:59,262] Trial 24 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.08065293649967936, 'colsample_bytree': 0.5377928271847101}. Best is trial 11 with value: 0.9694835680751174.\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\832836957.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2025-02-11 17:12:59,782] Trial 25 finished with value: 0.9671361502347419 and parameters: {'n_estimators': 400, 'max_depth': 8, 'learning_rate': 0.05050698295471122, 'colsample_bytree': 0.5622242008284309}. Best is trial 11 with value: 0.9694835680751174.\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\832836957.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2025-02-11 17:13:00,103] Trial 26 finished with value: 0.9647887323943661 and parameters: {'n_estimators': 200, 'max_depth': 7, 'learning_rate': 0.08059504932557628, 'colsample_bytree': 0.6229342019295631}. Best is trial 11 with value: 0.9694835680751174.\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\832836957.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2025-02-11 17:13:00,479] Trial 27 finished with value: 0.9694835680751174 and parameters: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.11832598163890899, 'colsample_bytree': 0.5353906877422494}. Best is trial 11 with value: 0.9694835680751174.\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\832836957.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2025-02-11 17:13:00,896] Trial 28 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.11809539246349653, 'colsample_bytree': 0.5854069969854523}. Best is trial 11 with value: 0.9694835680751174.\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\832836957.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2025-02-11 17:13:01,182] Trial 29 finished with value: 0.9647887323943661 and parameters: {'n_estimators': 200, 'max_depth': 4, 'learning_rate': 0.14445839395831506, 'colsample_bytree': 0.5663249832847655}. Best is trial 11 with value: 0.9694835680751174.\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\832836957.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2025-02-11 17:13:01,500] Trial 30 finished with value: 0.960093896713615 and parameters: {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.15710274426328985, 'colsample_bytree': 0.680766744549666}. Best is trial 11 with value: 0.9694835680751174.\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\832836957.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2025-02-11 17:13:01,977] Trial 31 finished with value: 0.9671361502347419 and parameters: {'n_estimators': 400, 'max_depth': 6, 'learning_rate': 0.09220119739390516, 'colsample_bytree': 0.5298754918212201}. Best is trial 11 with value: 0.9694835680751174.\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\832836957.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2025-02-11 17:13:02,561] Trial 32 finished with value: 0.9647887323943664 and parameters: {'n_estimators': 300, 'max_depth': 7, 'learning_rate': 0.02606448763350607, 'colsample_bytree': 0.5273132033749662}. Best is trial 11 with value: 0.9694835680751174.\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\832836957.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2025-02-11 17:13:03,199] Trial 33 finished with value: 0.9647887323943664 and parameters: {'n_estimators': 500, 'max_depth': 4, 'learning_rate': 0.05281923072344501, 'colsample_bytree': 0.6406609527898576}. Best is trial 11 with value: 0.9694835680751174.\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\832836957.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2025-02-11 17:13:03,391] Trial 34 finished with value: 0.9671361502347419 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.11891866749332966, 'colsample_bytree': 0.5932471034242033}. Best is trial 11 with value: 0.9694835680751174.\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\832836957.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2025-02-11 17:13:03,787] Trial 35 finished with value: 0.9647887323943661 and parameters: {'n_estimators': 300, 'max_depth': 9, 'learning_rate': 0.06788514816328857, 'colsample_bytree': 0.5536401544881058}. Best is trial 11 with value: 0.9694835680751174.\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\832836957.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2025-02-11 17:13:04,098] Trial 36 finished with value: 0.9647887323943661 and parameters: {'n_estimators': 200, 'max_depth': 10, 'learning_rate': 0.10106253248148109, 'colsample_bytree': 0.5078587898742468}. Best is trial 11 with value: 0.9694835680751174.\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\832836957.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2025-02-11 17:13:04,606] Trial 37 finished with value: 0.9671361502347416 and parameters: {'n_estimators': 400, 'max_depth': 7, 'learning_rate': 0.0779500396168364, 'colsample_bytree': 0.7156003387007263}. Best is trial 11 with value: 0.9694835680751174.\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\832836957.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2025-02-11 17:13:05,057] Trial 38 finished with value: 0.9577464788732395 and parameters: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.1201621257894897, 'colsample_bytree': 0.8477211554488601}. Best is trial 11 with value: 0.9694835680751174.\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\832836957.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2025-02-11 17:13:05,653] Trial 39 finished with value: 0.9647887323943661 and parameters: {'n_estimators': 500, 'max_depth': 6, 'learning_rate': 0.0488054112735274, 'colsample_bytree': 0.523765783403779}. Best is trial 11 with value: 0.9694835680751174.\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\832836957.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2025-02-11 17:13:05,937] Trial 40 finished with value: 0.960093896713615 and parameters: {'n_estimators': 200, 'max_depth': 7, 'learning_rate': 0.19769392255194812, 'colsample_bytree': 0.6427395569994874}. Best is trial 11 with value: 0.9694835680751174.\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\832836957.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2025-02-11 17:13:06,248] Trial 41 finished with value: 0.9671361502347419 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.11142817295829376, 'colsample_bytree': 0.6667828023911392}. Best is trial 11 with value: 0.9694835680751174.\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\832836957.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2025-02-11 17:13:06,450] Trial 42 finished with value: 0.9624413145539906 and parameters: {'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.13625756971636252, 'colsample_bytree': 0.7010889806766362}. Best is trial 11 with value: 0.9694835680751174.\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\832836957.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2025-02-11 17:13:06,735] Trial 43 finished with value: 0.9624413145539905 and parameters: {'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.12636272749283717, 'colsample_bytree': 0.5543078919588309}. Best is trial 11 with value: 0.9694835680751174.\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\832836957.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2025-02-11 17:13:07,135] Trial 44 finished with value: 0.960093896713615 and parameters: {'n_estimators': 200, 'max_depth': 7, 'learning_rate': 0.10019832509823395, 'colsample_bytree': 0.8008763665111965}. Best is trial 11 with value: 0.9694835680751174.\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\832836957.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2025-02-11 17:13:07,357] Trial 45 finished with value: 0.960093896713615 and parameters: {'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.09237819415933873, 'colsample_bytree': 0.9254084893515148}. Best is trial 11 with value: 0.9694835680751174.\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\832836957.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2025-02-11 17:13:07,678] Trial 46 finished with value: 0.9577464788732394 and parameters: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.15004737115406602, 'colsample_bytree': 0.7258389856221581}. Best is trial 11 with value: 0.9694835680751174.\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\832836957.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2025-02-11 17:13:08,072] Trial 47 finished with value: 0.9671361502347416 and parameters: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.08700063766019892, 'colsample_bytree': 0.7765001659842788}. Best is trial 11 with value: 0.9694835680751174.\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\832836957.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2025-02-11 17:13:08,402] Trial 48 finished with value: 0.9647887323943664 and parameters: {'n_estimators': 200, 'max_depth': 10, 'learning_rate': 0.07027715075234665, 'colsample_bytree': 0.6068759752931392}. Best is trial 11 with value: 0.9694835680751174.\n",
      "C:\\Users\\ljh10\\AppData\\Local\\Temp\\ipykernel_59524\\832836957.py:4: FutureWarning:\n",
      "\n",
      "suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "\n",
      "[I 2025-02-11 17:13:08,840] Trial 49 finished with value: 0.9671361502347419 and parameters: {'n_estimators': 400, 'max_depth': 9, 'learning_rate': 0.13304506207741765, 'colsample_bytree': 0.5179145833077843}. Best is trial 11 with value: 0.9694835680751174.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.09876109852081108, 'colsample_bytree': 0.5006904883553441}\n",
      "0.9694835680751174\n"
     ]
    }
   ],
   "source": [
    "# 1. 목적 함수\n",
    "def xgb_optuna_objective(trial):\n",
    "    params={\n",
    "        'n_estimators' : trial.suggest_int('n_estimators', 100,500,100),\n",
    "        'max_depth' : trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate' : trial.suggest_float('learning_rate', 0.01, 0.2),\n",
    "        'colsample_bytree' : trial.suggest_float('colsample_bytree', 0.5,1.0),\n",
    "    }\n",
    "        \n",
    "    xgb_clf = XGBClassifier(**params)\n",
    "    return cross_val_score(xgb_clf,X_train,y_train,scoring='accuracy',cv=3).mean()\n",
    "\n",
    "# 2. study 객체 -> 최적화\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(xgb_optuna_objective, n_trials=50)\n",
    "\n",
    "\n",
    "# 3. 결과 출력\n",
    "print(study.best_params)\n",
    "print(study.best_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HyperOpt vs Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HyperOpt 최적 파라미터 적용 : 0.958041958041958\n",
      "Optuna 최적 파라미터 적용 : 0.965034965034965\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "xgb_hpopt = XGBClassifier(\n",
    "    n_estimators=400,\n",
    "    max_depth=10,\n",
    "    learning_rate=0.11,\n",
    "    colsample_bytree=0.6\n",
    ")\n",
    "\n",
    "xgb_optuna = XGBClassifier(\n",
    "    n_estimators = 500,\n",
    "    max_depth = 7,\n",
    "    learning_rate = 0.2,\n",
    "    colsmple_bytree=0.55\n",
    ")\n",
    "\n",
    "xgb_hpopt.fit(X_train,y_train)\n",
    "xgb_optuna.fit(X_train,y_train)\n",
    "\n",
    "hpopt_pre = xgb_hpopt.predict(X_test)\n",
    "optuna_pred = xgb_optuna.predict(X_test)\n",
    "\n",
    "print(f'HyperOpt 최적 파라미터 적용 : {accuracy_score(y_test, hpopt_pre)}')\n",
    "print(f'Optuna 최적 파라미터 적용 : {accuracy_score(y_test, optuna_pred)}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pystudy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
