{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Embedding Vector 시각화 wevi \n",
    "https://ronxin.github.io/wevi/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2vac\n",
    "- 2013년 구글에서 개발한 Word Embedding 방법\n",
    "- 최초의 neural embedding model\n",
    "- 매우 큰 corpus에서 자동 학습\n",
    "    - 비지도 지도 학습 (자기 지도학습)이라 할 수 있음\n",
    "    - 많은 데이터를 기반으로 label 값 유추하고 이를 지도학습에 사요\n",
    "- ex)\n",
    "    - **이사금**께 충성을 맹세하였다.\n",
    "    - **왕**께 충성을 맹세하였다.\n",
    "\n",
    "**WordVec 훈련방식에 따른 구분**\n",
    "1. CBOW : 주변 단어로 중심 단어를 예측  (LLM의 훈련방식)\n",
    "2. skip-gram : 중심 단어로 주변 단어를 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 영어 Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터 취득 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "\n",
    "# url = 'https://drive.google.com/uc?id=1DCgLPJsfyLGZ99lB-aF8EvpKIWSZYgp4'\n",
    "# output = './data/ted_en.xml'\n",
    "\n",
    "# gdown.download(url, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lxml : xml 파일을 다루기 위한 라이브러리, etree : xml 파일을 파싱하기 위한 라이브러리\n",
    "from lxml import etree\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24222849\n",
      "24062319\n"
     ]
    }
   ],
   "source": [
    "# xml 데이터 처리\n",
    "f = open('./data/ted_en.xml', 'r', encoding='UTF8')\n",
    "xml = etree.parse(f)\n",
    "\n",
    "# content 태그 하위 텍스트 추출\n",
    "contents = xml.xpath('//content/text()')\n",
    "# contents[:5]\n",
    "\n",
    "# corpus : \n",
    "corpus = '\\n'.join(contents)\n",
    "print(len(corpus))\n",
    "\n",
    "# 정규식을 이용해 () 안에 있는 내용 제거, ()도 포함\n",
    "corpus = re.sub(r'\\([^)]*\\)','',corpus) # 괄호로 묶인 내용 제거\n",
    "print(len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['two', 'reasons', 'companies', 'fail', 'new'],\n",
       " ['real',\n",
       "  'real',\n",
       "  'solution',\n",
       "  'quality',\n",
       "  'growth',\n",
       "  'figuring',\n",
       "  'balance',\n",
       "  'two',\n",
       "  'activities',\n",
       "  'exploration',\n",
       "  'exploitation'],\n",
       " ['necessary', 'much', 'good', 'thing'],\n",
       " ['consider', 'facit'],\n",
       " ['actually', 'old', 'enough', 'remember']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 전처리 (토큰화/대소문자 정규화/불용어 처리)\n",
    "\n",
    "sentences = sent_tokenize(corpus)\n",
    "\n",
    "preprocessed_sentences = []\n",
    "en_stopwords = stopwords.words('english')\n",
    "\n",
    "for sentence in sentences:\n",
    "    sentence = sentence.lower()\n",
    "    sentence = re.sub('[^a-z0-9]', ' ', sentence) # [^] : not 의미, a-z0-9를 제외한 문자는 공백으로 처리\n",
    "    tokens = word_tokenize(sentence)\n",
    "    tokens = [token for token in tokens if token not in en_stopwords]\n",
    "    preprocessed_sentences.append(tokens)\n",
    "\n",
    "preprocessed_sentences[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Embedding 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21462, 100)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec(\n",
    "    sentences=preprocessed_sentences, # 전처리 완료한 corpus 전달\n",
    "    vector_size=100, # 임베딩 벡터의 차원 (열의 갯수)\n",
    "    sg=0, # 학습 알고리즘 선택 -> 0 : CBOW, 1 : Skip-gram\n",
    "    window=5, # 주변단어로 사용될 단어의 갯수 -> 앞뒤로 5개 사용\n",
    "    min_count=5 # 최소 단어 빈도수 -> 5 미만시 제거\n",
    ")\n",
    "\n",
    "model.wv.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>-0.170976</td>\n",
       "      <td>-0.352684</td>\n",
       "      <td>-1.109782</td>\n",
       "      <td>0.719097</td>\n",
       "      <td>-0.056872</td>\n",
       "      <td>-0.834759</td>\n",
       "      <td>0.155871</td>\n",
       "      <td>0.860720</td>\n",
       "      <td>-2.413358</td>\n",
       "      <td>-0.679618</td>\n",
       "      <td>...</td>\n",
       "      <td>1.186917</td>\n",
       "      <td>0.927451</td>\n",
       "      <td>-0.603660</td>\n",
       "      <td>0.320638</td>\n",
       "      <td>1.040395</td>\n",
       "      <td>-1.827408</td>\n",
       "      <td>-0.679039</td>\n",
       "      <td>-0.167280</td>\n",
       "      <td>0.545405</td>\n",
       "      <td>1.103500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>people</th>\n",
       "      <td>-1.743455</td>\n",
       "      <td>0.821341</td>\n",
       "      <td>-0.414869</td>\n",
       "      <td>0.994208</td>\n",
       "      <td>-0.464470</td>\n",
       "      <td>-1.744901</td>\n",
       "      <td>-0.087329</td>\n",
       "      <td>1.340298</td>\n",
       "      <td>-0.988168</td>\n",
       "      <td>-2.138733</td>\n",
       "      <td>...</td>\n",
       "      <td>0.793145</td>\n",
       "      <td>0.775812</td>\n",
       "      <td>-1.617177</td>\n",
       "      <td>-0.238939</td>\n",
       "      <td>-0.700463</td>\n",
       "      <td>0.278039</td>\n",
       "      <td>-0.328139</td>\n",
       "      <td>-1.022362</td>\n",
       "      <td>-1.243265</td>\n",
       "      <td>0.988217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>-0.351880</td>\n",
       "      <td>0.155944</td>\n",
       "      <td>-1.062290</td>\n",
       "      <td>-1.590005</td>\n",
       "      <td>0.033918</td>\n",
       "      <td>-0.171667</td>\n",
       "      <td>0.705476</td>\n",
       "      <td>0.608569</td>\n",
       "      <td>-1.799561</td>\n",
       "      <td>1.103314</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.516862</td>\n",
       "      <td>0.768208</td>\n",
       "      <td>-0.432847</td>\n",
       "      <td>0.008680</td>\n",
       "      <td>-0.335269</td>\n",
       "      <td>0.391648</td>\n",
       "      <td>0.549824</td>\n",
       "      <td>-0.159260</td>\n",
       "      <td>0.498485</td>\n",
       "      <td>-0.467530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>know</th>\n",
       "      <td>-0.663044</td>\n",
       "      <td>-0.103237</td>\n",
       "      <td>-0.110547</td>\n",
       "      <td>0.080980</td>\n",
       "      <td>0.302982</td>\n",
       "      <td>0.194516</td>\n",
       "      <td>-0.484664</td>\n",
       "      <td>0.197144</td>\n",
       "      <td>-0.966257</td>\n",
       "      <td>-0.892510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333185</td>\n",
       "      <td>-0.001130</td>\n",
       "      <td>-0.127065</td>\n",
       "      <td>-0.071313</td>\n",
       "      <td>-0.530158</td>\n",
       "      <td>0.252938</td>\n",
       "      <td>0.204229</td>\n",
       "      <td>-0.821670</td>\n",
       "      <td>0.593109</td>\n",
       "      <td>-0.193557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>going</th>\n",
       "      <td>-1.175145</td>\n",
       "      <td>0.670657</td>\n",
       "      <td>-0.436101</td>\n",
       "      <td>-0.210429</td>\n",
       "      <td>1.271690</td>\n",
       "      <td>0.325620</td>\n",
       "      <td>-0.871675</td>\n",
       "      <td>1.472317</td>\n",
       "      <td>-0.639476</td>\n",
       "      <td>-0.787817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833560</td>\n",
       "      <td>-0.867500</td>\n",
       "      <td>0.096362</td>\n",
       "      <td>1.681017</td>\n",
       "      <td>-0.179273</td>\n",
       "      <td>-0.251886</td>\n",
       "      <td>0.221924</td>\n",
       "      <td>-0.040647</td>\n",
       "      <td>-1.015305</td>\n",
       "      <td>0.550194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>think</th>\n",
       "      <td>-0.371681</td>\n",
       "      <td>-0.225626</td>\n",
       "      <td>0.867421</td>\n",
       "      <td>-0.487055</td>\n",
       "      <td>-0.114237</td>\n",
       "      <td>-1.230629</td>\n",
       "      <td>0.113927</td>\n",
       "      <td>0.007452</td>\n",
       "      <td>-1.126404</td>\n",
       "      <td>-1.171061</td>\n",
       "      <td>...</td>\n",
       "      <td>0.639116</td>\n",
       "      <td>1.374573</td>\n",
       "      <td>-0.547842</td>\n",
       "      <td>0.152309</td>\n",
       "      <td>0.334496</td>\n",
       "      <td>-0.446803</td>\n",
       "      <td>0.001394</td>\n",
       "      <td>-0.743430</td>\n",
       "      <td>-0.006959</td>\n",
       "      <td>-0.117203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>see</th>\n",
       "      <td>0.060864</td>\n",
       "      <td>-0.022080</td>\n",
       "      <td>0.499764</td>\n",
       "      <td>-1.225166</td>\n",
       "      <td>-1.059776</td>\n",
       "      <td>-0.929790</td>\n",
       "      <td>0.044639</td>\n",
       "      <td>0.464147</td>\n",
       "      <td>-2.076057</td>\n",
       "      <td>0.952108</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.597181</td>\n",
       "      <td>0.877456</td>\n",
       "      <td>0.508122</td>\n",
       "      <td>0.789730</td>\n",
       "      <td>0.522987</td>\n",
       "      <td>0.068140</td>\n",
       "      <td>0.653242</td>\n",
       "      <td>-1.047399</td>\n",
       "      <td>0.407329</td>\n",
       "      <td>0.221998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>would</th>\n",
       "      <td>0.296511</td>\n",
       "      <td>0.154338</td>\n",
       "      <td>0.447735</td>\n",
       "      <td>-0.749754</td>\n",
       "      <td>1.373878</td>\n",
       "      <td>0.397202</td>\n",
       "      <td>-0.376988</td>\n",
       "      <td>0.483165</td>\n",
       "      <td>-1.139663</td>\n",
       "      <td>-0.341627</td>\n",
       "      <td>...</td>\n",
       "      <td>1.192409</td>\n",
       "      <td>-0.286457</td>\n",
       "      <td>-1.085607</td>\n",
       "      <td>1.479000</td>\n",
       "      <td>-0.507268</td>\n",
       "      <td>0.910902</td>\n",
       "      <td>-1.225696</td>\n",
       "      <td>-0.850046</td>\n",
       "      <td>-0.978325</td>\n",
       "      <td>-0.795954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>really</th>\n",
       "      <td>-2.498835</td>\n",
       "      <td>-0.742601</td>\n",
       "      <td>-0.332148</td>\n",
       "      <td>0.181163</td>\n",
       "      <td>0.088897</td>\n",
       "      <td>-0.079612</td>\n",
       "      <td>1.333248</td>\n",
       "      <td>1.631978</td>\n",
       "      <td>-0.275459</td>\n",
       "      <td>-0.562740</td>\n",
       "      <td>...</td>\n",
       "      <td>0.550215</td>\n",
       "      <td>-0.231831</td>\n",
       "      <td>0.085143</td>\n",
       "      <td>0.041186</td>\n",
       "      <td>0.738517</td>\n",
       "      <td>-0.300301</td>\n",
       "      <td>-0.252834</td>\n",
       "      <td>-1.524760</td>\n",
       "      <td>-0.422742</td>\n",
       "      <td>-0.162458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>get</th>\n",
       "      <td>-2.349108</td>\n",
       "      <td>-1.466434</td>\n",
       "      <td>-1.017342</td>\n",
       "      <td>-0.998127</td>\n",
       "      <td>-0.129758</td>\n",
       "      <td>-1.123341</td>\n",
       "      <td>-0.468420</td>\n",
       "      <td>2.081601</td>\n",
       "      <td>-0.113608</td>\n",
       "      <td>-1.603799</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.205629</td>\n",
       "      <td>-0.392400</td>\n",
       "      <td>-0.202999</td>\n",
       "      <td>0.396128</td>\n",
       "      <td>0.703867</td>\n",
       "      <td>0.473035</td>\n",
       "      <td>0.105590</td>\n",
       "      <td>-0.056075</td>\n",
       "      <td>-0.839903</td>\n",
       "      <td>0.167500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6   \\\n",
       "one    -0.170976 -0.352684 -1.109782  0.719097 -0.056872 -0.834759  0.155871   \n",
       "people -1.743455  0.821341 -0.414869  0.994208 -0.464470 -1.744901 -0.087329   \n",
       "like   -0.351880  0.155944 -1.062290 -1.590005  0.033918 -0.171667  0.705476   \n",
       "know   -0.663044 -0.103237 -0.110547  0.080980  0.302982  0.194516 -0.484664   \n",
       "going  -1.175145  0.670657 -0.436101 -0.210429  1.271690  0.325620 -0.871675   \n",
       "think  -0.371681 -0.225626  0.867421 -0.487055 -0.114237 -1.230629  0.113927   \n",
       "see     0.060864 -0.022080  0.499764 -1.225166 -1.059776 -0.929790  0.044639   \n",
       "would   0.296511  0.154338  0.447735 -0.749754  1.373878  0.397202 -0.376988   \n",
       "really -2.498835 -0.742601 -0.332148  0.181163  0.088897 -0.079612  1.333248   \n",
       "get    -2.349108 -1.466434 -1.017342 -0.998127 -0.129758 -1.123341 -0.468420   \n",
       "\n",
       "              7         8         9   ...        90        91        92  \\\n",
       "one     0.860720 -2.413358 -0.679618  ...  1.186917  0.927451 -0.603660   \n",
       "people  1.340298 -0.988168 -2.138733  ...  0.793145  0.775812 -1.617177   \n",
       "like    0.608569 -1.799561  1.103314  ... -0.516862  0.768208 -0.432847   \n",
       "know    0.197144 -0.966257 -0.892510  ...  0.333185 -0.001130 -0.127065   \n",
       "going   1.472317 -0.639476 -0.787817  ...  0.833560 -0.867500  0.096362   \n",
       "think   0.007452 -1.126404 -1.171061  ...  0.639116  1.374573 -0.547842   \n",
       "see     0.464147 -2.076057  0.952108  ... -0.597181  0.877456  0.508122   \n",
       "would   0.483165 -1.139663 -0.341627  ...  1.192409 -0.286457 -1.085607   \n",
       "really  1.631978 -0.275459 -0.562740  ...  0.550215 -0.231831  0.085143   \n",
       "get     2.081601 -0.113608 -1.603799  ... -0.205629 -0.392400 -0.202999   \n",
       "\n",
       "              93        94        95        96        97        98        99  \n",
       "one     0.320638  1.040395 -1.827408 -0.679039 -0.167280  0.545405  1.103500  \n",
       "people -0.238939 -0.700463  0.278039 -0.328139 -1.022362 -1.243265  0.988217  \n",
       "like    0.008680 -0.335269  0.391648  0.549824 -0.159260  0.498485 -0.467530  \n",
       "know   -0.071313 -0.530158  0.252938  0.204229 -0.821670  0.593109 -0.193557  \n",
       "going   1.681017 -0.179273 -0.251886  0.221924 -0.040647 -1.015305  0.550194  \n",
       "think   0.152309  0.334496 -0.446803  0.001394 -0.743430 -0.006959 -0.117203  \n",
       "see     0.789730  0.522987  0.068140  0.653242 -1.047399  0.407329  0.221998  \n",
       "would   1.479000 -0.507268  0.910902 -1.225696 -0.850046 -0.978325 -0.795954  \n",
       "really  0.041186  0.738517 -0.300301 -0.252834 -1.524760 -0.422742 -0.162458  \n",
       "get     0.396128  0.703867  0.473035  0.105590 -0.056075 -0.839903  0.167500  \n",
       "\n",
       "[10 rows x 100 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 단어와 벡터값을 데이터프레임으로 변환\n",
    "pd.DataFrame(model.wv.vectors, index=model.wv.index_to_key).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습된 모델 저장장\n",
    "model.wv.save_word2vec_format('./data/ted_en_w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩 모델 로드\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "load_model = KeyedVectors.load_word2vec_format('./data/ted_en_w2v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 유사도 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('woman', 0.894888162612915),\n",
       " ('lady', 0.8059537410736084),\n",
       " ('daughter', 0.8046254515647888),\n",
       " ('girl', 0.7839692831039429),\n",
       " ('father', 0.768945574760437),\n",
       " ('son', 0.7668907046318054),\n",
       " ('sister', 0.7639594078063965),\n",
       " ('boy', 0.760553777217865),\n",
       " ('grandfather', 0.7535830736160278),\n",
       " ('brother', 0.7494614720344543)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('man')\n",
    "# model.wv.most_similar('abracadabra') # 없는 단어로 검색시 KeyError 발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('woman', 0.894888162612915),\n",
       " ('lady', 0.8059537410736084),\n",
       " ('daughter', 0.8046254515647888),\n",
       " ('girl', 0.7839692831039429),\n",
       " ('father', 0.768945574760437),\n",
       " ('son', 0.7668907046318054),\n",
       " ('sister', 0.7639594078063965),\n",
       " ('boy', 0.760553777217865),\n",
       " ('grandfather', 0.7535830736160278),\n",
       " ('brother', 0.7494614720344543)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_model.most_similar('man')  # Word2Vector = KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7839694"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습 과정에서 결과가 조금씩 달라질수 있음\n",
    "model.wv.similarity('man', 'girl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.7745835 , -0.22766349,  1.0062977 ,  1.8761008 , -0.91865075,\n",
       "       -0.15480942, -0.8077635 ,  1.481545  , -0.43826073, -0.9032544 ,\n",
       "        0.2819144 ,  0.75686204, -0.08193346,  0.520204  ,  1.178618  ,\n",
       "       -0.55458224,  0.816066  ,  0.29596296, -0.9180915 , -0.01825986,\n",
       "        0.92368734,  0.84741896, -0.04565032, -0.49587068,  0.4323257 ,\n",
       "        0.26310664, -0.9674338 , -0.6551638 , -0.27444005,  0.9216952 ,\n",
       "       -1.4798337 , -0.9679094 , -0.02177182, -1.6081411 , -0.2547376 ,\n",
       "        1.1141034 , -0.34371814, -0.58212453,  0.43535814, -0.23926155,\n",
       "        1.241017  ,  0.08917684,  0.7958752 ,  0.4483123 ,  1.9125143 ,\n",
       "       -0.04252987, -0.96859765,  0.4817343 ,  0.25932178, -0.35227594,\n",
       "        0.6278037 , -0.2608963 ,  0.1191903 , -0.9320729 ,  0.27536732,\n",
       "        0.595481  ,  0.37365815,  0.3440508 , -0.07001403, -0.18483338,\n",
       "        0.0405275 , -0.760845  , -1.8638783 ,  1.1551318 , -1.0451267 ,\n",
       "        0.91317815, -0.15356694,  0.2598233 ,  0.6875841 ,  1.5737036 ,\n",
       "       -0.69965965, -1.429682  ,  0.25278756, -1.0057676 ,  0.13254163,\n",
       "        1.2969652 , -0.0579938 ,  0.7504318 ,  0.8660984 , -0.36250964,\n",
       "       -0.30873707,  0.13641298, -1.1676508 ,  1.2436409 , -0.5801828 ,\n",
       "        0.09970257, -0.5594209 , -0.692152  ,  0.10810464,  0.5933589 ,\n",
       "       -0.0351528 , -0.7250807 , -0.31834665, -1.611734  ,  0.26763976,\n",
       "        0.39955872,  0.77313423,  0.04545775, -0.04603194, -1.3991048 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['man']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 임베딩 시각화\n",
    "\n",
    "https://projector.tensorflow.org/\n",
    "\n",
    "- embedding vector(tensor) 파일 (.tsv)\n",
    "- metadat 파일 (.tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 12:06:24,164 - word2vec2tensor - INFO - running c:\\Users\\ljh10\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\gensim\\scripts\\word2vec2tensor.py --input ./data/ted_en_w2v --output ./data/ted_en_w2v\n",
      "2025-02-20 12:06:24,164 - keyedvectors - INFO - loading projection weights from ./data/ted_en_w2v\n",
      "2025-02-20 12:06:25,706 - utils - INFO - KeyedVectors lifecycle event {'msg': 'loaded (21462, 100) matrix of type float32 from ./data/ted_en_w2v', 'binary': False, 'encoding': 'utf8', 'datetime': '2025-02-20T12:06:25.390534', 'gensim': '4.3.3', 'python': '3.12.8 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:48:34) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'load_word2vec_format'}\n",
      "2025-02-20 12:06:26,739 - word2vec2tensor - INFO - 2D tensor file saved to ./data/ted_en_w2v_tensor.tsv\n",
      "2025-02-20 12:06:26,739 - word2vec2tensor - INFO - Tensor metadata file saved to ./data/ted_en_w2v_metadata.tsv\n",
      "2025-02-20 12:06:26,739 - word2vec2tensor - INFO - finished running word2vec2tensor.py\n"
     ]
    }
   ],
   "source": [
    "!python -m gensim.scripts.word2vec2tensor --input ./data/ted_en_w2v --output ./data/ted_en_w2v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 한국어 Word Embedding\n",
    "- NSMC (Naver Sentiment Movie Corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "from konlpy.tag import Okt # 형태소 분석기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./data/naver_movie_ratings.txt', <http.client.HTTPMessage at 0x2968cf7b3e0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 다운로드 \n",
    "# urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt\",\n",
    "#                            filename='./data/naver_movie_ratings.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 프레임 생성\n",
    "ratings_df = pd.read_csv('./data/naver_movie_ratings.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "document    0\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 결측치 확인 및 처리 (제거)\n",
    "display(ratings_df.isnull().sum())\n",
    "\n",
    "ratings_df = ratings_df.dropna(how='any') # Null 값이 존재하는 행 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                       어릴때보고 지금다시봐도 재밌어요ㅋㅋ\n",
       "1         디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...\n",
       "2                      폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.\n",
       "3         와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...\n",
       "4                               안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.\n",
       "                                ...                        \n",
       "199995                                       포켓 몬스터 짜가 ㅡㅡ;;\n",
       "199996                                                쓰.레.기\n",
       "199997                    완전 사이코영화. 마지막은 더욱더 이 영화의질을 떨어트린다.\n",
       "199998                  왜난 재미없었지 ㅠㅠ 라따뚜이 보고나서 스머프 봐서 그런가 ㅋㅋ\n",
       "199999                                      포풍저그가나가신다영차영차영차\n",
       "Name: document, Length: 199992, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df['document']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글이 아닌 데이터 제거\n",
    "ratings_df['document'] =ratings_df['document'].replace(r'[^0-9가-힣ㄱ-ㅎㅏ-ㅣ]', '', regex=True) # 한글이 아닌 데이터 제거, 자음 혹은 모음으로만 이뤄진 단어들은 남겨둠\n",
    "# regex : 정규식 사용 여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 199992/199992 [1:07:18<00:00, 49.52it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['어리다', '때', '보고', '지금', '다시', '보다', '재밌다', 'ㅋㅋ'],\n",
       " ['디자인',\n",
       "  '배우다',\n",
       "  '학생',\n",
       "  '으로',\n",
       "  '외국',\n",
       "  '디자이너',\n",
       "  '일군',\n",
       "  '전통',\n",
       "  '통해',\n",
       "  '발전',\n",
       "  '하다',\n",
       "  '문화',\n",
       "  '산업',\n",
       "  '부럽다',\n",
       "  '사실',\n",
       "  '우리나라',\n",
       "  '에서도',\n",
       "  '어려운',\n",
       "  '시절',\n",
       "  '끝',\n",
       "  '열정',\n",
       "  '지키다',\n",
       "  '노라노',\n",
       "  '같다',\n",
       "  '전통',\n",
       "  '있다',\n",
       "  '저',\n",
       "  '같다',\n",
       "  '사람',\n",
       "  '꿈',\n",
       "  '꾸다',\n",
       "  '이루다',\n",
       "  '갈수',\n",
       "  '있다',\n",
       "  '감사하다'],\n",
       " ['폴리스스토리', '시리즈', '1', '뉴', '버리다', '없다', '최고'],\n",
       " ['오다',\n",
       "  '연기',\n",
       "  '진짜',\n",
       "  '개',\n",
       "  '쩔다',\n",
       "  '지루하다',\n",
       "  '생각',\n",
       "  '하다',\n",
       "  '몰입',\n",
       "  '하다',\n",
       "  '보다',\n",
       "  '다그',\n",
       "  '래',\n",
       "  '이렇다',\n",
       "  '진짜',\n",
       "  '영화',\n",
       "  '지'],\n",
       " ['안개', '자욱하다', '밤하늘', '뜨다', '초승달', '같다', '영화']]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전처리\n",
    "from tqdm import tqdm\n",
    "okt = Okt()\n",
    "ko_stopwards = ['은','는','이','가','을','를','와','과','들','도','부터','까지','에','나','너','그','걔','얘']\n",
    "\n",
    "preprocessed_data = []\n",
    "\n",
    "for sentence in tqdm(ratings_df['document']): # tqdm : 진행상황을 시각화 해주는 라이브러리\n",
    "    tokens = okt.morphs(sentence, stem=True)    #morphs : 형태소 분석기, stem : 어간 추출\n",
    "    tokens = [token for token in tokens if token not in ko_stopwards]\n",
    "    preprocessed_data.append(tokens)\n",
    "    \n",
    "preprocessed_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17889, 100)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Word2Vec(\n",
    "    sentences=preprocessed_data,\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    min_count=5,\n",
    "    sg=0 # CBOW\n",
    ")\n",
    "\n",
    "model.wv.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77569747"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('김혜수','박서준')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.save_word2vec_format('./data/naver_movie_ratings_w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 14:03:56,672 - word2vec2tensor - INFO - running c:\\Users\\ljh10\\anaconda3\\envs\\pystudy_env\\Lib\\site-packages\\gensim\\scripts\\word2vec2tensor.py --input ./data/naver_movie_ratings_w2v --output ./data/naver_movie_ratings_w2v\n",
      "2025-02-20 14:03:56,672 - keyedvectors - INFO - loading projection weights from ./data/naver_movie_ratings_w2v\n",
      "2025-02-20 14:03:57,559 - utils - INFO - KeyedVectors lifecycle event {'msg': 'loaded (17889, 100) matrix of type float32 from ./data/naver_movie_ratings_w2v', 'binary': False, 'encoding': 'utf8', 'datetime': '2025-02-20T14:03:57.383540', 'gensim': '4.3.3', 'python': '3.12.8 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:48:34) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-11-10.0.26100-SP0', 'event': 'load_word2vec_format'}\n",
      "2025-02-20 14:03:58,165 - word2vec2tensor - INFO - 2D tensor file saved to ./data/naver_movie_ratings_w2v_tensor.tsv\n",
      "2025-02-20 14:03:58,165 - word2vec2tensor - INFO - Tensor metadata file saved to ./data/naver_movie_ratings_w2v_metadata.tsv\n",
      "2025-02-20 14:03:58,165 - word2vec2tensor - INFO - finished running word2vec2tensor.py\n"
     ]
    }
   ],
   "source": [
    "!python -m gensim.scripts.word2vec2tensor --input ./data/naver_movie_ratings_w2v --output ./data/naver_movie_ratings_w2v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 사전 훈련된 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=11MWLNUBLOJWpJePTbOJwCtcgEryPGKGj\n",
      "From (redirected): https://drive.google.com/uc?id=11MWLNUBLOJWpJePTbOJwCtcgEryPGKGj&confirm=t&uuid=00b2a987-cf65-4a3c-bb25-449a69ddb0a6\n",
      "To: c:\\SKNetworks_AI\\ai-learning\\AI-learning\\NLP\\03_word_embedding\\data\\GoogleNews_vecs.bin.gz\n",
      "100%|██████████| 1.65G/1.65G [02:28<00:00, 11.1MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./data/GoogleNews_vecs.bin.gz'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url ='https://drive.google.com/uc?id=11MWLNUBLOJWpJePTbOJwCtcgEryPGKGj'\n",
    "output='./data/GoogleNews_vecs.bin.gz'\n",
    "\n",
    "gdown.download(url, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000000, 300)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_news_wv = KeyedVectors.load_word2vec_format('./data/GoogleNews_vecs.bin.gz', binary=True)\n",
    "google_news_wv.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22942673"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_news_wv.similarity('king','man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kings', 0.7138045430183411),\n",
       " ('queen', 0.6510956883430481),\n",
       " ('monarch', 0.6413194537162781),\n",
       " ('crown_prince', 0.6204220056533813),\n",
       " ('prince', 0.6159993410110474)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_news_wv.most_similar('king', topn=5) # topn : 상위 n개의 유사도를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24791393"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_news_wv.n_similarity(['king','queen'],['man','woman'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kings', 0.7138045430183411),\n",
       " ('queen', 0.6510956883430481),\n",
       " ('monarch', 0.6413194537162781),\n",
       " ('crown_prince', 0.6204220056533813),\n",
       " ('prince', 0.6159993410110474)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_news_wv.similar_by_word('king', topn=5) # similar_by_word : 단어를 입력받아 유사도를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_news_wv.has_index_for('king') # 단어가 존재하는지 확인"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pystudy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
